<!-- see https://stackoverflow.com/questions/2454577/sphinx-restructuredtext-show-hide-code-snippets -->
<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>k2 &mdash; k2 1.9 documentation</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="prev" title="version" href="version.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> k2
          </a>
              <div class="version">
                1.9
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../installation/index.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../core_concepts/index.html">Core concepts in k2</a></li>
<li class="toctree-l1"><a class="reference internal" href="../python_tutorials/index.html">Python tutorials</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">Python API reference</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="version.html">version</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">k2</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#add-epsilon-self-loops">add_epsilon_self_loops</a></li>
<li class="toctree-l3"><a class="reference internal" href="#arc-sort">arc_sort</a></li>
<li class="toctree-l3"><a class="reference internal" href="#cat">cat</a></li>
<li class="toctree-l3"><a class="reference internal" href="#closure">closure</a></li>
<li class="toctree-l3"><a class="reference internal" href="#compose">compose</a></li>
<li class="toctree-l3"><a class="reference internal" href="#compose-arc-maps">compose_arc_maps</a></li>
<li class="toctree-l3"><a class="reference internal" href="#connect">connect</a></li>
<li class="toctree-l3"><a class="reference internal" href="#convert-dense-to-fsa-vec">convert_dense_to_fsa_vec</a></li>
<li class="toctree-l3"><a class="reference internal" href="#create-fsa-vec">create_fsa_vec</a></li>
<li class="toctree-l3"><a class="reference internal" href="#create-sparse">create_sparse</a></li>
<li class="toctree-l3"><a class="reference internal" href="#ctc-graph">ctc_graph</a></li>
<li class="toctree-l3"><a class="reference internal" href="#ctc-loss">ctc_loss</a></li>
<li class="toctree-l3"><a class="reference internal" href="#ctc-topo">ctc_topo</a></li>
<li class="toctree-l3"><a class="reference internal" href="#determinize">determinize</a></li>
<li class="toctree-l3"><a class="reference internal" href="#expand-ragged-attributes">expand_ragged_attributes</a></li>
<li class="toctree-l3"><a class="reference internal" href="#get-best-matching-stats">get_best_matching_stats</a></li>
<li class="toctree-l3"><a class="reference internal" href="#index-add">index_add</a></li>
<li class="toctree-l3"><a class="reference internal" href="#index-fsa">index_fsa</a></li>
<li class="toctree-l3"><a class="reference internal" href="#index-select">index_select</a></li>
<li class="toctree-l3"><a class="reference internal" href="#intersect">intersect</a></li>
<li class="toctree-l3"><a class="reference internal" href="#intersect-dense">intersect_dense</a></li>
<li class="toctree-l3"><a class="reference internal" href="#intersect-dense-pruned">intersect_dense_pruned</a></li>
<li class="toctree-l3"><a class="reference internal" href="#intersect-device">intersect_device</a></li>
<li class="toctree-l3"><a class="reference internal" href="#invert">invert</a></li>
<li class="toctree-l3"><a class="reference internal" href="#is-rand-equivalent">is_rand_equivalent</a></li>
<li class="toctree-l3"><a class="reference internal" href="#levenshtein-alignment">levenshtein_alignment</a></li>
<li class="toctree-l3"><a class="reference internal" href="#levenshtein-graph">levenshtein_graph</a></li>
<li class="toctree-l3"><a class="reference internal" href="#linear-fsa">linear_fsa</a></li>
<li class="toctree-l3"><a class="reference internal" href="#linear-fst">linear_fst</a></li>
<li class="toctree-l3"><a class="reference internal" href="#properties-to-str">properties_to_str</a></li>
<li class="toctree-l3"><a class="reference internal" href="#prune-on-arc-post">prune_on_arc_post</a></li>
<li class="toctree-l3"><a class="reference internal" href="#random-fsa">random_fsa</a></li>
<li class="toctree-l3"><a class="reference internal" href="#random-fsa-vec">random_fsa_vec</a></li>
<li class="toctree-l3"><a class="reference internal" href="#random-paths">random_paths</a></li>
<li class="toctree-l3"><a class="reference internal" href="#remove-epsilon">remove_epsilon</a></li>
<li class="toctree-l3"><a class="reference internal" href="#remove-epsilon-and-add-self-loops">remove_epsilon_and_add_self_loops</a></li>
<li class="toctree-l3"><a class="reference internal" href="#remove-epsilon-self-loops">remove_epsilon_self_loops</a></li>
<li class="toctree-l3"><a class="reference internal" href="#replace-fsa">replace_fsa</a></li>
<li class="toctree-l3"><a class="reference internal" href="#shortest-path">shortest_path</a></li>
<li class="toctree-l3"><a class="reference internal" href="#simple-ragged-index-select">simple_ragged_index_select</a></li>
<li class="toctree-l3"><a class="reference internal" href="#to-dot">to_dot</a></li>
<li class="toctree-l3"><a class="reference internal" href="#to-str">to_str</a></li>
<li class="toctree-l3"><a class="reference internal" href="#to-str-simple">to_str_simple</a></li>
<li class="toctree-l3"><a class="reference internal" href="#to-tensor">to_tensor</a></li>
<li class="toctree-l3"><a class="reference internal" href="#top-sort">top_sort</a></li>
<li class="toctree-l3"><a class="reference internal" href="#union">union</a></li>
<li class="toctree-l3"><a class="reference internal" href="#ctcloss">CtcLoss</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#forward">forward</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#densefsavec">DenseFsaVec</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#init">__init__</a></li>
<li class="toctree-l4"><a class="reference internal" href="#from-dense-fsa-vec">_from_dense_fsa_vec</a></li>
<li class="toctree-l4"><a class="reference internal" href="#to">to</a></li>
<li class="toctree-l4"><a class="reference internal" href="#device">device</a></li>
<li class="toctree-l4"><a class="reference internal" href="#duration">duration</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#determinizeweightpushingtype">DeterminizeWeightPushingType</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#name">name</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#fsa">Fsa</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#getattr">__getattr__</a></li>
<li class="toctree-l4"><a class="reference internal" href="#getitem">__getitem__</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id1">__init__</a></li>
<li class="toctree-l4"><a class="reference internal" href="#setattr">__setattr__</a></li>
<li class="toctree-l4"><a class="reference internal" href="#str">__str__</a></li>
<li class="toctree-l4"><a class="reference internal" href="#get-arc-post">_get_arc_post</a></li>
<li class="toctree-l4"><a class="reference internal" href="#get-backward-scores">_get_backward_scores</a></li>
<li class="toctree-l4"><a class="reference internal" href="#get-entering-arcs">_get_entering_arcs</a></li>
<li class="toctree-l4"><a class="reference internal" href="#get-forward-scores">_get_forward_scores</a></li>
<li class="toctree-l4"><a class="reference internal" href="#get-tot-scores">_get_tot_scores</a></li>
<li class="toctree-l4"><a class="reference internal" href="#invalidate-cache">_invalidate_cache_</a></li>
<li class="toctree-l4"><a class="reference internal" href="#as-dict">as_dict</a></li>
<li class="toctree-l4"><a class="reference internal" href="#convert-attr-to-ragged">convert_attr_to_ragged</a></li>
<li class="toctree-l4"><a class="reference internal" href="#draw">draw</a></li>
<li class="toctree-l4"><a class="reference internal" href="#from-openfst">from_openfst</a></li>
<li class="toctree-l4"><a class="reference internal" href="#from-str">from_str</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id2">get_arc_post</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id3">get_backward_scores</a></li>
<li class="toctree-l4"><a class="reference internal" href="#get-filler">get_filler</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id4">get_forward_scores</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id5">get_tot_scores</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id6">invert</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id7">invert_</a></li>
<li class="toctree-l4"><a class="reference internal" href="#rename-tensor-attribute">rename_tensor_attribute</a></li>
<li class="toctree-l4"><a class="reference internal" href="#requires-grad">requires_grad_</a></li>
<li class="toctree-l4"><a class="reference internal" href="#set-scores-stochastic">set_scores_stochastic</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id8">to</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id9">device</a></li>
<li class="toctree-l4"><a class="reference internal" href="#grad">grad</a></li>
<li class="toctree-l4"><a class="reference internal" href="#labels">labels</a></li>
<li class="toctree-l4"><a class="reference internal" href="#num-arcs">num_arcs</a></li>
<li class="toctree-l4"><a class="reference internal" href="#properties">properties</a></li>
<li class="toctree-l4"><a class="reference internal" href="#properties-str">properties_str</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id10">requires_grad</a></li>
<li class="toctree-l4"><a class="reference internal" href="#shape">shape</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#nbest">Nbest</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id11">intersect</a></li>
<li class="toctree-l4"><a class="reference internal" href="#top-k">top_k</a></li>
<li class="toctree-l4"><a class="reference internal" href="#total-scores">total_scores</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#raggedshape">RaggedShape</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#eq">__eq__</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id14">__getitem__</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id15">__init__</a></li>
<li class="toctree-l4"><a class="reference internal" href="#ne">__ne__</a></li>
<li class="toctree-l4"><a class="reference internal" href="#repr">__repr__</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id16">__str__</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id17">compose</a></li>
<li class="toctree-l4"><a class="reference internal" href="#get-layer">get_layer</a></li>
<li class="toctree-l4"><a class="reference internal" href="#index">index</a></li>
<li class="toctree-l4"><a class="reference internal" href="#max-size">max_size</a></li>
<li class="toctree-l4"><a class="reference internal" href="#numel">numel</a></li>
<li class="toctree-l4"><a class="reference internal" href="#regular-ragged-shape">regular_ragged_shape</a></li>
<li class="toctree-l4"><a class="reference internal" href="#remove-axis">remove_axis</a></li>
<li class="toctree-l4"><a class="reference internal" href="#row-ids">row_ids</a></li>
<li class="toctree-l4"><a class="reference internal" href="#row-splits">row_splits</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id18">to</a></li>
<li class="toctree-l4"><a class="reference internal" href="#tot-size">tot_size</a></li>
<li class="toctree-l4"><a class="reference internal" href="#tot-sizes">tot_sizes</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id19">device</a></li>
<li class="toctree-l4"><a class="reference internal" href="#dim0">dim0</a></li>
<li class="toctree-l4"><a class="reference internal" href="#num-axes">num_axes</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#raggedtensor">RaggedTensor</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id20">__eq__</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id21">__getitem__</a></li>
<li class="toctree-l4"><a class="reference internal" href="#getstate">__getstate__</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id22">__init__</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id23">__ne__</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id24">__repr__</a></li>
<li class="toctree-l4"><a class="reference internal" href="#setstate">__setstate__</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id25">__str__</a></li>
<li class="toctree-l4"><a class="reference internal" href="#arange">arange</a></li>
<li class="toctree-l4"><a class="reference internal" href="#argmax">argmax</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id26">cat</a></li>
<li class="toctree-l4"><a class="reference internal" href="#clone">clone</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id27">index</a></li>
<li class="toctree-l4"><a class="reference internal" href="#max">max</a></li>
<li class="toctree-l4"><a class="reference internal" href="#min">min</a></li>
<li class="toctree-l4"><a class="reference internal" href="#normalize">normalize</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id28">numel</a></li>
<li class="toctree-l4"><a class="reference internal" href="#pad">pad</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id29">remove_axis</a></li>
<li class="toctree-l4"><a class="reference internal" href="#remove-values-eq">remove_values_eq</a></li>
<li class="toctree-l4"><a class="reference internal" href="#remove-values-leq">remove_values_leq</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id30">requires_grad_</a></li>
<li class="toctree-l4"><a class="reference internal" href="#sort">sort_</a></li>
<li class="toctree-l4"><a class="reference internal" href="#sum">sum</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id31">to</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id32">to_str_simple</a></li>
<li class="toctree-l4"><a class="reference internal" href="#tolist">tolist</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id33">tot_size</a></li>
<li class="toctree-l4"><a class="reference internal" href="#unique">unique</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id34">device</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id35">dim0</a></li>
<li class="toctree-l4"><a class="reference internal" href="#dtype">dtype</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id36">grad</a></li>
<li class="toctree-l4"><a class="reference internal" href="#is-cuda">is_cuda</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id37">num_axes</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id38">requires_grad</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id39">shape</a></li>
<li class="toctree-l4"><a class="reference internal" href="#values">values</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#symboltable">SymbolTable</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#add">add</a></li>
<li class="toctree-l4"><a class="reference internal" href="#from-file">from_file</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id40">from_str</a></li>
<li class="toctree-l4"><a class="reference internal" href="#get">get</a></li>
<li class="toctree-l4"><a class="reference internal" href="#merge">merge</a></li>
<li class="toctree-l4"><a class="reference internal" href="#to-file">to_file</a></li>
<li class="toctree-l4"><a class="reference internal" href="#ids">ids</a></li>
<li class="toctree-l4"><a class="reference internal" href="#symbols">symbols</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#k2-ragged">k2.ragged</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id41">cat</a></li>
<li class="toctree-l3"><a class="reference internal" href="#create-ragged-shape2">create_ragged_shape2</a></li>
<li class="toctree-l3"><a class="reference internal" href="#create-ragged-tensor">create_ragged_tensor</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id42">index</a></li>
<li class="toctree-l3"><a class="reference internal" href="#index-and-sum">index_and_sum</a></li>
<li class="toctree-l3"><a class="reference internal" href="#random-ragged-shape">random_ragged_shape</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id43">regular_ragged_shape</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id44">RaggedShape</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id45">__eq__</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id46">__getitem__</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id47">__init__</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id48">__ne__</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id49">__repr__</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id50">__str__</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id51">compose</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id52">get_layer</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id53">index</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id54">max_size</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id55">numel</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id56">regular_ragged_shape</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id57">remove_axis</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id58">row_ids</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id59">row_splits</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id60">to</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id61">tot_size</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id62">tot_sizes</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id63">device</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id64">dim0</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id65">num_axes</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#id66">RaggedTensor</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id67">__eq__</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id68">__getitem__</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id69">__getstate__</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id70">__init__</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id71">__ne__</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id72">__repr__</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id73">__setstate__</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id74">__str__</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id75">arange</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id76">argmax</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id77">cat</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id78">clone</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id79">index</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id80">max</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id81">min</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id82">normalize</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id83">numel</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id84">pad</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id85">remove_axis</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id86">remove_values_eq</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id87">remove_values_leq</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id88">requires_grad_</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id89">sort_</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id90">sum</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id91">to</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id92">to_str_simple</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id93">tolist</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id94">tot_size</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id95">unique</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id96">device</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id97">dim0</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id98">dtype</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id99">grad</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id100">is_cuda</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id101">num_axes</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id102">requires_grad</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id103">shape</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id104">values</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">k2</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content style-external-links">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="index.html">Python API reference</a> &raquo;</li>
      <li>k2</li>
      <li class="wy-breadcrumbs-aside">
              <a href="https://github.com/k2-fsa/k2/blob/master/k2/docs/source/python_api/api.rst" class="fa fa-github"> Edit on GitHub</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="k2">
<h1>k2<a class="headerlink" href="#k2" title="Permalink to this headline"></a></h1>
<section id="add-epsilon-self-loops">
<h2>add_epsilon_self_loops<a class="headerlink" href="#add-epsilon-self-loops" title="Permalink to this headline"></a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="k2.add_epsilon_self_loops">
<span class="sig-prename descclassname"><span class="pre">k2.</span></span><span class="sig-name descname"><span class="pre">add_epsilon_self_loops</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fsa</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ret_arc_map</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/k2-fsa/k2/blob/master/k2/python/k2/fsa_algo.py#L475-L506"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#k2.add_epsilon_self_loops" title="Permalink to this definition"></a></dt>
<dd><p>Add epsilon self-loops to an Fsa or FsaVec.</p>
<p>This is required when composing using a composition method that does not
treat epsilons specially, if the other FSA has epsilons in it.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>fsa</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Fsa</span></code>) – The input FSA. It can be either a single FSA or an FsaVec.</p></li>
<li><p><strong>ret_arc_map</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – If False, return the resulting Fsa.
If True, return an extra arc map.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Fsa</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Fsa</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>]]</p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>If ret_arc_map is False, return an instance of <code class="xref py py-class docutils literal notranslate"><span class="pre">Fsa</span></code> that has an
epsilon self-loop on every non-final state.
If ret_arc_map is True, it returns an extra arc_map. arc_map[i] is the
arc index in the input <cite>fsa</cite> that corresponds to the i-th arc in the
resulting Fsa. arc_map[i] is -1 if the i-th arc in the resulting Fsa
has no counterpart in the input <cite>fsa</cite>.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="arc-sort">
<h2>arc_sort<a class="headerlink" href="#arc-sort" title="Permalink to this headline"></a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="k2.arc_sort">
<span class="sig-prename descclassname"><span class="pre">k2.</span></span><span class="sig-name descname"><span class="pre">arc_sort</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fsa</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ret_arc_map</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/k2-fsa/k2/blob/master/k2/python/k2/fsa_algo.py#L406-L447"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#k2.arc_sort" title="Permalink to this definition"></a></dt>
<dd><p>Sort arcs of every state.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Arcs are sorted by labels first, and then by dest states.</p>
</div>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>If the input <cite>fsa</cite> is already arc sorted, we return it directly.
Otherwise, a new sorted fsa is returned.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>fsa</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Fsa</span></code>) – The input FSA.</p></li>
<li><p><strong>ret_arc_map</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – True to return an extra arc_map (a 1-D tensor with dtype being
torch.int32). arc_map[i] is the arc index in the input <cite>fsa</cite> that
corresponds to the i-th arc in the output Fsa.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Fsa</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Fsa</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>]]</p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>If ret_arc_map is False, return the sorted FSA. It is the same as the
input <cite>fsa</cite> if the input <cite>fsa</cite> is arc sorted. Otherwise, a new sorted
fsa is returned and the input <cite>fsa</cite> is NOT modified.
If ret_arc_map is True, an extra arc map is also returned.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="cat">
<h2>cat<a class="headerlink" href="#cat" title="Permalink to this headline"></a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="k2.cat">
<span class="sig-prename descclassname"><span class="pre">k2.</span></span><span class="sig-name descname"><span class="pre">cat</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">srcs</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/k2-fsa/k2/blob/master/k2/python/k2/ops.py#L198-L245"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#k2.cat" title="Permalink to this definition"></a></dt>
<dd><p>Concatenate a list of FsaVec into a single FsaVec.</p>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>Only common tensor attributes are kept in the output FsaVec.
For non-tensor attributes, only one copy is kept in the output
FsaVec. We choose the first copy of the FsaVec that has the
lowest index in <cite>srcs</cite>.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>srcs</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Fsa</span></code>]) – A list of FsaVec. Each element MUST be an FsaVec.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Fsa</span></code></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Return a single FsaVec concatenated from the input FsaVecs.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="closure">
<h2>closure<a class="headerlink" href="#closure" title="Permalink to this headline"></a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="k2.closure">
<span class="sig-prename descclassname"><span class="pre">k2.</span></span><span class="sig-name descname"><span class="pre">closure</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fsa</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/k2-fsa/k2/blob/master/k2/python/k2/fsa_algo.py#L653-L708"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#k2.closure" title="Permalink to this definition"></a></dt>
<dd><p>Compute the Kleene closure of the input FSA.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>fsa</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Fsa</span></code>) – The input FSA. It has to be a single FSA. That is,
len(fsa.shape) == 2.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Fsa</span></code></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>The resulting FSA which is the Kleene closure of the input FSA.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="compose">
<h2>compose<a class="headerlink" href="#compose" title="Permalink to this headline"></a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="k2.compose">
<span class="sig-prename descclassname"><span class="pre">k2.</span></span><span class="sig-name descname"><span class="pre">compose</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">a_fsa</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">b_fsa</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">treat_epsilons_specially</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inner_labels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/k2-fsa/k2/blob/master/k2/python/k2/fsa_algo.py#L290-L373"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#k2.compose" title="Permalink to this definition"></a></dt>
<dd><p>Compute the composition of two FSAs.</p>
<p>When <cite>treat_epsilons_specially</cite> is True, this function works only on CPU.
When <cite>treat_epsilons_specially</cite> is False and both <cite>a_fsa</cite> and <cite>b_fsa</cite>
are on GPU, then this function works on GPU; in this case, the two
input FSAs do not need to be arc sorted.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><cite>a_fsa.aux_labels</cite> is required to be defined and it can be either
a <cite>torch.Tensor</cite> or a ragged tensor of type <cite>k2.RaggedTensor</cite>.
If it is a ragged tensor, then it requires that a_fsa.requires_grad is
False.</p>
<p>For both FSAs, the <cite>aux_labels</cite> attribute is interpreted as output labels,
(olabels), and the composition involves matching the olabels of a_fsa with
the ilabels of b_fsa.  This is implemented by intersecting the inverse of
a_fsa (a_fsa_inv) with b_fsa, then replacing the ilabels of the result
with the original ilabels on a_fsa which are now the aux_labels of
a_fsa_inv.  If <cite>b_fsa.aux_labels</cite> is not defined, <cite>b_fsa</cite> is treated as an
acceptor (as in OpenFST), i.e. its olabels and ilabels are assumed to be
the same.</p>
</div>
<p>Refer to <a class="reference internal" href="#k2.intersect" title="k2.intersect"><code class="xref py py-func docutils literal notranslate"><span class="pre">k2.intersect()</span></code></a> for how we assign the attributes of the
output FSA.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a_fsa</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Fsa</span></code>) – The first input FSA. It can be either a single FSA or an FsaVec.</p></li>
<li><p><strong>b_fsa</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Fsa</span></code>) – The second input FSA. it can be either a single FSA or an FsaVec.</p></li>
<li><p><strong>treat_epsilons_specially</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – If True, epsilons will be treated as epsilon, meaning epsilon arcs can
match with an implicit epsilon self-loop.
If False, epsilons will be treated as real, normal symbols (to have
them treated as epsilons in this case you may have to add epsilon
self-loops to whichever of the inputs is naturally epsilon-free).</p></li>
<li><p><strong>inner_labels</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>]) – If specified (and if a_fsa has <cite>aux_labels</cite>), the labels that we matched
on, which would normally be discarded, will instead be copied to
this attribute name.</p></li>
</ul>
</dd>
</dl>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p><cite>b_fsa</cite> has to be arc sorted if the function runs on CPU.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Fsa</span></code></p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The result of composing a_fsa and b_fsa. <cite>len(out_fsa.shape)</cite> is 2
if and only if the two input FSAs are single FSAs;
otherwise, <cite>len(out_fsa.shape)</cite> is 3.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="compose-arc-maps">
<h2>compose_arc_maps<a class="headerlink" href="#compose-arc-maps" title="Permalink to this headline"></a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="k2.compose_arc_maps">
<span class="sig-prename descclassname"><span class="pre">k2.</span></span><span class="sig-name descname"><span class="pre">compose_arc_maps</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">step1_arc_map</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">step2_arc_map</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/k2-fsa/k2/blob/master/k2/python/k2/ops.py#L248-L276"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#k2.compose_arc_maps" title="Permalink to this definition"></a></dt>
<dd><p>Compose arc maps from two Fsa operations.</p>
<p>It implements:</p>
<blockquote>
<div><ul class="simple">
<li><p>ans_arc_map[i] = step1_arc_map[step2_arc_map[i]] if
step2_arc_map[i] is not -1</p></li>
<li><p>ans_arc_map[i] = -1 if step2_arc_map[i] is -1</p></li>
</ul>
</div></blockquote>
<p>for i in 0 to <cite>step2_arc_map.numel() - 1</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>step1_arc_map</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – A 1-D tensor with dtype torch.int32 from the first Fsa operation.</p></li>
<li><p><strong>step2_arc_map</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – A 1-D tensor with dtype torch.int32 from the second Fsa operation.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Return a 1-D tensor with dtype torch.int32. It has the same number
of elements as step2_arc_map. That is,
ans_arc_map.shape == step2_arc_map.shape.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="connect">
<h2>connect<a class="headerlink" href="#connect" title="Permalink to this headline"></a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="k2.connect">
<span class="sig-prename descclassname"><span class="pre">k2.</span></span><span class="sig-name descname"><span class="pre">connect</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fsa</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/k2-fsa/k2/blob/master/k2/python/k2/fsa_algo.py#L376-L403"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#k2.connect" title="Permalink to this definition"></a></dt>
<dd><p>Connect an FSA.</p>
<p>Removes states that are neither accessible nor co-accessible.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>A state is not accessible if it is not reachable from the start state.
A state is not co-accessible if it cannot reach the final state.</p>
</div>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>If the input FSA is already connected, it is returned directly.
Otherwise, a new connected FSA is returned.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>fsa</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Fsa</span></code>) – The input FSA to be connected.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Fsa</span></code></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>An FSA that is connected.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="convert-dense-to-fsa-vec">
<h2>convert_dense_to_fsa_vec<a class="headerlink" href="#convert-dense-to-fsa-vec" title="Permalink to this headline"></a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="k2.convert_dense_to_fsa_vec">
<span class="sig-prename descclassname"><span class="pre">k2.</span></span><span class="sig-name descname"><span class="pre">convert_dense_to_fsa_vec</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dense_fsa_vec</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/k2-fsa/k2/blob/master/k2/python/k2/dense_fsa_vec.py#L231-L246"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#k2.convert_dense_to_fsa_vec" title="Permalink to this definition"></a></dt>
<dd><p>Convert a DenseFsaVec to an FsaVec.</p>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>Intended for use in testing/debug mode only. This operation is NOT
differentiable.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>dense_fsa_vec</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">DenseFsaVec</span></code>) – DenseFsaVec to convert.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Fsa</span></code></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>The converted FsaVec .</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="create-fsa-vec">
<h2>create_fsa_vec<a class="headerlink" href="#create-fsa-vec" title="Permalink to this headline"></a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="k2.create_fsa_vec">
<span class="sig-prename descclassname"><span class="pre">k2.</span></span><span class="sig-name descname"><span class="pre">create_fsa_vec</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fsas</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/k2-fsa/k2/blob/master/k2/python/k2/utils.py#L250-L306"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#k2.create_fsa_vec" title="Permalink to this definition"></a></dt>
<dd><p>Create an FsaVec from a list of FSAs</p>
<p>We use the following rules to set the attributes of the output FsaVec:</p>
<ul class="simple">
<li><p>For tensor attributes, we assume that all input FSAs have the same
attribute name and the values are concatenated.</p></li>
<li><p>For non-tensor attributes, if any two of the input FSAs have the same
attribute name, then we assume that their attribute values are equal and
the output FSA will inherit the attribute.</p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>fsas</strong> – A list of <cite>Fsa</cite>. Each element must be a single FSA.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>An instance of <code class="xref py py-class docutils literal notranslate"><span class="pre">Fsa</span></code> that represents a FsaVec.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="create-sparse">
<h2>create_sparse<a class="headerlink" href="#create-sparse" title="Permalink to this headline"></a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="k2.create_sparse">
<span class="sig-prename descclassname"><span class="pre">k2.</span></span><span class="sig-name descname"><span class="pre">create_sparse</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">rows</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cols</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">values</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_col_index</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/k2-fsa/k2/blob/master/k2/python/k2/utils.py#L361-L420"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#k2.create_sparse" title="Permalink to this definition"></a></dt>
<dd><p>This is a utility function that creates a (torch) sparse matrix likely
intended to represent posteriors.  The likely usage is something like
(for example):</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">post</span> <span class="o">=</span> <span class="n">k2</span><span class="o">.</span><span class="n">create_sparse</span><span class="p">(</span><span class="n">fsa</span><span class="o">.</span><span class="n">seqframe</span><span class="p">,</span> <span class="n">fsa</span><span class="o">.</span><span class="n">phones</span><span class="p">,</span>
                        <span class="n">fsa</span><span class="o">.</span><span class="n">get_arc_post</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">exp</span><span class="p">(),</span>
                        <span class="n">min_col_index</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
<p>(assuming <cite>seqframe</cite> and <cite>phones</cite> were integer-valued attributes of <cite>fsa</cite>).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>rows</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – Row indexes of the sparse matrix (a torch.Tensor), which must have
values &gt;= 0; likely <cite>fsa.seqframe</cite>.   Must have row_indexes.dim == 1.
Will be converted to <cite>dtype=torch.long</cite></p></li>
<li><p><strong>cols</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – Column indexes of the sparse matrix, with the same shape as <cite>rows</cite>.
Will be converted to <cite>dtype=torch.long</cite></p></li>
<li><p><strong>values</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – Values of the sparse matrix, likely of dtype float or double, with
the same shape as <cite>rows</cite> and <cite>cols</cite>.</p></li>
<li><p><strong>size</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>]]) – Optional. If not None, it is assumed to be a tuple containing
<cite>(num_frames, highest_phone_plus_one)</cite></p></li>
<li><p><strong>min_col_index</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>]) – If provided, before the sparse tensor is constructed we will filter out
elements with <cite>cols[i] &lt; min_col_index</cite>.  Will likely be 0 or 1, if
set.  This is necessary if <cite>col_indexes</cite> may have values less than 0,
or if you want to filter out 0 values (e.g. as representing blanks).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Returns a torch.Tensor that is sparse with coo (coordinate) format,
i.e. <cite>layout=torch.sparse_coo</cite> (which is actually the only sparse format
that torch currently supports).</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="ctc-graph">
<h2>ctc_graph<a class="headerlink" href="#ctc-graph" title="Permalink to this headline"></a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="k2.ctc_graph">
<span class="sig-prename descclassname"><span class="pre">k2.</span></span><span class="sig-name descname"><span class="pre">ctc_graph</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">symbols</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">modified</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'cpu'</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/k2-fsa/k2/blob/master/k2/python/k2/fsa_algo.py#L984-L1020"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#k2.ctc_graph" title="Permalink to this definition"></a></dt>
<dd><p>Construct ctc graphs from symbols.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The scores of arcs in the returned FSA are all 0.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>symbols</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>]], <code class="xref py py-class docutils literal notranslate"><span class="pre">RaggedTensor</span></code>]) – <p>It can be one of the following types:</p>
<blockquote>
<div><ul>
<li><p>A list of list-of-integers, e..g, <cite>[ [1, 2], [1, 2, 3] ]</cite></p></li>
<li><p>An instance of <code class="xref py py-class docutils literal notranslate"><span class="pre">k2.RaggedTensor</span></code>.
Must have <cite>num_axes == 2</cite>.</p></li>
</ul>
</div></blockquote>
</p></li>
<li><p><strong>standard</strong> – Option to specify the type of CTC topology: “standard” or “simplified”,
where the “standard” one makes the blank mandatory between a pair of
identical symbols. Default True.</p></li>
<li><p><strong>device</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">device</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – Optional. It can be either a string (e.g., ‘cpu’, ‘cuda:0’) or a
torch.device.
By default, the returned FSA is on CPU.
If <cite>symbols</cite> is an instance of <code class="xref py py-class docutils literal notranslate"><span class="pre">k2.RaggedTensor</span></code>, the returned
FSA will on the same device as <cite>k2.RaggedTensor</cite>.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Fsa</span></code></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>An FsaVec containing the returned ctc graphs, with “Dim0()” the same as
“len(symbols)”(List[List[int]]) or “dim0”(k2.RaggedTensor)</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="ctc-loss">
<h2>ctc_loss<a class="headerlink" href="#ctc-loss" title="Permalink to this headline"></a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="k2.ctc_loss">
<span class="sig-prename descclassname"><span class="pre">k2.</span></span><span class="sig-name descname"><span class="pre">ctc_loss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">decoding_graph</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dense_fsa_vec</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_beam</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reduction</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'sum'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_double_scores</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_lengths</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/k2-fsa/k2/blob/master/k2/python/k2/ctc_loss.py#L98-L136"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#k2.ctc_loss" title="Permalink to this definition"></a></dt>
<dd><p>Compute the CTC loss given a decoding graph and a dense fsa vector.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>decoding_graph</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Fsa</span></code>) – An FsaVec. It can be the composition result of a ctc topology
and a transcript.</p></li>
<li><p><strong>dense_fsa_vec</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">DenseFsaVec</span></code>) – It represents the neural network output. Refer to the help information
in <code class="xref py py-class docutils literal notranslate"><span class="pre">k2.DenseFsaVec</span></code>.</p></li>
<li><p><strong>output_beam</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>) – Beam to prune output, similar to lattice-beam in Kaldi.  Relative
to best path of output.</p></li>
<li><p><strong>reduction</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Literal</span></code>[‘none’, ‘mean’, ‘sum’]) – Specifies the reduction to apply to the output: ‘none’ | ‘mean’ | ‘sum’.
‘none’: no reduction will be applied, ‘mean’: the output losses will be
divided by the target lengths and then the mean over the batch is taken.
‘sum’: sum the output losses over batches.</p></li>
<li><p><strong>use_double_scores</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – True to use double precision floating point in computing
the total scores. False to use single precision.</p></li>
<li><p><strong>target_lengths</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>]) – Used only when <cite>reduction</cite> is <cite>mean</cite>. It is a 1-D tensor of batch
size representing lengths of the targets, e.g., number of phones or
number of word pieces in a sentence.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>If <cite>reduction</cite> is <cite>none</cite>, return a 1-D tensor with size equal to batch
size. If <cite>reduction</cite> is <cite>mean</cite> or <cite>sum</cite>, return a scalar.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="ctc-topo">
<h2>ctc_topo<a class="headerlink" href="#ctc-topo" title="Permalink to this headline"></a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="k2.ctc_topo">
<span class="sig-prename descclassname"><span class="pre">k2.</span></span><span class="sig-name descname"><span class="pre">ctc_topo</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">max_token</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">modified</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/k2-fsa/k2/blob/master/k2/python/k2/fsa_algo.py#L1023-L1060"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#k2.ctc_topo" title="Permalink to this definition"></a></dt>
<dd><p>Create a CTC topology.</p>
<p>A token which appears once on the right side (i.e. olabels) may
appear multiple times on the left side (ilabels), possibly with
epsilons in between.
When 0 appears on the left side, it represents the blank symbol;
when it appears on the right side, it indicates an epsilon. That
is, 0 has two meanings here.</p>
<p>A standard CTC topology is the conventional one, where there
is a mandatory blank between two repeated neighboring symbols.
A non-standard, i.e., modified CTC topology, imposes no such constraint.</p>
<p>See <a class="reference external" href="https://github.com/k2-fsa/k2/issues/746#issuecomment-856421616">https://github.com/k2-fsa/k2/issues/746#issuecomment-856421616</a>
and <a class="reference external" href="https://github.com/k2-fsa/snowfall/pull/209">https://github.com/k2-fsa/snowfall/pull/209</a>
for more details.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>max_token</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – The maximum token ID (inclusive). We assume that token IDs
are contiguous (from 1 to <cite>max_token</cite>). 0 represents blank.</p></li>
<li><p><strong>modified</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – If False, create a standard CTC topology. Otherwise, create a
modified CTC topology.</p></li>
<li><p><strong>device</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">device</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – Optional. It can be either a string (e.g., ‘cpu’,
‘cuda:0’) or a torch.device.
If it is None, then the returned FSA is on CPU.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Fsa</span></code></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Return either a standard or a modified CTC topology as an FSA
depending on whether <cite>standard</cite> is True or False.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="determinize">
<h2>determinize<a class="headerlink" href="#determinize" title="Permalink to this headline"></a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="k2.determinize">
<span class="sig-prename descclassname"><span class="pre">k2.</span></span><span class="sig-name descname"><span class="pre">determinize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="pre">fsa</span></em>, <em class="sig-param"><span class="pre">weight_pushing_type=&lt;DeterminizeWeightPushingType.kNoWeightPushing:</span> <span class="pre">2&gt;</span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/k2-fsa/k2/blob/master/k2/python/k2/fsa_algo.py#L602-L650"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#k2.determinize" title="Permalink to this definition"></a></dt>
<dd><p>Determinize the input Fsa.</p>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<ul class="simple">
<li><p>It only works on for CPU.</p></li>
<li><p>Any weight_pushing_type value other than kNoWeightPushing causes
the ‘arc_derivs’ to not accurately reflect the real derivatives,
although this will not matter as long as the derivatives ultimately
derive from FSA operations such as getting total scores or
arc posteriors, which are insensitive to pushing.</p></li>
</ul>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>fsa</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Fsa</span></code>) – The input FSA. It can be either a single FSA or an FsaVec.
Must be connected. It’s also expected to be epsilon-free,
but this is not checked; in any case,
epsilon will be treated as a normal symbol.</p></li>
<li><p><strong>weight_pushing_type</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">DeterminizeWeightPushingType</span></code>) – <p>An enum value that determines what kind of weight pushing is desired,
default kNoWeightPushing.</p>
<blockquote>
<div><dl class="simple">
<dt>kTropicalWeightPushing:</dt><dd><p>use tropical semiring (actually, max on scores) for weight pushing.</p>
</dd>
<dt>kLogWeightPushing:</dt><dd><p>use log semiring (actually, log-sum on score) for weight pushing</p>
</dd>
<dt>kNoWeightPushing:</dt><dd><p>do no weight pushing; this will cause some delay in scores being
emitted, and the weights created in this way will correspond
exactly to those that would be produced by the arc_derivs.</p>
</dd>
</dl>
</div></blockquote>
<p>For decoding graph creation, we recommend kLogSumWeightPushing.</p>
</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Fsa</span></code></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>The resulting Fsa, it’s equivalent to the input <cite>fsa</cite> under
tropical semiring but will be deterministic.
It will be the same as the input <cite>fsa</cite> if the input
<cite>fsa</cite> has property kFsaPropertiesArcSortedAndDeterministic.
Otherwise, a new deterministic fsa is returned and the
input <cite>fsa</cite> is NOT modified.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="expand-ragged-attributes">
<h2>expand_ragged_attributes<a class="headerlink" href="#expand-ragged-attributes" title="Permalink to this headline"></a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="k2.expand_ragged_attributes">
<span class="sig-prename descclassname"><span class="pre">k2.</span></span><span class="sig-name descname"><span class="pre">expand_ragged_attributes</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fsas</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ret_arc_map</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ragged_attribute_names</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/k2-fsa/k2/blob/master/k2/python/k2/fsa_algo.py#L834-L932"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#k2.expand_ragged_attributes" title="Permalink to this definition"></a></dt>
<dd><p>Turn ragged labels attached to this FSA into linear (Tensor) labels,
expanding arcs into sequences of arcs as necessary to achieve this.
Supports autograd.  If <cite>fsas</cite> had no ragged attributes, returns <cite>fsas</cite>
itself.</p>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>This function will ensure that for final-arcs in the returned
fsa, the corresponding labels for all ragged attributes are -1; it will
add an extra arc at the end if necessary to ensure this, if the
original ragged attributes did not have -1 as their final element on
final-arcs (note: our intention is that -1’s on final arcs, like filler
symbols, are removed when making attributes ragged; this is what
fsa_from_unary_function_ragged() does if remove_filler==True (the
default).</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>fsas</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Fsa</span></code>) – The source Fsa</p></li>
<li><p><strong>ret_arc_map</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – If true, will return a pair (new_fsas, arc_map)
with <cite>arc_map</cite> a tensor of int32 that maps from arcs in the
result to arcs in <cite>fsas</cite>, with -1’s for newly created arcs.
If false, just returns new_fsas.</p></li>
<li><p><strong>ragged_attribute_names</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>]]) – If specified, just this list of ragged
attributes will be expanded to linear tensor attributes, and
the rest will stay ragged.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Fsa</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Fsa</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>]]</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="get-best-matching-stats">
<h2>get_best_matching_stats<a class="headerlink" href="#get-best-matching-stats" title="Permalink to this headline"></a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="k2.get_best_matching_stats">
<span class="sig-prename descclassname"><span class="pre">k2.</span></span><span class="sig-name descname"><span class="pre">get_best_matching_stats</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tokens</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scores</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">counts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eos</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_token</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_token</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_order</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/k2-fsa/k2/blob/master/k2/python/k2/utils.py#L696-L783"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#k2.get_best_matching_stats" title="Permalink to this definition"></a></dt>
<dd><p>For “query” sentences, this function gets the mean and variance of
scores from the best matching words-in-context in a set of provided “key”
sentences. This matching process matches the word and the words preceding
it, looking for the highest-order match it can find (it’s intended for
approximating the scores of models that see only left-context,
like language models). The intended application is in estimating the scores
of hypothesized transcripts, when we have actually computed the scores for
only a subset of the hypotheses.</p>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>This function only runs on CPU for now.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>tokens</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">RaggedTensor</span></code>) – <p>A ragged tensor of int32_t with 2 or 3 axes. If 2 axes, this represents
a collection of key and query sequences. If 3 axes, this represents a
set of such collections.</p>
<blockquote>
<div><dl class="simple">
<dt>2-axis example:</dt><dd><p>[ [ the, cat, said, eos ], [ the, cat, fed, eos ] ]</p>
</dd>
<dt>3-axis example:</dt><dd><dl class="simple">
<dt>[ [ [ the, cat, said, eos ], [ the, cat, fed, eos ] ],</dt><dd><p>[ [ hi, my, name, is, eos ], [ bye, my, name, is, eos ] ], … ]</p>
</dd>
</dl>
</dd>
</dl>
</div></blockquote>
<p>where the words would actually be represented as integers,
The eos symbol is required if this code is to work as intended
(otherwise this code will not be able to recognize when we have reached
the beginnings of sentences when comparing histories).
bos symbols are allowed but not required.</p>
</p></li>
<li><p><strong>scores</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – A one dim torch.tensor with scores.size() == tokens.NumElements(),
this is the item for which we are requesting best-matching values
(as means and variances in case there are multiple best matches).
In our anticipated use, these would represent scores of words in the
sentences, but they could represent anything.</p></li>
<li><p><strong>counts</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – An one dim torch.tensor with counts.size() == tokens.NumElements(),
containing 1 for words that are considered “keys” and 0 for
words that are considered “queries”.  Typically some entire
sentences will be keys and others will be queries.</p></li>
<li><p><strong>eos</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – The value of the eos (end of sentence) symbol; internally, this
is used as an extra padding value before the first sentence in each
collection, so that it can act like a “bos” symbol.</p></li>
<li><p><strong>min_token</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – The lowest possible token value, including the bos
symbol (e.g., might be -1).</p></li>
<li><p><strong>max_token</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – The maximum possible token value.  Be careful not to
set this too large the implementation contains a part which
takes time and space O(max_token - min_token).</p></li>
<li><p><strong>max_order</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – The maximum n-gram order to ever return in the
<cite>ngram_order</cite> output; the output will be the minimum of max_order
and the actual order matched; or max_order if we matched all the
way to the beginning of both sentences. The main reason this is
needed is that we need a finite number to return at the
beginning of sentences.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>]</p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><dl class="simple">
<dt>Returns a tuple of four torch.tensor (mean, var, counts_out, ngram_order)</dt><dd><dl class="simple">
<dt>mean:</dt><dd><p>For query positions, will contain the mean of the scores at the
best matching key positions, or zero if that is undefined because
there are no key positions at all.  For key positions,
you can treat the output as being undefined (actually they
are treated the same as queries, but won’t match with only
themselves because we don’t match at singleton intervals).</p>
</dd>
<dt>var:</dt><dd><p>Like <cite>mean</cite>, but contains the (centered) variance
of the best matching positions.</p>
</dd>
<dt>counts_out:</dt><dd><p>The number of key positions that contributed to the <cite>mean</cite>
and <cite>var</cite> statistics.  This should only be zero if <cite>counts</cite>
was all zero.</p>
</dd>
<dt>ngram_order:</dt><dd><p>The n-gram order corresponding to the best matching
positions found at each query position, up to a maximum of
<cite>max_order</cite>; will be <cite>max_order</cite> if we matched all
the way to the beginning of a sentence.</p>
</dd>
</dl>
</dd>
</dl>
</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="index-add">
<h2>index_add<a class="headerlink" href="#index-add" title="Permalink to this headline"></a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="k2.index_add">
<span class="sig-prename descclassname"><span class="pre">k2.</span></span><span class="sig-name descname"><span class="pre">index_add</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">index</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">value</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">in_out</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/k2-fsa/k2/blob/master/k2/python/k2/ops.py#L121-L156"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#k2.index_add" title="Permalink to this definition"></a></dt>
<dd><p>It implements in_out[index[i]] += value[i].</p>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>It has similar semantics with <cite>torch.Tensor.index_add_</cite> except
that:</p>
<blockquote>
<div><ul class="simple">
<li><p><cite>index.dtype == torch.int32</cite></p></li>
<li><p><cite>-1 &lt;= index[i] &lt; in_out.shape[0]</cite></p></li>
<li><p><cite>index[i] == -1</cite> is ignored.</p></li>
<li><p><cite>index</cite> has to be a 1-D <strong>contiguous</strong> tensor.</p></li>
</ul>
</div></blockquote>
</div>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p><cite>in_out</cite> is modified <strong>in-place</strong>.</p>
</div>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>This functions does NOT support autograd.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>index</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – A 1-D <strong>contiguous</strong> tensor with dtype <cite>torch.int32</cite>.
Must satisfy <cite>-1 &lt;= index[i] &lt; in_out.shape[0]</cite></p></li>
<li><p><strong>value</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – A 1-D or 2-D tensor with dtype <cite>torch.int32</cite>, <cite>torch.float32</cite>,
or <cite>torch.float64</cite>.
Must satisfy <cite>index.shape[0] == value.shape[0]</cite></p></li>
<li><p><strong>in_out</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – A 1-D or 2-D tensor with the same dtype as <cite>value</cite>. It satisfies
<cite>in_out.shape[1] == value.shape[1]</cite> if it is a 2-D tensor.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Return None.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="index-fsa">
<h2>index_fsa<a class="headerlink" href="#index-fsa" title="Permalink to this headline"></a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="k2.index_fsa">
<span class="sig-prename descclassname"><span class="pre">k2.</span></span><span class="sig-name descname"><span class="pre">index_fsa</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">src</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">indexes</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/k2-fsa/k2/blob/master/k2/python/k2/ops.py#L159-L195"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#k2.index_fsa" title="Permalink to this definition"></a></dt>
<dd><p>Select a list of FSAs from <cite>src</cite> with a 1-D tensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>src</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Fsa</span></code>) – An FsaVec.</p></li>
<li><p><strong>indexes</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – A 1-D <cite>torch.Tensor</cite> of dtype <cite>torch.int32</cite> containing
the ids of FSAs to select.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Fsa</span></code></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Return an FsaVec containing only those FSAs specified by <cite>indexes</cite>.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="index-select">
<h2>index_select<a class="headerlink" href="#index-select" title="Permalink to this headline"></a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="k2.index_select">
<span class="sig-prename descclassname"><span class="pre">k2.</span></span><span class="sig-name descname"><span class="pre">index_select</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">src</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">index</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">default_value</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/k2-fsa/k2/blob/master/k2/python/k2/ops.py#L83-L118"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#k2.index_select" title="Permalink to this definition"></a></dt>
<dd><p>Returns a new tensor which indexes the input tensor along dimension 0
using the entries in <cite>index</cite>.</p>
<p>If the entry in <cite>index</cite> is -1, then the corresponding entry in the
returned tensor is 0.</p>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p><cite>index.dtype == torch.int32</cite> and <cite>index.ndim == 1</cite>.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>src</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – The input tensor. Either 1-D or 2-D with dtype <cite>torch.int32</cite>,
<cite>torch.int64</cite>, <cite>torch.float32</cite>, or <cite>torch.float64</cite>.</p></li>
<li><p><strong>index</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – 1-D tensor of dtype <cite>torch.int32</cite> containing the indexes.
If an entry is -1, the corresponding entry in the returned value
is 0. The elements of <cite>index</cite> should be in the range
<cite>[-1..src.shape[0]-1]</cite>.</p></li>
<li><p><strong>default_value</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>) – Used only when <cite>src</cite> is a 1-D tensor. It sets ans[i] to default_value
if index[i] is -1.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A tensor with shape <code class="docutils literal notranslate"><span class="pre">(index.numel(),</span> <span class="pre">*src.shape[1:])</span></code> and dtype the
same as <cite>src</cite>, e.g. if <cite>src.ndim == 1</cite>, <cite>ans.shape</cite> would be
<cite>(index.shape[0],)</cite>; if <cite>src.ndim == 2</cite>, <cite>ans.shape</cite> would be
<cite>(index.shape[0], src.shape[1])</cite>.
Will satisfy <cite>ans[i] == src[index[i]]</cite> if <cite>src.ndim == 1</cite>,
or <cite>ans[i, j] == src[index[i], j]</cite> if <cite>src.ndim == 2</cite>, except for
entries where <cite>index[i] == -1</cite> which will be zero.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="intersect">
<h2>intersect<a class="headerlink" href="#intersect" title="Permalink to this headline"></a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="k2.intersect">
<span class="sig-prename descclassname"><span class="pre">k2.</span></span><span class="sig-name descname"><span class="pre">intersect</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">a_fsa</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">b_fsa</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">treat_epsilons_specially</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ret_arc_maps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/k2-fsa/k2/blob/master/k2/python/k2/fsa_algo.py#L205-L287"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#k2.intersect" title="Permalink to this definition"></a></dt>
<dd><p>Compute the intersection of two FSAs.</p>
<p>When <cite>treat_epsilons_specially</cite> is True, this function works only on CPU.
When <cite>treat_epsilons_specially</cite> is False and both <cite>a_fsa</cite> and <cite>b_fsa</cite>
are on GPU, then this function works on GPU; in this case, the two
input FSAs do not need to be arc sorted.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a_fsa</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Fsa</span></code>) – The first input FSA. It can be either a single FSA or an FsaVec.</p></li>
<li><p><strong>b_fsa</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Fsa</span></code>) – The second input FSA. it can be either a single FSA or an FsaVec.
If both a_fsa and b_fsa are FsaVec, they must contain the same
number of FSAs.</p></li>
<li><p><strong>treat_epsilons_specially</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – If True, epsilons will be treated as epsilon, meaning epsilon arcs can
match with an implicit epsilon self-loop.
If False, epsilons will be treated as real, normal symbols (to have
them treated as epsilons in this case you may have to add epsilon
self-loops to whichever of the inputs is naturally epsilon-free).</p></li>
<li><p><strong>ret_arc_maps</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – <p>If False, return the resulting Fsa. If True, return a tuple
containing three entries:</p>
<blockquote>
<div><ul>
<li><p>the resulting Fsa</p></li>
<li><p>a_arc_map, a 1-D torch.Tensor with dtype torch.int32.
a_arc_map[i] is the arc index in a_fsa that corresponds
to the i-th arc in the resulting Fsa. a_arc_map[i] is -1
if the i-th arc in the resulting Fsa has no corresponding
arc in a_fsa.</p></li>
<li><p>b_arc_map, a 1-D torch.Tensor with dtype torch.int32.
b_arc_map[i] is the arc index in b_fsa that corresponds
to the i-th arc in the resulting Fsa. b_arc_map[i] is -1
if the i-th arc in the resulting Fsa has no corresponding
arc in b_fsa.</p></li>
</ul>
</div></blockquote>
</p></li>
</ul>
</dd>
</dl>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>The two input FSAs MUST be arc sorted if <cite>treat_epsilons_specially</cite>
is True.</p>
</div>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>The rules for assigning the attributes of the output Fsa are as follows:</p>
<ul class="simple">
<li><p>(1) For attributes where only one source (a_fsa or b_fsa) has that
attribute: Copy via arc_map, or use zero if arc_map has -1. This rule
works for both floating point and integer attributes.</p></li>
<li><p>(2) For attributes where both sources (a_fsa and b_fsa) have that
attribute: For floating point attributes: sum via arc_maps, or use zero
if arc_map has -1. For integer attributes, it’s not supported for now
(the attributes will be discarded and will not be kept in the output
FSA).</p></li>
</ul>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Fsa</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Fsa</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>]]</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>If ret_arc_maps is False, return the result of intersecting a_fsa and
b_fsa. len(out_fsa.shape) is 2 if and only if the two input FSAs are
single FSAs; otherwise, len(out_fsa.shape) is 3.
If ret_arc_maps is True, it returns additionally two arc_maps:
a_arc_map and b_arc_map.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="intersect-dense">
<h2>intersect_dense<a class="headerlink" href="#intersect-dense" title="Permalink to this headline"></a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="k2.intersect_dense">
<span class="sig-prename descclassname"><span class="pre">k2.</span></span><span class="sig-name descname"><span class="pre">intersect_dense</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">a_fsas</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">b_fsas</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_beam</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_states</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">15000000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_arcs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1073741824</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">a_to_b_map</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seqframe_idx_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">frame_idx_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/k2-fsa/k2/blob/master/k2/python/k2/autograd.py#L772-L845"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#k2.intersect_dense" title="Permalink to this definition"></a></dt>
<dd><p>Intersect array of FSAs on CPU/GPU.</p>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p><cite>a_fsas</cite> MUST be arc sorted.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a_fsas</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Fsa</span></code>) – Input FsaVec, i.e., <cite>decoding graphs</cite>, one per sequence. It might just
be a linear sequence of phones, or might be something more complicated.
Must have <cite>a_fsas.shape[0] == b_fsas.dim0()</cite> if <cite>a_to_b_map</cite> is None.
Otherwise, must have <cite>a_fsas.shape[0] == a_to_b_map.shape[0]</cite></p></li>
<li><p><strong>b_fsas</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">DenseFsaVec</span></code>) – Input FSAs that correspond to neural network output.</p></li>
<li><p><strong>output_beam</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>) – Beam to prune output, similar to lattice-beam in Kaldi.  Relative
to best path of output.</p></li>
<li><p><strong>max_states</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – The max number of states to prune the output, mainly to avoid
out-of-memory and numerical overflow, default 15,000,000.</p></li>
<li><p><strong>max_arcs</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – The max number of arcs to prune the output, mainly to avoid
out-of-memory and numerical overflow, default 1073741824(2^30).</p></li>
<li><p><strong>a_to_b_map</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>]) – Maps from FSA-index in a to FSA-index in b to use for it.
If None, then we expect the number of FSAs in a_fsas to equal
b_fsas.dim0().  If set, then it should be a Tensor with ndim=1
and dtype=torch.int32, with a_to_b_map.shape[0] equal to the
number of FSAs in a_fsas (i.e. a_fsas.shape[0] if
len(a_fsas.shape) == 3, else 1); and elements 0 &lt;= i &lt; b_fsas.dim0().</p></li>
<li><p><strong>seqframe_idx_name</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>]) – If set (e.g. to ‘seqframe’), an attribute in the output will be created
that encodes the sequence-index and the frame-index within that
sequence; this is equivalent to a row-index into b_fsas.values,
or, equivalently, an element in b_fsas.shape.</p></li>
<li><p><strong>frame_idx_name</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>]) – If set (e.g. to ‘frame’, an attribute in the output will be created
that contains the frame-index within the corresponding sequence.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Fsa</span></code></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>The result of the intersection (pruned to <cite>output_beam</cite>; this pruning
is exact, it uses forward and backward scores.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="intersect-dense-pruned">
<h2>intersect_dense_pruned<a class="headerlink" href="#intersect-dense-pruned" title="Permalink to this headline"></a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="k2.intersect_dense_pruned">
<span class="sig-prename descclassname"><span class="pre">k2.</span></span><span class="sig-name descname"><span class="pre">intersect_dense_pruned</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">a_fsas</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">b_fsas</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">search_beam</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_beam</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_active_states</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_active_states</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seqframe_idx_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">frame_idx_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/k2-fsa/k2/blob/master/k2/python/k2/autograd.py#L695-L769"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#k2.intersect_dense_pruned" title="Permalink to this definition"></a></dt>
<dd><p>Intersect array of FSAs on CPU/GPU.</p>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p><cite>a_fsas</cite> MUST be arc sorted.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a_fsas</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Fsa</span></code>) – Input FsaVec, i.e., <cite>decoding graphs</cite>, one per sequence. It might just
be a linear sequence of phones, or might be something more complicated.
Must have either <cite>a_fsas.shape[0] == b_fsas.dim0()</cite>, or
<cite>a_fsas.shape[0] == 1</cite> in which case the graph is shared.</p></li>
<li><p><strong>b_fsas</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">DenseFsaVec</span></code>) – Input FSAs that correspond to neural network output.</p></li>
<li><p><strong>search_beam</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>) – Decoding beam, e.g. 20.  Smaller is faster, larger is more exact
(less pruning). This is the default value; it may be modified by
<cite>min_active_states</cite> and <cite>max_active_states</cite>.</p></li>
<li><p><strong>output_beam</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>) – Beam to prune output, similar to lattice-beam in Kaldi.  Relative
to best path of output.</p></li>
<li><p><strong>min_active_states</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – Minimum number of FSA states that are allowed to be active on any given
frame for any given intersection/composition task. This is advisory,
in that it will try not to have fewer than this number active.
Set it to zero if there is no constraint.</p></li>
<li><p><strong>max_active_states</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – Maximum number of FSA states that are allowed to be active on any given
frame for any given intersection/composition task. This is advisory,
in that it will try not to exceed that but may not always succeed.
You can use a very large number if no constraint is needed.</p></li>
<li><p><strong>seqframe_idx_name</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>]) – If set (e.g. to ‘seqframe’), an attribute in the output will be created
that encodes the sequence-index and the frame-index within that
sequence; this is equivalent to a row-index into b_fsas.values,
or, equivalently, an element in b_fsas.shape.</p></li>
<li><p><strong>frame_idx_name</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>]) – If set (e.g. to ‘frame’, an attribute in the output will be created
that contains the frame-index within the corresponding sequence.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Fsa</span></code></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>The result of the intersection.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="intersect-device">
<h2>intersect_device<a class="headerlink" href="#intersect-device" title="Permalink to this headline"></a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="k2.intersect_device">
<span class="sig-prename descclassname"><span class="pre">k2.</span></span><span class="sig-name descname"><span class="pre">intersect_device</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">a_fsas</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">b_fsas</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">b_to_a_map</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sorted_match_a</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ret_arc_maps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/k2-fsa/k2/blob/master/k2/python/k2/fsa_algo.py#L124-L202"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#k2.intersect_device" title="Permalink to this definition"></a></dt>
<dd><p>Compute the intersection of two FsaVecs treating epsilons
as real, normal symbols.</p>
<p>This function supports both CPU and GPU. But it is very slow on CPU.
That’s why this function name ends with <cite>_device</cite>. It is intended for GPU.
See <a class="reference internal" href="#k2.intersect" title="k2.intersect"><code class="xref py py-func docutils literal notranslate"><span class="pre">k2.intersect()</span></code></a> which is a more general interface
(it will call the same underlying code, IntersectDevice(), if
the inputs are on GPU and a_fsas is arc-sorted).</p>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>Epsilons are treated as real, normal symbols.</p>
</div>
<div class="admonition hint">
<p class="admonition-title">Hint</p>
<p>The two inputs do not need to be arc-sorted.</p>
</div>
<p>Refer to <a class="reference internal" href="#k2.intersect" title="k2.intersect"><code class="xref py py-func docutils literal notranslate"><span class="pre">k2.intersect()</span></code></a> for how we assign the attributes of the
output FsaVec.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a_fsas</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Fsa</span></code>) – An FsaVec (must have 3 axes, i.e., <cite>len(a_fsas.shape) == 3</cite>.</p></li>
<li><p><strong>b_fsas</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Fsa</span></code>) – An FsaVec (must have 3 axes) on the same device as <cite>a_fsas</cite>.</p></li>
<li><p><strong>b_to_a_map</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – <p>A 1-D torch.Tensor with dtype torch.int32 on the same device
as <cite>a_fsas</cite>. Map from FSA-id in <cite>b_fsas</cite> to the corresponding
FSA-id in <cite>a_fsas</cite> that we want to compose it with.
E.g. might be an identity map, or all-to-zero, or something the
user chooses.</p>
<dl class="simple">
<dt>Requires</dt><dd><ul>
<li><p><cite>b_to_a_map.shape[0] == b_fsas.shape[0]</cite></p></li>
<li><p><cite>0 &lt;= b_to_a_map[i] &lt; a_fsas.shape[0]</cite></p></li>
</ul>
</dd>
</dl>
</p></li>
<li><p><strong>sorted_match_a</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – If true, the arcs of a_fsas must be sorted by label (checked by
calling code via properties), and we’ll use a matching approach
that requires this.</p></li>
<li><p><strong>ret_arc_maps</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – <p>If False, return the resulting Fsa. If True, return a tuple
containing three entries:</p>
<blockquote>
<div><ul>
<li><p>the resulting Fsa</p></li>
<li><p>a_arc_map, a 1-D torch.Tensor with dtype torch.int32.
a_arc_map[i] is the arc index in a_fsas that corresponds
to the i-th arc in the resulting Fsa. a_arc_map[i] is -1
if the i-th arc in the resulting Fsa has no corresponding
arc in a_fsas.</p></li>
<li><p>b_arc_map, a 1-D torch.Tensor with dtype torch.int32.
b_arc_map[i] is the arc index in b_fsas that corresponds
to the i-th arc in the resulting Fsa. b_arc_map[i] is -1
if the i-th arc in the resulting Fsa has no corresponding
arc in b_fsas.</p></li>
</ul>
</div></blockquote>
</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Fsa</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Fsa</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>]]</p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>If ret_arc_maps is False, return intersected FsaVec;
will satisfy <cite>ans.shape == b_fsas.shape</cite>.
If ret_arc_maps is True, it returns additionally two arc maps:
a_arc_map and b_arc_map.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="invert">
<h2>invert<a class="headerlink" href="#invert" title="Permalink to this headline"></a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="k2.invert">
<span class="sig-prename descclassname"><span class="pre">k2.</span></span><span class="sig-name descname"><span class="pre">invert</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fsa</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ret_arc_map</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/k2-fsa/k2/blob/master/k2/python/k2/fsa_algo.py#L711-L746"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#k2.invert" title="Permalink to this definition"></a></dt>
<dd><p>Invert an FST, swapping the labels in the FSA with the auxiliary labels.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>fsa</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Fsa</span></code>) – The input FSA. It can be either a single FSA or an FsaVec.</p></li>
<li><p><strong>ret_arc_map</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – True to return an extra arc map, which is a 1-D tensor with dtype
torch.int32. The returned arc_map[i] is the arc index in the input
fsa that corresponds to the i-th arc in the returned fsa. arc_map[i]
is -1 if the i-th arc in the returned fsa has no counterpart in the
input fsa.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Fsa</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Fsa</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>]]</p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>If ret_arc_map is False, return the inverted Fsa, it’s top-sorted if
<cite>fsa</cite> is top-sorted.
If ret_arc_map is True, return an extra arc map.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="is-rand-equivalent">
<h2>is_rand_equivalent<a class="headerlink" href="#is-rand-equivalent" title="Permalink to this headline"></a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="k2.is_rand_equivalent">
<span class="sig-prename descclassname"><span class="pre">k2.</span></span><span class="sig-name descname"><span class="pre">is_rand_equivalent</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">a</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">b</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log_semiring</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">beam</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">inf</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">treat_epsilons_specially</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">delta</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-06</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">npath</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/k2-fsa/k2/blob/master/k2/python/k2/utils.py#L309-L358"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#k2.is_rand_equivalent" title="Permalink to this definition"></a></dt>
<dd><p>Check if the Fsa <cite>a</cite> appears to be equivalent to <cite>b</cite> by
randomly checking some symbol sequences in them.</p>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>It works only on CPU.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Fsa</span></code>) – One of the input FSA. It can be either a single FSA or an FsaVec.
Must be top-sorted and on CPU.</p></li>
<li><p><strong>b</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Fsa</span></code>) – The other input FSA. It must have the same NumAxes() as a.
Must be top-sorted and on CPU.</p></li>
<li><p><strong>log_semiring</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – The semiring to be used for all weight measurements;
if false then we use ‘max’ on alternative paths; if
true we use ‘log-add’.</p></li>
<li><p><strong>beam</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>) – beam &gt; 0 that affects pruning; the algorithm will only check
paths within <cite>beam</cite> of the total score of the lattice (for
tropical semiring, it’s max weight over all paths from start
state to final state; for log semiring, it’s log-sum probs over
all paths) in <cite>a</cite> or <cite>b</cite>.</p></li>
<li><p><strong>treat_epsilons_specially</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – We’ll do <cite>intersection</cite> between generated path and a or b when
check equivalence. Generally, if it’s true, we will treat
epsilons as epsilon when doing intersection; Otherwise, epsilons
will just be treated as any other symbol.</p></li>
<li><p><strong>delta</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>) – Tolerance for path weights to check the equivalence.
If abs(weights_a, weights_b) &lt;= delta, we say the two
paths are equivalent.</p></li>
<li><p><strong>npath</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – The number of paths will be generated to check the
equivalence of <cite>a</cite> and <cite>b</cite></p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>True if the Fsa <cite>a</cite> appears to be equivalent to <cite>b</cite> by randomly
generating <cite>npath</cite> paths from one of them and then checking if the symbol
sequence exists in the other one and if the total weight for that symbol
sequence is the same in both FSAs.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="levenshtein-alignment">
<h2>levenshtein_alignment<a class="headerlink" href="#levenshtein-alignment" title="Permalink to this headline"></a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="k2.levenshtein_alignment">
<span class="sig-prename descclassname"><span class="pre">k2.</span></span><span class="sig-name descname"><span class="pre">levenshtein_alignment</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">refs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hyps</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hyp_to_ref_map</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sorted_match_ref</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/k2-fsa/k2/blob/master/k2/python/k2/fsa_algo.py#L1108-L1181"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#k2.levenshtein_alignment" title="Permalink to this definition"></a></dt>
<dd><p>Get the levenshtein alignment of two FsaVecs</p>
<p>This function supports both CPU and GPU. But it is very slow on CPU.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>refs</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Fsa</span></code>) – An FsaVec (must have 3 axes, i.e., <cite>len(refs.shape) == 3</cite>. It is the
output Fsa of the <a class="reference internal" href="#k2.levenshtein_graph" title="k2.levenshtein_graph"><code class="xref py py-func docutils literal notranslate"><span class="pre">levenshtein_graph()</span></code></a>.</p></li>
<li><p><strong>hyps</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Fsa</span></code>) – An FsaVec (must have 3 axes) on the same device as <cite>refs</cite>. It is the
output Fsa of the <a class="reference internal" href="#k2.levenshtein_graph" title="k2.levenshtein_graph"><code class="xref py py-func docutils literal notranslate"><span class="pre">levenshtein_graph()</span></code></a>.</p></li>
<li><p><strong>hyp_to_ref_map</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – <p>A 1-D torch.Tensor with dtype torch.int32 on the same device
as <cite>refs</cite>. Map from FSA-id in <cite>hpys</cite> to the corresponding
FSA-id in <cite>refs</cite> that we want to get levenshtein alignment with.
E.g. might be an identity map, or all-to-zero, or something the
user chooses.</p>
<dl class="simple">
<dt>Requires</dt><dd><ul>
<li><p><cite>hyp_to_ref_map.shape[0] == hyps.shape[0]</cite></p></li>
<li><p><cite>0 &lt;= hyp_to_ref_map[i] &lt; refs.shape[0]</cite></p></li>
</ul>
</dd>
</dl>
</p></li>
<li><p><strong>sorted_match_ref</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – If true, the arcs of refs must be sorted by label (checked by
calling code via properties), and we’ll use a matching approach
that requires this.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Fsa</span></code></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Returns an FsaVec containing the alignment information and satisfing
<cite>ans.Dim0() == hyps.Dim0()</cite>. Two attributes named <cite>ref_labels</cite> and
<cite>hyp_labels</cite> will be added to the returned FsaVec. <cite>ref_labels</cite> contains
the aligned sequences of refs and <cite>hyp_labels</cite> contains the aligned
sequences of hyps. You can get the levenshtein distance by calling
<cite>get_tot_scores</cite> on the returned FsaVec.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">hyps</span> <span class="o">=</span> <span class="n">k2</span><span class="o">.</span><span class="n">levenshtein_graph</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">refs</span> <span class="o">=</span> <span class="n">k2</span><span class="o">.</span><span class="n">levenshtein_graph</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">alignment</span> <span class="o">=</span> <span class="n">k2</span><span class="o">.</span><span class="n">levenshtein_alignment</span><span class="p">(</span>
<span class="go">        refs, hyps,</span>
<span class="go">        hyp_to_ref_map=torch.tensor([0, 0], dtype=torch.int32),</span>
<span class="go">        sorted_match_ref=True)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">alignment</span><span class="o">.</span><span class="n">labels</span>
<span class="go">tensor([ 1,  2,  0, -1,  1,  0,  0,  0, -1], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">alignment</span><span class="o">.</span><span class="n">ref_labels</span>
<span class="go">tensor([ 1,  2,  4, -1,  1,  2,  4,  0, -1], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">alignment</span><span class="o">.</span><span class="n">hyp_labels</span>
<span class="go">tensor([ 1,  2,  3, -1,  1,  3,  3,  2, -1], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="o">-</span><span class="n">alignment</span><span class="o">.</span><span class="n">get_tot_scores</span><span class="p">(</span>
<span class="go">        use_double_scores=False, log_semiring=False))</span>
<span class="go">tensor([1., 3.])</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="levenshtein-graph">
<h2>levenshtein_graph<a class="headerlink" href="#levenshtein-graph" title="Permalink to this headline"></a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="k2.levenshtein_graph">
<span class="sig-prename descclassname"><span class="pre">k2.</span></span><span class="sig-name descname"><span class="pre">levenshtein_graph</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">symbols</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ins_del_score</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">-</span> <span class="pre">0.501</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'cpu'</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/k2-fsa/k2/blob/master/k2/python/k2/fsa_algo.py#L1063-L1105"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#k2.levenshtein_graph" title="Permalink to this definition"></a></dt>
<dd><p>Construct levenshtein graphs from symbols.</p>
<p>See <a class="reference external" href="https://github.com/k2-fsa/k2/pull/828">https://github.com/k2-fsa/k2/pull/828</a> for more details about levenshtein
graph.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>symbols</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">RaggedTensor</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>]]]) – <p>It can be one of the following types:</p>
<blockquote>
<div><ul>
<li><p>A list of list-of-integers, e..g, <cite>[ [1, 2], [1, 2, 3] ]</cite></p></li>
<li><p>An instance of <code class="xref py py-class docutils literal notranslate"><span class="pre">k2.RaggedTensor</span></code>.
Must have <cite>num_axes == 2</cite> and with dtype <cite>torch.int32</cite>.</p></li>
</ul>
</div></blockquote>
</p></li>
<li><p><strong>ins_del_score</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>) – The score on the self loops arcs in the graphs, the main idea of this
score is to set insertion and deletion penalty, which will affect the
shortest path searching produre.</p></li>
<li><p><strong>device</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">device</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – Optional. It can be either a string (e.g., ‘cpu’, ‘cuda:0’) or a
torch.device.
By default, the returned FSA is on CPU.
If <cite>symbols</cite> is an instance of <code class="xref py py-class docutils literal notranslate"><span class="pre">k2.RaggedTensor</span></code>, the returned
FSA will on the same device as <cite>k2.RaggedTensor</cite>.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Fsa</span></code></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>An FsaVec containing the returned levenshtein graphs, with “Dim0()”
the same as “len(symbols)”(List[List[int]]) or “dim0”(k2.RaggedTensor).</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="linear-fsa">
<h2>linear_fsa<a class="headerlink" href="#linear-fsa" title="Permalink to this headline"></a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="k2.linear_fsa">
<span class="sig-prename descclassname"><span class="pre">k2.</span></span><span class="sig-name descname"><span class="pre">linear_fsa</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">labels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/k2-fsa/k2/blob/master/k2/python/k2/fsa_algo.py#L37-L68"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#k2.linear_fsa" title="Permalink to this definition"></a></dt>
<dd><p>Construct an linear FSA from labels.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The scores of arcs in the returned FSA are all 0.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>labels</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>], <code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>]], <code class="xref py py-class docutils literal notranslate"><span class="pre">RaggedTensor</span></code>]) – <p>It can be one of the following types:</p>
<blockquote>
<div><ul>
<li><p>A list of integers, e.g., <cite>[1, 2, 3]</cite></p></li>
<li><p>A list of list-of-integers, e..g, <cite>[ [1, 2], [1, 2, 3] ]</cite></p></li>
<li><p>An instance of <code class="xref py py-class docutils literal notranslate"><span class="pre">k2.RaggedTensor</span></code>.
Must have <cite>num_axes == 2</cite>.</p></li>
</ul>
</div></blockquote>
</p></li>
<li><p><strong>device</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">device</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – Optional. It can be either a string (e.g., ‘cpu’, ‘cuda:0’) or a
torch.device.
If it is <code class="docutils literal notranslate"><span class="pre">None</span></code>, then the returned FSA is on CPU. It has to be None
if <code class="docutils literal notranslate"><span class="pre">labels</span></code> is an instance of <code class="xref py py-class docutils literal notranslate"><span class="pre">k2.RaggedTensor</span></code>.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Fsa</span></code></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><ul class="simple">
<li><p>If <code class="docutils literal notranslate"><span class="pre">labels</span></code> is a list of integers, return an FSA</p></li>
<li><p>If <code class="docutils literal notranslate"><span class="pre">labels</span></code> is a list of list-of-integers, return an FsaVec</p></li>
<li><p>If <code class="docutils literal notranslate"><span class="pre">labels</span></code> is an instance of <code class="xref py py-class docutils literal notranslate"><span class="pre">k2.RaggedTensor</span></code>, return
an FsaVec</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="linear-fst">
<h2>linear_fst<a class="headerlink" href="#linear-fst" title="Permalink to this headline"></a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="k2.linear_fst">
<span class="sig-prename descclassname"><span class="pre">k2.</span></span><span class="sig-name descname"><span class="pre">linear_fst</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">labels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">aux_labels</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/k2-fsa/k2/blob/master/k2/python/k2/fsa_algo.py#L71-L100"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#k2.linear_fst" title="Permalink to this definition"></a></dt>
<dd><p>Construct a linear FST from labels and its corresponding
auxiliary labels.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The scores of arcs in the returned FST are all 0.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>labels</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>], <code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>]]]) – A list of integers or a list of list of integers.</p></li>
<li><p><strong>aux_labels</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>], <code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>]]]) – A list of integers or a list of list of integers.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Fsa</span></code></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>An FST if the labels is a list of integers.
A vector of FSTs (FsaVec) if the input is a list of list of integers.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="properties-to-str">
<h2>properties_to_str<a class="headerlink" href="#properties-to-str" title="Permalink to this headline"></a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="k2.properties_to_str">
<span class="sig-prename descclassname"><span class="pre">k2.</span></span><span class="sig-name descname"><span class="pre">properties_to_str</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">p</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/k2-fsa/k2/blob/master/k2/python/k2/fsa_properties.py#L48-L58"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#k2.properties_to_str" title="Permalink to this definition"></a></dt>
<dd><p>Convert properties to a string for debug purpose.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>p</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – An integer returned by <code class="xref py py-func docutils literal notranslate"><span class="pre">get_properties()</span></code>.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A string representation of the input properties.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="prune-on-arc-post">
<h2>prune_on_arc_post<a class="headerlink" href="#prune-on-arc-post" title="Permalink to this headline"></a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="k2.prune_on_arc_post">
<span class="sig-prename descclassname"><span class="pre">k2.</span></span><span class="sig-name descname"><span class="pre">prune_on_arc_post</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fsas</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">threshold_prob</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_double_scores</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/k2-fsa/k2/blob/master/k2/python/k2/fsa_algo.py#L801-L831"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#k2.prune_on_arc_post" title="Permalink to this definition"></a></dt>
<dd><p>Remove arcs whose posteriors are less than the given threshold.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>fsas</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Fsa</span></code>) – An FsaVec. Must have 3 axes.</p></li>
<li><p><strong>threshold_prob</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>) – Arcs whose posteriors are less than this value are removed.
.. note:: 0 &lt; threshold_prob &lt; 1</p></li>
<li><p><strong>use_double_scores</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – True to use double precision during computation; False to use
single precision.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Fsa</span></code></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Return a pruned FsaVec.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="random-fsa">
<h2>random_fsa<a class="headerlink" href="#random-fsa" title="Permalink to this headline"></a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="k2.random_fsa">
<span class="sig-prename descclassname"><span class="pre">k2.</span></span><span class="sig-name descname"><span class="pre">random_fsa</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">acyclic</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_symbol</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">50</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_num_arcs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_num_arcs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1000</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/k2-fsa/k2/blob/master/k2/python/k2/utils.py#L644-L663"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#k2.random_fsa" title="Permalink to this definition"></a></dt>
<dd><p>Generate a random Fsa.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>acyclic</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – If true, generated Fsa will be acyclic.</p></li>
<li><p><strong>max_symbol</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – <dl class="simple">
<dt>Maximum symbol on arcs. Generated arc symbols will be in range</dt><dd><p>[-1,max_symbol], note -1 is kFinalSymbol; must be at least 0;</p>
</dd>
<dt>min_num_arcs:</dt><dd><p>Minimum number of arcs; must be at least 0.</p>
</dd>
<dt>max_num_arcs:</dt><dd><p>Maximum number of arcs; must be &gt;= min_num_arcs.</p>
</dd>
</dl>
</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Fsa</span></code></p>
</dd>
</dl>
</dd></dl>

</section>
<section id="random-fsa-vec">
<h2>random_fsa_vec<a class="headerlink" href="#random-fsa-vec" title="Permalink to this headline"></a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="k2.random_fsa_vec">
<span class="sig-prename descclassname"><span class="pre">k2.</span></span><span class="sig-name descname"><span class="pre">random_fsa_vec</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">min_num_fsas</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_num_fsas</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">acyclic</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_symbol</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">50</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_num_arcs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_num_arcs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1000</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/k2-fsa/k2/blob/master/k2/python/k2/utils.py#L666-L693"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#k2.random_fsa_vec" title="Permalink to this definition"></a></dt>
<dd><p>Generate a random FsaVec.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>min_num_fsas</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – Minimum number of fsas we’ll generated in the returned FsaVec;
must be at least 1.</p></li>
<li><p><strong>max_num_fsas</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – Maximum number of fsas we’ll generated in the returned FsaVec;
must be &gt;= min_num_fsas.</p></li>
<li><p><strong>acyclic</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – If true, generated Fsas will be acyclic.</p></li>
<li><p><strong>max_symbol</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – Maximum symbol on arcs. Generated arcs’ symbols will be in range
[-1,max_symbol], note -1 is kFinalSymbol; must be at least 0;</p></li>
<li><p><strong>min_num_arcs</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – Minimum number of arcs in each Fsa; must be at least 0.</p></li>
<li><p><strong>max_num_arcs</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – Maximum number of arcs in each Fsa; must be &gt;= min_num_arcs.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Fsa</span></code></p>
</dd>
</dl>
</dd></dl>

</section>
<section id="random-paths">
<h2>random_paths<a class="headerlink" href="#random-paths" title="Permalink to this headline"></a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="k2.random_paths">
<span class="sig-prename descclassname"><span class="pre">k2.</span></span><span class="sig-name descname"><span class="pre">random_paths</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fsas</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_double_scores</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_paths</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/k2-fsa/k2/blob/master/k2/python/k2/fsa_algo.py#L749-L798"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#k2.random_paths" title="Permalink to this definition"></a></dt>
<dd><p>Compute pseudo-random paths through the FSAs in this vector of FSAs
(this object must have 3 axes, <cite>self.arcs.num_axes() == 3</cite>)</p>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>It does not support autograd.</p>
</div>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>Do not be confused by the function name. There is no
randomness at all, thus no <cite>seed</cite>. It uses a deterministic algorithm
internally, similar to arithmetic coding
(see <a class="reference external" href="https://en.wikipedia.org/wiki/Arithmetic_coding">https://en.wikipedia.org/wiki/Arithmetic_coding</a>).</p>
<p>Look into the C++ implementation code for more details.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>fsas</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Fsa</span></code>) – A FsaVec, i.e., <cite>len(fsas.shape) == 3</cite></p></li>
<li><p><strong>use_double_scores</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – If true, do computation with double-precision,
else float (single-precision)</p></li>
<li><p><strong>num_paths</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – Number of paths requested through each FSA. FSAs that have no successful
paths will have zero paths returned.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>[fsa][path][arc_pos]; the final
sub-lists (indexed with arc_pos) are sequences of arcs starting from the
start state and terminating in the final state. The values are arc_idx012,
i.e. arc indexes.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Returns a k2.RaggedTensor (dtype is torch.int32) with 3 axes</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="remove-epsilon">
<h2>remove_epsilon<a class="headerlink" href="#remove-epsilon" title="Permalink to this headline"></a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="k2.remove_epsilon">
<span class="sig-prename descclassname"><span class="pre">k2.</span></span><span class="sig-name descname"><span class="pre">remove_epsilon</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fsa</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/k2-fsa/k2/blob/master/k2/python/k2/fsa_algo.py#L531-L565"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#k2.remove_epsilon" title="Permalink to this definition"></a></dt>
<dd><p>Remove epsilons (symbol zero) in the input Fsa.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>fsa</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Fsa</span></code>) – <p>The input FSA. It can be either a single FSA or an FsaVec.
Works either for CPU or GPU, but the algorithm is different.
We can only use the CPU algorithm if the input is top-sorted,
and the GPU algorithm, while it works for CPU, may not be
very fast.</p>
<p><cite>fsa</cite> must be free of epsilon loops that have score
greater than 0.</p>
</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Fsa</span></code></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>The resulting Fsa is equivalent to the input <cite>fsa</cite> under the
tropical semiring but will be epsilon-free.  Any linear tensor
attributes, such as ‘aux_labels’, will have been turned into
ragged labels after removing fillers (i.e. labels whose
value equals fsa.XXX_filler if the attribute name is XXX),
counting -1’s on final-arcs as fillers even if the filler
value for that attribute is not -1.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="remove-epsilon-and-add-self-loops">
<h2>remove_epsilon_and_add_self_loops<a class="headerlink" href="#remove-epsilon-and-add-self-loops" title="Permalink to this headline"></a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="k2.remove_epsilon_and_add_self_loops">
<span class="sig-prename descclassname"><span class="pre">k2.</span></span><span class="sig-name descname"><span class="pre">remove_epsilon_and_add_self_loops</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fsa</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">remove_filler</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/k2-fsa/k2/blob/master/k2/python/k2/fsa_algo.py#L574-L599"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#k2.remove_epsilon_and_add_self_loops" title="Permalink to this definition"></a></dt>
<dd><p>Remove epsilons (symbol zero) in the input Fsa, and then add
epsilon self-loops to all states in the input Fsa (usually as
a preparation for intersection with treat_epsilons_specially=0).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>fsa</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Fsa</span></code>) – The input FSA. It can be either a single FSA or an FsaVec.</p></li>
<li><p><strong>remove_filler</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – If true, we will remove any <cite>filler values</cite> of attributes when
converting linear to ragged attributes.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Fsa</span></code></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>The resulting Fsa.   See <a class="reference internal" href="#k2.remove_epsilon" title="k2.remove_epsilon"><code class="xref py py-func docutils literal notranslate"><span class="pre">remove_epsilon()</span></code></a> for details.
The only epsilons will be epsilon self-loops on all states.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="remove-epsilon-self-loops">
<h2>remove_epsilon_self_loops<a class="headerlink" href="#remove-epsilon-self-loops" title="Permalink to this headline"></a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="k2.remove_epsilon_self_loops">
<span class="sig-prename descclassname"><span class="pre">k2.</span></span><span class="sig-name descname"><span class="pre">remove_epsilon_self_loops</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fsa</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/k2-fsa/k2/blob/master/k2/python/k2/fsa_algo.py#L509-L528"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#k2.remove_epsilon_self_loops" title="Permalink to this definition"></a></dt>
<dd><p>Remove epsilon self-loops of an Fsa or an FsaVec.</p>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>Unlike <a class="reference internal" href="#k2.remove_epsilon" title="k2.remove_epsilon"><code class="xref py py-func docutils literal notranslate"><span class="pre">remove_epsilon()</span></code></a>, this funciton removes only
epsilon self-loops.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>fsa</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Fsa</span></code>) – The input FSA. It can be either a single FSA or an FsaVec.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Fsa</span></code></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>An instance of <code class="xref py py-class docutils literal notranslate"><span class="pre">Fsa</span></code> that has no epsilon self-loops on every
non-final state.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="replace-fsa">
<h2>replace_fsa<a class="headerlink" href="#replace-fsa" title="Permalink to this headline"></a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="k2.replace_fsa">
<span class="sig-prename descclassname"><span class="pre">k2.</span></span><span class="sig-name descname"><span class="pre">replace_fsa</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">src</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">index</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">symbol_begin_range</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ret_arc_map</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/k2-fsa/k2/blob/master/k2/python/k2/fsa_algo.py#L935-L981"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#k2.replace_fsa" title="Permalink to this definition"></a></dt>
<dd><p>Replace arcs in index FSA with the corresponding fsas in a vector of
FSAs(src). For arcs in <cite>index</cite> with label
<cite>symbol_range_begin &lt;= label &lt; symbol_range_begin + src.Dim0()</cite> will be
replaced with fsa indexed <cite>label - symbol_begin_range</cite> in <cite>src</cite>.
The destination state of the arc in <cite>index</cite> is identified with the
<cite>final-state</cite> of the corresponding FSA in <cite>src</cite>, and the arc in <cite>index</cite>
will become an epsilon arc leading to a new state in the output that is
a copy of the start-state of the corresponding FSA in <cite>src</cite>. Arcs with
labels outside this range are just copied. Labels on final-arcs in <cite>src</cite>
(Which will be -1) would be set to 0(epsilon) in the result fsa.</p>
<dl class="simple">
<dt>Caution: Attributes of the result inherits from <cite>index</cite> and <cite>src</cite> via</dt><dd><p><cite>arc_map_index</cite> and <cite>arc_map_src</cite>, But if there are attributes
with same name, only the attributes with dtype <cite>torch.float32</cite>
are supported, the other kinds of attributes are discarded.
See docs in <cite>fsa_from_binary_function_tensor</cite> for details.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>src</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Fsa</span></code>) – Fsa that we’ll be inserting into the result, MUST have 3 axes.</p></li>
<li><p><strong>index</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Fsa</span></code>) – The Fsa that is to be replaced, It can be a single FSA or a vector of
FSAs.</p></li>
<li><p><strong>symbol_range_begin</strong> – Beginning of the range of symbols that are to be replaced with Fsas.</p></li>
<li><p><strong>ret_arc_map</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – if true, will return a tuple
(new_fsas, arc_map_index, arc_map_src) with <cite>arc_map_index</cite> and
<cite>arc_map_src</cite> tensors of int32 that maps from arcs in the result to
arcs in <cite>index</cite> and <cite>src</cite> , with -1’s for the arcs not mapped.
If false, just returns new_fsas.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Fsa</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Fsa</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>]]</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="shortest-path">
<h2>shortest_path<a class="headerlink" href="#shortest-path" title="Permalink to this headline"></a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="k2.shortest_path">
<span class="sig-prename descclassname"><span class="pre">k2.</span></span><span class="sig-name descname"><span class="pre">shortest_path</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fsa</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_double_scores</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/k2-fsa/k2/blob/master/k2/python/k2/fsa_algo.py#L450-L472"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#k2.shortest_path" title="Permalink to this definition"></a></dt>
<dd><p>Return the shortest paths as linear FSAs from the start state
to the final state in the tropical semiring.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>It uses the opposite sign. That is, It uses <cite>max</cite> instead of <cite>min</cite>.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>fsa</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Fsa</span></code>) – The input FSA. It can be either a single FSA or an FsaVec.</p></li>
<li><p><strong>use_double_scores</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – False to use float, i.e., single precision floating point, for scores.
True to use double.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Fsa</span></code></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>FsaVec, it contains the best paths as linear FSAs</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="simple-ragged-index-select">
<h2>simple_ragged_index_select<a class="headerlink" href="#simple-ragged-index-select" title="Permalink to this headline"></a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="k2.simple_ragged_index_select">
<span class="sig-prename descclassname"><span class="pre">k2.</span></span><span class="sig-name descname"><span class="pre">simple_ragged_index_select</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="pre">src:</span> <span class="pre">torch.Tensor</span></em>, <em class="sig-param"><span class="pre">indexes:</span> <span class="pre">k2::RaggedAny</span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="headerlink" href="#k2.simple_ragged_index_select" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</section>
<section id="to-dot">
<h2>to_dot<a class="headerlink" href="#to-dot" title="Permalink to this headline"></a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="k2.to_dot">
<span class="sig-prename descclassname"><span class="pre">k2.</span></span><span class="sig-name descname"><span class="pre">to_dot</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fsa</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">title</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/k2-fsa/k2/blob/master/k2/python/k2/utils.py#L109-L247"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#k2.to_dot" title="Permalink to this definition"></a></dt>
<dd><p>Visualize an Fsa via graphviz.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Graphviz is needed only when this function is called.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>fsa</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Fsa</span></code>) – The input FSA to be visualized.</p></li>
<li><p><strong>title</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>]) – Optional. The title of the resulting visualization.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>Digraph</p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>a Diagraph from grahpviz.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="to-str">
<h2>to_str<a class="headerlink" href="#to-str" title="Permalink to this headline"></a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="k2.to_str">
<span class="sig-prename descclassname"><span class="pre">k2.</span></span><span class="sig-name descname"><span class="pre">to_str</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fsa</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">openfst</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/k2-fsa/k2/blob/master/k2/python/k2/utils.py#L32-L61"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#k2.to_str" title="Permalink to this definition"></a></dt>
<dd><p>Convert an Fsa to a string.  This version prints out all integer
labels and integer ragged labels on the same line as each arc, the
same format accepted by Fsa.from_str().</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The returned string can be used to construct an Fsa with Fsa.from_str(),
but you would need to know the names of the auxiliary labels and ragged
labels.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>openfst</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – Optional. If true, we negate the scores during the conversion.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A string representation of the Fsa.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="to-str-simple">
<h2>to_str_simple<a class="headerlink" href="#to-str-simple" title="Permalink to this headline"></a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="k2.to_str_simple">
<span class="sig-prename descclassname"><span class="pre">k2.</span></span><span class="sig-name descname"><span class="pre">to_str_simple</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fsa</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">openfst</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/k2-fsa/k2/blob/master/k2/python/k2/utils.py#L64-L85"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#k2.to_str_simple" title="Permalink to this definition"></a></dt>
<dd><p>Convert an Fsa to a string.  This is less complete than Fsa.to_str(),
fsa.__str__(), or to_str_full(), meaning it prints only fsa.aux_labels and
no ragged labels, not printing any other attributes.  This is used in
testing.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The returned string can be used to construct an Fsa.  See also to_str().</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>openfst</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – Optional. If true, we negate the scores during the conversion.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A string representation of the Fsa.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="to-tensor">
<h2>to_tensor<a class="headerlink" href="#to-tensor" title="Permalink to this headline"></a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="k2.to_tensor">
<span class="sig-prename descclassname"><span class="pre">k2.</span></span><span class="sig-name descname"><span class="pre">to_tensor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fsa</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/k2-fsa/k2/blob/master/k2/python/k2/utils.py#L88-L106"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#k2.to_tensor" title="Permalink to this definition"></a></dt>
<dd><p>Convert an Fsa to a Tensor.</p>
<p>You can save the tensor to disk and read it later
to construct an Fsa.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The returned Tensor contains only the transition rules, e.g.,
arcs. You may want to save its aux_labels separately if any.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>fsa</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Fsa</span></code>) – The input Fsa.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A <cite>torch.Tensor</cite> of dtype <cite>torch.int32</cite>. It is a 2-D tensor
if the input is a single FSA. It is a 1-D tensor if the input
is a vector of FSAs.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="top-sort">
<h2>top_sort<a class="headerlink" href="#top-sort" title="Permalink to this headline"></a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="k2.top_sort">
<span class="sig-prename descclassname"><span class="pre">k2.</span></span><span class="sig-name descname"><span class="pre">top_sort</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fsa</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/k2-fsa/k2/blob/master/k2/python/k2/fsa_algo.py#L103-L121"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#k2.top_sort" title="Permalink to this definition"></a></dt>
<dd><p>Sort an FSA topologically.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>It returns a new FSA. The input FSA is NOT changed.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>fsa</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Fsa</span></code>) – The input FSA to be sorted. It can be either a single FSA
or a vector of FSAs.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Fsa</span></code></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>It returns a single FSA if the input is a single FSA; it returns
a vector of FSAs if the input is a vector of FSAs.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="union">
<h2>union<a class="headerlink" href="#union" title="Permalink to this headline"></a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="k2.union">
<span class="sig-prename descclassname"><span class="pre">k2.</span></span><span class="sig-name descname"><span class="pre">union</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fsas</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/k2-fsa/k2/blob/master/k2/python/k2/autograd.py#L848-L865"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#k2.union" title="Permalink to this definition"></a></dt>
<dd><p>Compute the union of a FsaVec.</p>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>We require that every fsa in fsas is non-empty, i.e.,
contains at least two states</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>fsas</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Fsa</span></code>) – A FsaVec. That is, len(fsas.shape) == 3.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Fsa</span></code></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A single Fsa that is the union of the input fsas.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="ctcloss">
<h2>CtcLoss<a class="headerlink" href="#ctcloss" title="Permalink to this headline"></a></h2>
<section id="forward">
<h3>forward<a class="headerlink" href="#forward" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.CtcLoss.forward">
<span class="sig-prename descclassname"><span class="pre">CtcLoss.</span></span><span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">decoding_graph</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dense_fsa_vec</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_lengths</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/k2-fsa/k2/blob/master/k2/python/k2/ctc_loss.py#L59-L95"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#k2.CtcLoss.forward" title="Permalink to this definition"></a></dt>
<dd><p>Compute the CTC loss given a decoding graph and a dense fsa vector.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>decoding_graph</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Fsa</span></code>) – An FsaVec. It can be the composition result of a CTC topology
and a transcript.</p></li>
<li><p><strong>dense_fsa_vec</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">DenseFsaVec</span></code>) – It represents the neural network output. Refer to the help
information in <code class="xref py py-class docutils literal notranslate"><span class="pre">k2.DenseFsaVec</span></code>.</p></li>
<li><p><strong>target_lengths</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>]) – Used only when <cite>reduction</cite> is <cite>mean</cite>. It is a 1-D tensor of batch
size representing lengths of the targets, e.g., number of phones or
number of word pieces in a sentence.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>If <cite>reduction</cite> is <cite>none</cite>, return a 1-D tensor with size equal to batch
size. If <cite>reduction</cite> is <cite>mean</cite> or <cite>sum</cite>, return a scalar.</p>
</dd>
</dl>
</dd></dl>

</section>
</section>
<section id="densefsavec">
<h2>DenseFsaVec<a class="headerlink" href="#densefsavec" title="Permalink to this headline"></a></h2>
<section id="init">
<h3>__init__<a class="headerlink" href="#init" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.DenseFsaVec.__init__">
<span class="sig-prename descclassname"><span class="pre">DenseFsaVec.</span></span><span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">log_probs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">supervision_segments</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">allow_truncate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/k2-fsa/k2/blob/master/k2/python/k2/dense_fsa_vec.py#L43-L145"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#k2.DenseFsaVec.__init__" title="Permalink to this definition"></a></dt>
<dd><p>Construct a DenseFsaVec from neural net log-softmax outputs.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>log_probs</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – A 3-D tensor of dtype <cite>torch.float32</cite> with shape <cite>(N, T, C)</cite>,
where <cite>N</cite> is the number of sequences, <cite>T</cite> the maximum input
length, and <cite>C</cite> the number of output classes.</p></li>
<li><p><strong>supervision_segments</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – <p>A 2-D <strong>CPU</strong> tensor of dtype <cite>torch.int32</cite> with 3 columns.
Each row contains information for a supervision segment. Column 0
is the <cite>sequence_index</cite> indicating which sequence this segment
comes from; column 1 specifies the <cite>start_frame</cite> of this segment
within the sequence; column 2 contains the <cite>duration</cite> of this
segment.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<ul>
<li><p><cite>0 &lt; start_frame + duration &lt;= T + allow_truncate</cite></p></li>
<li><p><cite>0 &lt;= start_frame &lt; T</cite></p></li>
<li><p><cite>duration &gt; 0</cite></p></li>
</ul>
</div>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>If the resulting dense fsa vec is used as an input to
<cite>k2.intersect_dense</cite>, then the last column, i.e., the duration
column, has to be sorted in <strong>decreasing</strong> order.
That is, the first supervision_segment (the first row) has the
largest duration.
Otherwise, you don’t need to sort the last column.</p>
<p><cite>k2.intersect_dense</cite> is often used in the training stage, so
you should usually sort dense fsa vecs by its duration
in training. <cite>k2.intersect_dense_pruned</cite> is usually used in the
decoding stage, so you don’t need to sort dense fsa vecs in
decoding.</p>
</div>
</p></li>
<li><p><strong>allow_truncate</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – If not zero, it truncates at most this number of frames from
duration in case start_frame + duration &gt; T.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>
<section id="from-dense-fsa-vec">
<h3>_from_dense_fsa_vec<a class="headerlink" href="#from-dense-fsa-vec" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.DenseFsaVec._from_dense_fsa_vec">
<em class="property"><span class="pre">classmethod</span> </em><span class="sig-prename descclassname"><span class="pre">DenseFsaVec.</span></span><span class="sig-name descname"><span class="pre">_from_dense_fsa_vec</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dense_fsa_vec</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scores</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/k2-fsa/k2/blob/master/k2/python/k2/dense_fsa_vec.py#L158-L177"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#k2.DenseFsaVec._from_dense_fsa_vec" title="Permalink to this definition"></a></dt>
<dd><p>Construct a DenseFsaVec from <cite>_k2.DenseFsaVec</cite> and <cite>scores</cite>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>It is intended for internal use. Users will normally not use it.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dense_fsa_vec</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">DenseFsaVec</span></code>) – An instance of <cite>_k2.DenseFsaVec</cite>.</p></li>
<li><p><strong>scores</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – The <cite>scores</cite> of <cite>_k2.DenseFsaVec</cite> for back propagation.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">DenseFsaVec</span></code></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>An instance of DenseFsaVec.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="to">
<h3>to<a class="headerlink" href="#to" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.DenseFsaVec.to">
<span class="sig-prename descclassname"><span class="pre">DenseFsaVec.</span></span><span class="sig-name descname"><span class="pre">to</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">device</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/k2-fsa/k2/blob/master/k2/python/k2/dense_fsa_vec.py#L206-L228"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#k2.DenseFsaVec.to" title="Permalink to this definition"></a></dt>
<dd><p>Move the DenseFsaVec onto a given device.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>device</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">device</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>]) – An instance of <cite>torch.device</cite> or a string that can be used to
construct a <cite>torch.device</cite>, e.g., ‘cpu’, ‘cuda:0’.
It supports only cpu and cuda devices.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">DenseFsaVec</span></code></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Returns a new DenseFsaVec which is this object copied to the given
device (or this object itself, if the device was the same).</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="device">
<h3>device<a class="headerlink" href="#device" title="Permalink to this headline"></a></h3>
<dl class="py attribute">
<dt class="sig sig-object py" id="k2.DenseFsaVec.device">
<span class="sig-prename descclassname"><span class="pre">DenseFsaVec.</span></span><span class="sig-name descname"><span class="pre">device</span></span><a class="headerlink" href="#k2.DenseFsaVec.device" title="Permalink to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">device</span></code></p>
</dd>
</dl>
</dd></dl>

</section>
<section id="duration">
<h3>duration<a class="headerlink" href="#duration" title="Permalink to this headline"></a></h3>
<dl class="py attribute">
<dt class="sig sig-object py" id="k2.DenseFsaVec.duration">
<span class="sig-prename descclassname"><span class="pre">DenseFsaVec.</span></span><span class="sig-name descname"><span class="pre">duration</span></span><a class="headerlink" href="#k2.DenseFsaVec.duration" title="Permalink to this definition"></a></dt>
<dd><p>Return the duration (on CPU) of each seq.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></p>
</dd>
</dl>
</dd></dl>

</section>
</section>
<section id="determinizeweightpushingtype">
<h2>DeterminizeWeightPushingType<a class="headerlink" href="#determinizeweightpushingtype" title="Permalink to this headline"></a></h2>
<section id="name">
<h3>name<a class="headerlink" href="#name" title="Permalink to this headline"></a></h3>
<dl class="py attribute">
<dt class="sig sig-object py" id="k2.DeterminizeWeightPushingType.name">
<span class="sig-prename descclassname"><span class="pre">DeterminizeWeightPushingType.</span></span><span class="sig-name descname"><span class="pre">name</span></span><a class="headerlink" href="#k2.DeterminizeWeightPushingType.name" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</section>
</section>
<section id="fsa">
<h2>Fsa<a class="headerlink" href="#fsa" title="Permalink to this headline"></a></h2>
<section id="getattr">
<h3>__getattr__<a class="headerlink" href="#getattr" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.Fsa.__getattr__">
<span class="sig-prename descclassname"><span class="pre">Fsa.</span></span><span class="sig-name descname"><span class="pre">__getattr__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/k2-fsa/k2/blob/master/k2/python/k2/fsa.py#L486-L504"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#k2.Fsa.__getattr__" title="Permalink to this definition"></a></dt>
<dd><p>Note: for attributes that exist as properties, e.g.
self.labels, self.properties, self.requires_grad, we won’t
reach this code because Python checks the class dict before
calling getattr.  The same is true for instance attributes
such as self.{_tensor_attr,_non_tensor_attr,_cache,_properties}</p>
<p>The ‘virtual’ members of this class are those in self._tensor_attr
and self._non_tensor_attr.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code></p>
</dd>
</dl>
</dd></dl>

</section>
<section id="getitem">
<h3>__getitem__<a class="headerlink" href="#getitem" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.Fsa.__getitem__">
<span class="sig-prename descclassname"><span class="pre">Fsa.</span></span><span class="sig-name descname"><span class="pre">__getitem__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">i</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/k2-fsa/k2/blob/master/k2/python/k2/fsa.py#L1010-L1042"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#k2.Fsa.__getitem__" title="Permalink to this definition"></a></dt>
<dd><p>Get the i-th FSA.</p>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p><cite>self</cite> has to be an FsaVec, i.e. len(self.shape) == 3</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>i</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – The i-th FSA to select. 0 &lt;= i &lt; self.arcs.dim0().</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Fsa</span></code></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>The i-th FSA. Note it is a single FSA.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="id1">
<h3>__init__<a class="headerlink" href="#id1" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.Fsa.__init__">
<span class="sig-prename descclassname"><span class="pre">Fsa.</span></span><span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">arcs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">aux_labels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">properties</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/k2-fsa/k2/blob/master/k2/python/k2/fsa.py#L119-L229"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#k2.Fsa.__init__" title="Permalink to this definition"></a></dt>
<dd><p>Build an Fsa from a tensor with optional aux_labels.</p>
<p>It is useful when loading an Fsa from file.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>tensor</strong> – <p>A torch tensor of dtype <cite>torch.int32</cite> with 4 columns.
Each row represents an arc. Column 0 is the src_state,
column 1 the dest_state, column 2 the label, and column
3 the score.</p>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>Scores are floats and their binary pattern is
<strong>reinterpreted</strong> as integers and saved in a tensor
of dtype <cite>torch.int32</cite>.</p>
</div>
</p></li>
<li><p><strong>aux_labels</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">RaggedTensor</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]) – Optional. If not None, it associates an aux_label with every arc,
so it has as many rows as <cite>tensor</cite>. It is a 1-D tensor of dtype
<cite>torch.int32</cite> or <cite>k2.RaggedTensor</cite> whose <cite>dim0</cite> equals to the
number of arcs.</p></li>
<li><p><strong>properties</strong> – Tensor properties if known (should only be provided by
internal code, as they are not checked; intended for use
by <code class="xref py py-func docutils literal notranslate"><span class="pre">clone()</span></code>)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>An instance of Fsa.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="setattr">
<h3>__setattr__<a class="headerlink" href="#setattr" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.Fsa.__setattr__">
<span class="sig-prename descclassname"><span class="pre">Fsa.</span></span><span class="sig-name descname"><span class="pre">__setattr__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">value</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/k2-fsa/k2/blob/master/k2/python/k2/fsa.py#L372-L416"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#k2.Fsa.__setattr__" title="Permalink to this definition"></a></dt>
<dd><div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>We save a reference to <cite>value</cite>. If you need to change <cite>value</cite>
afterwards, please consider passing a copy of it.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>name</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – Name of the attribute.</p></li>
<li><p><strong>value</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>) – Value of the attribute.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

</section>
<section id="str">
<h3>__str__<a class="headerlink" href="#str" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.Fsa.__str__">
<span class="sig-prename descclassname"><span class="pre">Fsa.</span></span><span class="sig-name descname"><span class="pre">__str__</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/k2-fsa/k2/blob/master/k2/python/k2/fsa.py#L301-L306"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#k2.Fsa.__str__" title="Permalink to this definition"></a></dt>
<dd><p>Return a string representation of this object</p>
<p>For visualization and debug only.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></p>
</dd>
</dl>
</dd></dl>

</section>
<section id="get-arc-post">
<h3>_get_arc_post<a class="headerlink" href="#get-arc-post" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.Fsa._get_arc_post">
<span class="sig-prename descclassname"><span class="pre">Fsa.</span></span><span class="sig-name descname"><span class="pre">_get_arc_post</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">use_double_scores</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log_semiring</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/k2-fsa/k2/blob/master/k2/python/k2/fsa.py#L758-L792"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#k2.Fsa._get_arc_post" title="Permalink to this definition"></a></dt>
<dd><p>Compute scores on arcs, representing log probabilities;
with log_semiring=True you could call these log posteriors,
but if log_semiring=False they can only be interpreted as the
difference betwen the best-path score and the score of the
best path that includes this arc.</p>
<p>This version is not differentiable; see also <a class="reference internal" href="#k2.Fsa.get_arc_post" title="k2.Fsa.get_arc_post"><code class="xref py py-func docutils literal notranslate"><span class="pre">get_arc_post()</span></code></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>use_double_scores</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – if True, use double precision.</p></li>
<li><p><strong>log_semiring</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – if True, use log semiring, else tropical.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A torch.Tensor with shape equal to (num_arcs,)
and non-positive elements.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="get-backward-scores">
<h3>_get_backward_scores<a class="headerlink" href="#get-backward-scores" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.Fsa._get_backward_scores">
<span class="sig-prename descclassname"><span class="pre">Fsa.</span></span><span class="sig-name descname"><span class="pre">_get_backward_scores</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">use_double_scores</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log_semiring</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/k2-fsa/k2/blob/master/k2/python/k2/fsa.py#L699-L736"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#k2.Fsa._get_backward_scores" title="Permalink to this definition"></a></dt>
<dd><p>Compute backward-scores, i.e. total weight (or best-path weight)
from each state to the final state.</p>
<p>For internal k2 use. Not differentiable.</p>
<p>See also <a class="reference internal" href="#k2.Fsa.get_backward_scores" title="k2.Fsa.get_backward_scores"><code class="xref py py-func docutils literal notranslate"><span class="pre">get_backward_scores()</span></code></a> which is differentiable.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>use_double_scores</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – True to use <cite>double precision</cite> floating point.
False to use <cite>single precision</cite>.</p></li>
<li><p><strong>log_semiring</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – True to use log semiring (log-sum), false to use tropical (i.e. max
on scores).</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A torch.Tensor with shape equal to (num_states,)</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="get-entering-arcs">
<h3>_get_entering_arcs<a class="headerlink" href="#get-entering-arcs" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.Fsa._get_entering_arcs">
<span class="sig-prename descclassname"><span class="pre">Fsa.</span></span><span class="sig-name descname"><span class="pre">_get_entering_arcs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">use_double_scores</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/k2-fsa/k2/blob/master/k2/python/k2/fsa.py#L832-L846"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#k2.Fsa._get_entering_arcs" title="Permalink to this definition"></a></dt>
<dd><p>Compute, for each state, the index of the best arc entering it.</p>
<p>For internal k2 use.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>use_double_scores</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – True to use <cite>double precision</cite> floating point.
False to use <cite>single precision</cite>.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></p>
</dd>
</dl>
</dd></dl>

</section>
<section id="get-forward-scores">
<h3>_get_forward_scores<a class="headerlink" href="#get-forward-scores" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.Fsa._get_forward_scores">
<span class="sig-prename descclassname"><span class="pre">Fsa.</span></span><span class="sig-name descname"><span class="pre">_get_forward_scores</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">use_double_scores</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log_semiring</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/k2-fsa/k2/blob/master/k2/python/k2/fsa.py#L594-L628"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#k2.Fsa._get_forward_scores" title="Permalink to this definition"></a></dt>
<dd><p>Get (and compute if necessary) cached property
<cite>self.forward_scores_xxx_yyy</cite> (where xxx indicates float-type and
yyy indicates semiring).</p>
<p>For use by internal k2 code; returns the total score from start-state to
each state.  Not differentiable; see <a class="reference internal" href="#k2.Fsa.get_forward_scores" title="k2.Fsa.get_forward_scores"><code class="xref py py-func docutils literal notranslate"><span class="pre">get_forward_scores()</span></code></a> which is
the differentiable version.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>use_double_scores</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – True to use <cite>double precision</cite> floating point.
False to use <cite>single precision</cite>.</p></li>
<li><p><strong>log_semiring</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – True to use log semiring (log-sum), false to use tropical (i.e. max
on scores).</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></p>
</dd>
</dl>
</dd></dl>

</section>
<section id="get-tot-scores">
<h3>_get_tot_scores<a class="headerlink" href="#get-tot-scores" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.Fsa._get_tot_scores">
<span class="sig-prename descclassname"><span class="pre">Fsa.</span></span><span class="sig-name descname"><span class="pre">_get_tot_scores</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">use_double_scores</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log_semiring</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/k2-fsa/k2/blob/master/k2/python/k2/fsa.py#L650-L678"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#k2.Fsa._get_tot_scores" title="Permalink to this definition"></a></dt>
<dd><p>Compute total-scores (one per FSA) as the best-path score.</p>
<p>This version is not differentiable; see also <a class="reference internal" href="#k2.Fsa.get_tot_scores" title="k2.Fsa.get_tot_scores"><code class="xref py py-func docutils literal notranslate"><span class="pre">get_tot_scores()</span></code></a>
which is differentiable.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>use_double_scores</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – If True, use <cite>double precision</cite> floating point; false;
else single precision.</p></li>
<li><p><strong>log_semiring</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – True to use log semiring (log-sum), false to use tropical (i.e. max
on scores).</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></p>
</dd>
</dl>
</dd></dl>

</section>
<section id="invalidate-cache">
<h3>_invalidate_cache_<a class="headerlink" href="#invalidate-cache" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.Fsa._invalidate_cache_">
<span class="sig-prename descclassname"><span class="pre">Fsa.</span></span><span class="sig-name descname"><span class="pre">_invalidate_cache_</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">scores_only</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/k2-fsa/k2/blob/master/k2/python/k2/fsa.py#L231-L262"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#k2.Fsa._invalidate_cache_" title="Permalink to this definition"></a></dt>
<dd><p>Intended for internal use only so its
name begins with an underline.</p>
<p>Also, it changes <cite>self</cite> in-place.</p>
<p>Currently, it is used only when the <cite>scores</cite> field
are re-assigned.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>scores_only</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – It True, it invalidates only cached entries related
to scores. If False, the whole cache is invalidated.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

</section>
<section id="as-dict">
<h3>as_dict<a class="headerlink" href="#as-dict" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.Fsa.as_dict">
<span class="sig-prename descclassname"><span class="pre">Fsa.</span></span><span class="sig-name descname"><span class="pre">as_dict</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/k2-fsa/k2/blob/master/k2/python/k2/fsa.py#L1054-L1073"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#k2.Fsa.as_dict" title="Permalink to this definition"></a></dt>
<dd><p>Convert this Fsa to a dict (probably for purposes of serialization
, e.g., torch.save).</p>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p><cite>self.requires_grad</cite> attribute is not saved.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>]</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A <cite>dict</cite> that can be used to reconstruct this FSA by using
<cite>Fsa.from_dict</cite>.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="convert-attr-to-ragged">
<h3><a class="reference internal" href="#convert-attr-to-ragged">convert_attr_to_ragged</a><a class="headerlink" href="#convert-attr-to-ragged" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.Fsa.convert_attr_to_ragged_">
<span class="sig-prename descclassname"><span class="pre">Fsa.</span></span><span class="sig-name descname"><span class="pre">convert_attr_to_ragged_</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">remove_eps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/k2-fsa/k2/blob/master/k2/python/k2/fsa.py#L1399-L1432"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#k2.Fsa.convert_attr_to_ragged_" title="Permalink to this definition"></a></dt>
<dd><p>Convert the attribute given by <cite>name</cite> from a 1-D torch.tensor
to a k2.RaggedTensor.</p>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>This function ends with an underscore, meaning it changes the FSA
<strong>in-place</strong>.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>name</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – The attribute name. This attribute is expected to be a 1-D tensor
with dtype torch.int32.</p></li>
<li><p><strong>remove_eps</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – True to remove 0s in the resulting ragged tensor.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Fsa</span></code></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Return self.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="draw">
<h3>draw<a class="headerlink" href="#draw" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.Fsa.draw">
<span class="sig-prename descclassname"><span class="pre">Fsa.</span></span><span class="sig-name descname"><span class="pre">draw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">filename</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">title</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/k2-fsa/k2/blob/master/k2/python/k2/fsa.py#L332-L370"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#k2.Fsa.draw" title="Permalink to this definition"></a></dt>
<dd><p>Render FSA as an image via graphviz, and return the Digraph object;
and optionally save to file <cite>filename</cite>.
<cite>filename</cite> must have a suffix that graphviz understands, such as
<cite>pdf</cite>, <cite>svg</cite> or <cite>png</cite>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>You need to install graphviz to use this function:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">pip</span> <span class="n">install</span> <span class="n">graphviz</span>
</pre></div>
</div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>filename</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>]) – Filename to (optionally) save to, e.g. ‘foo.png’, ‘foo.svg’,
‘foo.png’  (must have a suffix that graphviz understands).</p></li>
<li><p><strong>title</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>]) – Title to be displayed in image, e.g. ‘A simple FSA example’</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>Digraph</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="from-openfst">
<h3>from_openfst<a class="headerlink" href="#from-openfst" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.Fsa.from_openfst">
<em class="property"><span class="pre">classmethod</span> </em><span class="sig-prename descclassname"><span class="pre">Fsa.</span></span><span class="sig-name descname"><span class="pre">from_openfst</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">s</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">acceptor</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_aux_labels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">aux_label_names</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ragged_label_names</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">[]</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/k2-fsa/k2/blob/master/k2/python/k2/fsa.py#L1304-L1362"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#k2.Fsa.from_openfst" title="Permalink to this definition"></a></dt>
<dd><p>Create an Fsa from a string in OpenFST format (or a slightly more
general format, if num_aux_labels &gt; 1). See also <a class="reference internal" href="#k2.Fsa.from_str" title="k2.Fsa.from_str"><code class="xref py py-func docutils literal notranslate"><span class="pre">from_str()</span></code></a>.</p>
<p>The given string <cite>s</cite> consists of lines with the following format:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">src_state</span> <span class="n">dest_state</span> <span class="n">label</span> <span class="p">[</span><span class="n">aux_label1</span> <span class="n">aux_label2</span><span class="o">...</span><span class="p">]</span> <span class="p">[</span><span class="n">cost</span><span class="p">]</span>
</pre></div>
</div>
<p>(the cost defaults to 0.0 if not present).</p>
<p>The line for the final state consists of two fields:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">final_state</span> <span class="p">[</span><span class="n">cost</span><span class="p">]</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Fields are separated by space(s), tab(s) or both. The <cite>cost</cite>
field is a float, while other fields are integers.</p>
<p>There might be multiple final states. Also, OpenFst may omit the cost
if it is 0.0.</p>
</div>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>We use <cite>cost</cite> here to indicate that its value will be negated so that
we can get <cite>scores</cite>. That is, <cite>score = -1 * cost</cite>.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>At most one of <cite>acceptor</cite>, <cite>num_aux_labels</cite>, and <cite>aux_label_names</cite>
must be supplied; if none are supplied, acceptor format is assumed.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>s</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – The input string. Refer to the above comment for its format.</p></li>
<li><p><strong>acceptor</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>]) – Set to true to denote acceptor format which is num_aux_labels == 0,
or false to denote transducer format (i.e. num_aux_labels == 1
with name ‘aux_labels’).</p></li>
<li><p><strong>num_aux_labels</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>]) – The number of auxiliary labels to expect on each line (in addition
to the ‘acceptor’ label; is 1 for traditional transducers but can be
any non-negative number.</p></li>
<li><p><strong>aux_label_names</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>]]) – If provided, the length of this list dictates the number of
aux_labels. By default the names are ‘aux_labels’, ‘aux_labels2’,
‘aux_labels3’ and so on.</p></li>
<li><p><strong>ragged_label_names</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>]) – If provided, expect this number of ragged labels, in the order
of this list.  It is advisable that this list be in
alphabetical order, so that the format when we write back to
a string will be unchanged.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Fsa</span></code></p>
</dd>
</dl>
</dd></dl>

</section>
<section id="from-str">
<h3>from_str<a class="headerlink" href="#from-str" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.Fsa.from_str">
<em class="property"><span class="pre">classmethod</span> </em><span class="sig-prename descclassname"><span class="pre">Fsa.</span></span><span class="sig-name descname"><span class="pre">from_str</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">s</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">acceptor</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_aux_labels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">aux_label_names</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ragged_label_names</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">[]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">openfst</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/k2-fsa/k2/blob/master/k2/python/k2/fsa.py#L1222-L1302"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#k2.Fsa.from_str" title="Permalink to this definition"></a></dt>
<dd><p>Create an Fsa from a string in the k2 or OpenFst format.
(See also <a class="reference internal" href="#k2.Fsa.from_openfst" title="k2.Fsa.from_openfst"><code class="xref py py-func docutils literal notranslate"><span class="pre">from_openfst()</span></code></a>).</p>
<p>The given string <cite>s</cite> consists of lines with the following format:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">src_state</span> <span class="n">dest_state</span> <span class="n">label</span> <span class="p">[</span><span class="n">aux_label1</span> <span class="n">aux_label2</span><span class="o">...</span><span class="p">]</span> <span class="p">[</span><span class="n">score</span><span class="p">]</span>
</pre></div>
</div>
<p>The line for the final state consists of only one field:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">final_state</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Fields are separated by space(s), tab(s) or both. The <cite>score</cite>
field is a float, while other fields are integers.</p>
</div>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>The first column has to be non-decreasing.</p>
</div>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>The final state has the largest state number. There is <strong>ONLY</strong>
ONE final state. All arcs that are connected to the final state
have label -1. If there are aux_labels, they are also -1 for
arcs entering the final state.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>At most one of <cite>acceptor</cite>, <cite>num_aux_labels</cite>, and <cite>aux_label_names</cite>
must be supplied; if none are supplied, acceptor format is assumed.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>s</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – The input string. Refer to the above comment for its format.</p></li>
<li><p><strong>acceptor</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>]) – Set to true to denote acceptor format which is num_aux_labels == 0,
or false to denote transducer format (i.e. num_aux_labels == 1
with name ‘aux_labels’).</p></li>
<li><p><strong>num_aux_labels</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>]) – The number of auxiliary labels to expect on each line (in addition
to the ‘acceptor’ label; is 1 for traditional transducers but can be
any non-negative number.  The names of the aux_labels default to
‘aux_labels’ then ‘aux_labels2’, ‘aux_labels3’ and so on.</p></li>
<li><p><strong>aux_label_names</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>]]) – If provided, the length of this list dictates the number of
aux_labels and this list dictates their names.</p></li>
<li><p><strong>ragged_label_names</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>]) – If provided, expect this number of ragged labels, in the order
of this list.  It is advisable that this list be in
alphabetical order, so that the format when we write back to
a string will be unchanged.</p></li>
<li><p><strong>openfst</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – If true, will expect the OpenFST format (costs not scores, i.e.
negated; final-probs rather than final-state specified).</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Fsa</span></code></p>
</dd>
</dl>
</dd></dl>

</section>
<section id="id2">
<h3>get_arc_post<a class="headerlink" href="#id2" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.Fsa.get_arc_post">
<span class="sig-prename descclassname"><span class="pre">Fsa.</span></span><span class="sig-name descname"><span class="pre">get_arc_post</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">use_double_scores</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log_semiring</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/k2-fsa/k2/blob/master/k2/python/k2/fsa.py#L794-L830"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#k2.Fsa.get_arc_post" title="Permalink to this definition"></a></dt>
<dd><p>Compute scores on arcs, representing log probabilities;
with log_semiring=True you could call these log posteriors,
but if log_semiring=False they can only be interpreted as the
difference between the best-path score and the score of the
best path that includes this arc.
This version is differentiable; see also <a class="reference internal" href="#k2.Fsa._get_arc_post" title="k2.Fsa._get_arc_post"><code class="xref py py-func docutils literal notranslate"><span class="pre">_get_arc_post()</span></code></a>.</p>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>Because of how the autograd mechanics works and the
need to avoid circular references, this is not cached;
it’s best to store it if you’ll need it multiple times.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>use_double_scores</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – if True, use double precision.</p></li>
<li><p><strong>log_semiring</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – if True, use log semiring, else tropical.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A torch.Tensor with shape equal to (num_arcs,)
and non-positive elements.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="id3">
<h3>get_backward_scores<a class="headerlink" href="#id3" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.Fsa.get_backward_scores">
<span class="sig-prename descclassname"><span class="pre">Fsa.</span></span><span class="sig-name descname"><span class="pre">get_backward_scores</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">use_double_scores</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log_semiring</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/k2-fsa/k2/blob/master/k2/python/k2/fsa.py#L738-L756"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#k2.Fsa.get_backward_scores" title="Permalink to this definition"></a></dt>
<dd><p>Compute backward-scores, i.e. total weight (or best-path weight)
from each state to the final state.</p>
<p>Supports autograd.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>use_double_scores</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – if True, use double precision.</p></li>
<li><p><strong>log_semiring</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – if True, use log semiring, else tropical.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A torch.Tensor with shape equal to (num_states,)</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="get-filler">
<h3>get_filler<a class="headerlink" href="#get-filler" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.Fsa.get_filler">
<span class="sig-prename descclassname"><span class="pre">Fsa.</span></span><span class="sig-name descname"><span class="pre">get_filler</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">attribute_name</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/k2-fsa/k2/blob/master/k2/python/k2/fsa.py#L308-L330"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#k2.Fsa.get_filler" title="Permalink to this definition"></a></dt>
<dd><p>Return the filler value associated with attribute names.</p>
<p>This is 0 unless otherwise specified, but you can override this by
for example, doing:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">fsa</span><span class="o">.</span><span class="n">foo_filler</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
</pre></div>
</div>
<p>which will mean the “filler” for attribute fsa.foo is -1; and this will
get propagated when you do FSA operations, like any other non-tensor
attribute.  The filler is the value that means “nothing is here” (like
epsilon).</p>
<dl class="simple">
<dt>Caution::</dt><dd><p>you should use a value that is castable to float and back to integer
without loss of precision, because currently the <cite>default_value</cite>
parameter of <cite>index_select</cite> in ./ops.py is a float.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>]</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="id4">
<h3>get_forward_scores<a class="headerlink" href="#id4" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.Fsa.get_forward_scores">
<span class="sig-prename descclassname"><span class="pre">Fsa.</span></span><span class="sig-name descname"><span class="pre">get_forward_scores</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">use_double_scores</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log_semiring</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/k2-fsa/k2/blob/master/k2/python/k2/fsa.py#L630-L648"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#k2.Fsa.get_forward_scores" title="Permalink to this definition"></a></dt>
<dd><p>Compute forward-scores, i.e. total weight (or best-path weight)
from start state to each state.</p>
<p>Supports autograd.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>use_double_scores</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – if True, use double precision.</p></li>
<li><p><strong>log_semiring</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – if True, use log semiring, else tropical.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A torch.Tensor with shape equal to (num_states,)</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="id5">
<h3>get_tot_scores<a class="headerlink" href="#id5" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.Fsa.get_tot_scores">
<span class="sig-prename descclassname"><span class="pre">Fsa.</span></span><span class="sig-name descname"><span class="pre">get_tot_scores</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">use_double_scores</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log_semiring</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/k2-fsa/k2/blob/master/k2/python/k2/fsa.py#L680-L697"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#k2.Fsa.get_tot_scores" title="Permalink to this definition"></a></dt>
<dd><p>Compute total-scores (one per FSA) as the
best-path score.</p>
<p>This version is differentiable.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>use_double_scores</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – True to use <cite>double precision</cite> floating point;
False to use <cite>single precision</cite>.</p></li>
<li><p><strong>log_semiring</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – True to use log semiring (log-sum), false to use tropical (i.e. max
on scores).</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></p>
</dd>
</dl>
</dd></dl>

</section>
<section id="id6">
<h3>invert<a class="headerlink" href="#id6" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.Fsa.invert">
<span class="sig-prename descclassname"><span class="pre">Fsa.</span></span><span class="sig-name descname"><span class="pre">invert</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/k2-fsa/k2/blob/master/k2/python/k2/fsa.py#L977-L988"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#k2.Fsa.invert" title="Permalink to this definition"></a></dt>
<dd><p>Swap the <cite>labels</cite> and <cite>aux_labels</cite>.</p>
<p>If there are symbol tables associated with <cite>labels</cite> and
<cite>aux_labels</cite>, they are also swapped.</p>
<p>It is an error if the FSA contains no <cite>aux_labels</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Fsa</span></code></p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Return a new Fsa.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="id7">
<h3><a href="#id105"><span class="problematic" id="id106">invert_</span></a><a class="headerlink" href="#id7" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.Fsa.invert_">
<span class="sig-prename descclassname"><span class="pre">Fsa.</span></span><span class="sig-name descname"><span class="pre">invert_</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/k2-fsa/k2/blob/master/k2/python/k2/fsa.py#L924-L975"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#k2.Fsa.invert_" title="Permalink to this definition"></a></dt>
<dd><p>Swap the <cite>labels</cite> and <cite>aux_labels</cite>.</p>
<p>If there are symbol tables associated with <cite>labels</cite> and
<cite>aux_labels</cite>, they are also swapped.</p>
<p>It is an error if the FSA contains no <cite>aux_labels</cite>.</p>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>The function name ends with an underscore which means this
is an <strong>in-place</strong> operation.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Fsa</span></code></p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Return <cite>self</cite>.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="rename-tensor-attribute">
<h3><a class="reference internal" href="#rename-tensor-attribute">rename_tensor_attribute</a><a class="headerlink" href="#rename-tensor-attribute" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.Fsa.rename_tensor_attribute_">
<span class="sig-prename descclassname"><span class="pre">Fsa.</span></span><span class="sig-name descname"><span class="pre">rename_tensor_attribute_</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">src_name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dest_name</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/k2-fsa/k2/blob/master/k2/python/k2/fsa.py#L873-L922"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#k2.Fsa.rename_tensor_attribute_" title="Permalink to this definition"></a></dt>
<dd><p>Rename a tensor attribute (or, as a special case ‘labels’),
and also rename non-tensor attributes that are associated with it,
i.e. that have it as a prefix.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>src_name</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – The original name, exist as a tensor attribute, e.g. ‘aux_labels’,
or, as a special case, equal ‘labels’; special attributes ‘labels’
and ‘scores’ are allowed but won’t be deleted.</p></li>
<li><p><strong>dest_name</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – The new name, that we are renaming it to. If it already existed as
a tensor attribute, it will be rewritten; and any previously
existing non-tensor attributes that have this as a prefix will be
deleted.  As a special case, may equal ‘labels’.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Fsa</span></code></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Return <cite>self</cite>.</p>
</dd>
</dl>
<dl class="simple">
<dt>Note::</dt><dd><p>It is OK if src_name and/or dest_name equals ‘labels’ or ‘scores’,
but these special attributes won’t be deleted.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="requires-grad">
<h3><a href="#id107"><span class="problematic" id="id108">requires_grad_</span></a><a class="headerlink" href="#requires-grad" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.Fsa.requires_grad_">
<span class="sig-prename descclassname"><span class="pre">Fsa.</span></span><span class="sig-name descname"><span class="pre">requires_grad_</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">requires_grad</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/k2-fsa/k2/blob/master/k2/python/k2/fsa.py#L848-L871"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#k2.Fsa.requires_grad_" title="Permalink to this definition"></a></dt>
<dd><p>Change if autograd should record operations on this FSA:</p>
<p>Sets the <cite>scores</cite>’s requires_grad attribute in-place.</p>
<p>Returns this FSA.</p>
<p>You can test whether this object has the requires_grad property
true or false by accessing <a class="reference internal" href="#k2.Fsa.requires_grad" title="k2.Fsa.requires_grad"><code class="xref py py-attr docutils literal notranslate"><span class="pre">requires_grad</span></code></a> (handled in
<a class="reference internal" href="#k2.Fsa.__getattr__" title="k2.Fsa.__getattr__"><code class="xref py py-func docutils literal notranslate"><span class="pre">__getattr__()</span></code></a>).</p>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>This is an <strong>in-place</strong> operation as you can see that the function
name ends with <cite>_</cite>.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>requires_grad</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – If autograd should record operations on this FSA or not.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Fsa</span></code></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>This FSA itself.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="set-scores-stochastic">
<h3><a class="reference internal" href="#set-scores-stochastic">set_scores_stochastic</a><a class="headerlink" href="#set-scores-stochastic" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.Fsa.set_scores_stochastic_">
<span class="sig-prename descclassname"><span class="pre">Fsa.</span></span><span class="sig-name descname"><span class="pre">set_scores_stochastic_</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">scores</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/k2-fsa/k2/blob/master/k2/python/k2/fsa.py#L1373-L1397"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#k2.Fsa.set_scores_stochastic_" title="Permalink to this definition"></a></dt>
<dd><p>Normalize the given <cite>scores</cite> and assign it to <cite>self.scores</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>scores</strong> – Tensor of scores of dtype torch.float32, and shape equal to
<cite>self.scores.shape</cite> (one axis). Will be normalized so the
sum, after exponentiating, of the scores leaving each state
that has at least one arc leaving it is 1.</p>
</dd>
</dl>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>The function name ends with an underline indicating this function
will modify <cite>self</cite> <strong>in-place</strong>.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

</section>
<section id="id8">
<h3>to<a class="headerlink" href="#id8" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.Fsa.to">
<span class="sig-prename descclassname"><span class="pre">Fsa.</span></span><span class="sig-name descname"><span class="pre">to</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">device</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/k2-fsa/k2/blob/master/k2/python/k2/fsa.py#L1084-L1120"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#k2.Fsa.to" title="Permalink to this definition"></a></dt>
<dd><p>Move the FSA onto a given device.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>device</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">device</span></code>]) – An instance of <cite>torch.device</cite> or a string that can be used to
construct a <cite>torch.device</cite>, e.g., ‘cpu’, ‘cuda:0’.
It supports only cpu and cuda devices.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Fsa</span></code></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Returns a new Fsa which is this object copied to the given device
(or this object itself, if the device was the same)</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="id9">
<h3>device<a class="headerlink" href="#id9" title="Permalink to this headline"></a></h3>
<dl class="py attribute">
<dt class="sig sig-object py" id="k2.Fsa.device">
<span class="sig-prename descclassname"><span class="pre">Fsa.</span></span><span class="sig-name descname"><span class="pre">device</span></span><a class="headerlink" href="#k2.Fsa.device" title="Permalink to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">device</span></code></p>
</dd>
</dl>
</dd></dl>

</section>
<section id="grad">
<h3>grad<a class="headerlink" href="#grad" title="Permalink to this headline"></a></h3>
<dl class="py attribute">
<dt class="sig sig-object py" id="k2.Fsa.grad">
<span class="sig-prename descclassname"><span class="pre">Fsa.</span></span><span class="sig-name descname"><span class="pre">grad</span></span><a class="headerlink" href="#k2.Fsa.grad" title="Permalink to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></p>
</dd>
</dl>
</dd></dl>

</section>
<section id="labels">
<h3>labels<a class="headerlink" href="#labels" title="Permalink to this headline"></a></h3>
<dl class="py attribute">
<dt class="sig sig-object py" id="k2.Fsa.labels">
<span class="sig-prename descclassname"><span class="pre">Fsa.</span></span><span class="sig-name descname"><span class="pre">labels</span></span><a class="headerlink" href="#k2.Fsa.labels" title="Permalink to this definition"></a></dt>
<dd><p>Return the labels.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Return a 1-D <cite>torch.Tensor</cite> with dtype <cite>torch.int32</cite>.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="num-arcs">
<h3>num_arcs<a class="headerlink" href="#num-arcs" title="Permalink to this headline"></a></h3>
<dl class="py attribute">
<dt class="sig sig-object py" id="k2.Fsa.num_arcs">
<span class="sig-prename descclassname"><span class="pre">Fsa.</span></span><span class="sig-name descname"><span class="pre">num_arcs</span></span><a class="headerlink" href="#k2.Fsa.num_arcs" title="Permalink to this definition"></a></dt>
<dd><p>Return the number of arcs in this Fsa.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></p>
</dd>
</dl>
</dd></dl>

</section>
<section id="properties">
<h3>properties<a class="headerlink" href="#properties" title="Permalink to this headline"></a></h3>
<dl class="py attribute">
<dt class="sig sig-object py" id="k2.Fsa.properties">
<span class="sig-prename descclassname"><span class="pre">Fsa.</span></span><span class="sig-name descname"><span class="pre">properties</span></span><a class="headerlink" href="#k2.Fsa.properties" title="Permalink to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></p>
</dd>
</dl>
</dd></dl>

</section>
<section id="properties-str">
<h3>properties_str<a class="headerlink" href="#properties-str" title="Permalink to this headline"></a></h3>
<dl class="py attribute">
<dt class="sig sig-object py" id="k2.Fsa.properties_str">
<span class="sig-prename descclassname"><span class="pre">Fsa.</span></span><span class="sig-name descname"><span class="pre">properties_str</span></span><a class="headerlink" href="#k2.Fsa.properties_str" title="Permalink to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></p>
</dd>
</dl>
</dd></dl>

</section>
<section id="id10">
<h3>requires_grad<a class="headerlink" href="#id10" title="Permalink to this headline"></a></h3>
<dl class="py attribute">
<dt class="sig sig-object py" id="k2.Fsa.requires_grad">
<span class="sig-prename descclassname"><span class="pre">Fsa.</span></span><span class="sig-name descname"><span class="pre">requires_grad</span></span><a class="headerlink" href="#k2.Fsa.requires_grad" title="Permalink to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></p>
</dd>
</dl>
</dd></dl>

</section>
<section id="shape">
<h3>shape<a class="headerlink" href="#shape" title="Permalink to this headline"></a></h3>
<dl class="py attribute">
<dt class="sig sig-object py" id="k2.Fsa.shape">
<span class="sig-prename descclassname"><span class="pre">Fsa.</span></span><span class="sig-name descname"><span class="pre">shape</span></span><a class="headerlink" href="#k2.Fsa.shape" title="Permalink to this definition"></a></dt>
<dd><p>Returns:
<cite>(num_states, None)</cite> if this is an Fsa;
<cite>(num_fsas, None, None)</cite> if this is an FsaVec.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>, …]</p>
</dd>
</dl>
</dd></dl>

</section>
</section>
<section id="nbest">
<h2>Nbest<a class="headerlink" href="#nbest" title="Permalink to this headline"></a></h2>
<section id="id11">
<h3>intersect<a class="headerlink" href="#id11" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.Nbest.intersect">
<span class="sig-prename descclassname"><span class="pre">Nbest.</span></span><span class="sig-name descname"><span class="pre">intersect</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">lats</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/k2-fsa/k2/blob/master/k2/python/k2/nbest.py#L50-L88"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#k2.Nbest.intersect" title="Permalink to this definition"></a></dt>
<dd><p>Intersect this Nbest object with a lattice and get 1-best
path from the resulting FsaVec.</p>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>We assume FSAs in <cite>self.fsa</cite> don’t have epsilon self-loops.
We also assume <cite>self.fsa.labels</cite> and <cite>lats.labels</cite> are token IDs.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>lats</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Fsa</span></code>) – An FsaVec. It can be the return value of
<code class="xref py py-func docutils literal notranslate"><span class="pre">whole_lattice_rescoring()</span></code>.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Nbest</span></code></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Return a new Nbest. This new Nbest shares the same shape with <cite>self</cite>,
while its <cite>fsa</cite> is the 1-best path from intersecting <cite>self.fsa</cite> and
<a href="#id12"><span class="problematic" id="id13">`</span></a>lats.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="top-k">
<h3>top_k<a class="headerlink" href="#top-k" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.Nbest.top_k">
<span class="sig-prename descclassname"><span class="pre">Nbest.</span></span><span class="sig-name descname"><span class="pre">top_k</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">k</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/k2-fsa/k2/blob/master/k2/python/k2/nbest.py#L104-L142"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#k2.Nbest.top_k" title="Permalink to this definition"></a></dt>
<dd><p>Get a subset of paths in the Nbest. The resulting Nbest is regular
in that each sequence (i.e., utterance) has the same number of
paths (k).</p>
<p>We select the top-k paths according to the total_scores of each path.
If a utterance has less than k paths, then its last path, after sorting
by tot_scores in descending order, is repeated so that each utterance
has exactly k paths.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>k</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – Number of paths in each utterance.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Nbest</span></code></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Return a new Nbest with a regular shape.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="total-scores">
<h3>total_scores<a class="headerlink" href="#total-scores" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.Nbest.total_scores">
<span class="sig-prename descclassname"><span class="pre">Nbest.</span></span><span class="sig-name descname"><span class="pre">total_scores</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/k2-fsa/k2/blob/master/k2/python/k2/nbest.py#L90-L102"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#k2.Nbest.total_scores" title="Permalink to this definition"></a></dt>
<dd><p>Get total scores of the FSAs in this Nbest.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Since FSAs in Nbest are just linear FSAs, log-semirng and tropical
semiring produce the same total scores.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">RaggedTensor</span></code></p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Return a ragged tensor with two axes [utt][path_scores].</p>
</dd>
</dl>
</dd></dl>

</section>
</section>
<section id="raggedshape">
<h2>RaggedShape<a class="headerlink" href="#raggedshape" title="Permalink to this headline"></a></h2>
<section id="eq">
<h3>__eq__<a class="headerlink" href="#eq" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.RaggedShape.__eq__">
<span class="sig-prename descclassname"><span class="pre">RaggedShape.</span></span><span class="sig-name descname"><span class="pre">__eq__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">k2.ragged.RaggedShape</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">other</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">k2.ragged.RaggedShape</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">bool</span></span></span><a class="headerlink" href="#k2.RaggedShape.__eq__" title="Permalink to this definition"></a></dt>
<dd><p>Return <code class="docutils literal notranslate"><span class="pre">True</span></code> if two shapes are equal. Otherwise, return <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>The two shapes have to be on the same device. Otherwise, it throws
an exception.</p>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape1</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedShape</span><span class="p">(</span><span class="s1">&#39;[ [] [x] ]&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape2</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedShape</span><span class="p">(</span><span class="s1">&#39;[ [x] [x] ]&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape3</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedShape</span><span class="p">(</span><span class="s1">&#39;[ [x] [x] ]&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape1</span> <span class="o">==</span> <span class="n">shape2</span>
<span class="go">False</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape3</span> <span class="o">==</span> <span class="n">shape2</span>
<span class="go">True</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>other</strong> – The shape that we want to compare with <code class="docutils literal notranslate"><span class="pre">self</span></code>.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Return <code class="docutils literal notranslate"><span class="pre">True</span></code> if the two shapes are the same.
Return <code class="docutils literal notranslate"><span class="pre">False</span></code> otherwise.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="id14">
<h3>__getitem__<a class="headerlink" href="#id14" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.RaggedShape.__getitem__">
<span class="sig-prename descclassname"><span class="pre">RaggedShape.</span></span><span class="sig-name descname"><span class="pre">__getitem__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">k2.ragged.RaggedShape</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">i</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">k2.ragged.RaggedShape</span></span></span><a class="headerlink" href="#k2.RaggedShape.__getitem__" title="Permalink to this definition"></a></dt>
<dd><p>Select the i-th sublist along axis 0.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>It requires that this shape has at least 3 axes.</p>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedShape</span><span class="p">(</span><span class="s1">&#39;[ [[x] [x x]] [[x x x] [] [x x]] ]&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="go">[ [ x ] [ x x ] ]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="go">[ [ x x x ] [ ] [ x x ] ]</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>i</strong> – The i-th sublist along axis 0.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Return a new ragged shape with one fewer axis.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="id15">
<h3>__init__<a class="headerlink" href="#id15" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.RaggedShape.__init__">
<span class="sig-prename descclassname"><span class="pre">RaggedShape.</span></span><span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">k2.ragged.RaggedShape</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">s</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#k2.RaggedShape.__init__" title="Permalink to this definition"></a></dt>
<dd><p>Construct a ragged shape from a string.</p>
<p>An example string for a ragged shape with 2 axes is:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span> <span class="p">[</span><span class="n">x</span> <span class="n">x</span><span class="p">]</span> <span class="p">[</span> <span class="p">]</span> <span class="p">[</span><span class="n">x</span><span class="p">]</span> <span class="p">]</span>
</pre></div>
</div>
<p>An example string for a ragged shape with 3 axes is:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span> <span class="p">[[</span><span class="n">x</span><span class="p">]</span> <span class="p">[]]</span> <span class="p">[[</span><span class="n">x</span><span class="p">]</span> <span class="p">[</span><span class="n">x</span> <span class="n">x</span><span class="p">]]</span> <span class="p">]</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedShape</span><span class="p">(</span><span class="s1">&#39;[ [x] [] [x x] ]&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape</span>
<span class="go">[ [ x ] [ ] [ x x ] ]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape2</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedShape</span><span class="p">(</span><span class="s1">&#39;[ [[x] [] [x x]] [[]] ]&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape2</span>
<span class="go">[ [ [ x ] [ ] [ x x ] ] [ [ ] ] ]</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="ne">
<h3>__ne__<a class="headerlink" href="#ne" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.RaggedShape.__ne__">
<span class="sig-prename descclassname"><span class="pre">RaggedShape.</span></span><span class="sig-name descname"><span class="pre">__ne__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">k2.ragged.RaggedShape</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">other</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">k2.ragged.RaggedShape</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">bool</span></span></span><a class="headerlink" href="#k2.RaggedShape.__ne__" title="Permalink to this definition"></a></dt>
<dd><p>Return <code class="docutils literal notranslate"><span class="pre">True</span></code> if two shapes are not equal. Otherwise, return <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>The two shapes have to be on the same device. Otherwise, it throws
an exception.</p>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape1</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedShape</span><span class="p">(</span><span class="s1">&#39;[ [] [x] ]&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape2</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedShape</span><span class="p">(</span><span class="s1">&#39;[ [x] [x] ]&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape3</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedShape</span><span class="p">(</span><span class="s1">&#39;[ [x] [x] ]&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape1</span> <span class="o">!=</span> <span class="n">shape2</span>
<span class="go">True</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape2</span> <span class="o">!=</span> <span class="n">shape3</span>
<span class="go">False</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>other</strong> – The shape that we want to compare with <code class="docutils literal notranslate"><span class="pre">self</span></code>.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Return <code class="docutils literal notranslate"><span class="pre">True</span></code> if the two shapes are not equal.
Return <code class="docutils literal notranslate"><span class="pre">False</span></code> otherwise.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="repr">
<h3>__repr__<a class="headerlink" href="#repr" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.RaggedShape.__repr__">
<span class="sig-prename descclassname"><span class="pre">RaggedShape.</span></span><span class="sig-name descname"><span class="pre">__repr__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">k2.ragged.RaggedShape</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">str</span></span></span><a class="headerlink" href="#k2.RaggedShape.__repr__" title="Permalink to this definition"></a></dt>
<dd><p>Return a string representation of this shape.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedShape</span><span class="p">(</span><span class="s1">&#39;[ [x] [] [x x ] ]&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
<span class="go">[ [ x ] [ ] [ x x ] ]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape</span>
<span class="go">[ [ x ] [ ] [ x x ] ]</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="id16">
<h3>__str__<a class="headerlink" href="#id16" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.RaggedShape.__str__">
<span class="sig-prename descclassname"><span class="pre">RaggedShape.</span></span><span class="sig-name descname"><span class="pre">__str__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">k2.ragged.RaggedShape</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">str</span></span></span><a class="headerlink" href="#k2.RaggedShape.__str__" title="Permalink to this definition"></a></dt>
<dd><p>Return a string representation of this shape.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedShape</span><span class="p">(</span><span class="s1">&#39;[ [x] [] [x x ] ]&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
<span class="go">[ [ x ] [ ] [ x x ] ]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape</span>
<span class="go">[ [ x ] [ ] [ x x ] ]</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="id17">
<h3>compose<a class="headerlink" href="#id17" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.RaggedShape.compose">
<span class="sig-prename descclassname"><span class="pre">RaggedShape.</span></span><span class="sig-name descname"><span class="pre">compose</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">k2.ragged.RaggedShape</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">other</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">k2.ragged.RaggedShape</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">k2.ragged.RaggedShape</span></span></span><a class="headerlink" href="#k2.RaggedShape.compose" title="Permalink to this definition"></a></dt>
<dd><p>Compose <code class="docutils literal notranslate"><span class="pre">self</span></code> with a given shape.</p>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p><code class="docutils literal notranslate"><span class="pre">other</span></code> and <code class="docutils literal notranslate"><span class="pre">self</span></code> MUST be on the same device.</p>
</div>
<div class="admonition hint">
<p class="admonition-title">Hint</p>
<p>In order to compose <code class="docutils literal notranslate"><span class="pre">self</span></code> with <code class="docutils literal notranslate"><span class="pre">other</span></code>, it has to
satisfy <code class="docutils literal notranslate"><span class="pre">self.tot_size(self.num_axes</span> <span class="pre">-</span> <span class="pre">1)</span> <span class="pre">==</span> <span class="pre">other.dim0</span></code></p>
</div>
<p><strong>Example 1</strong>:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape1</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedShape</span><span class="p">(</span><span class="s1">&#39;[ [x x] [x] ]&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape2</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedShape</span><span class="p">(</span><span class="s1">&#39;[ [x x x] [x x] [] ]&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape1</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">shape2</span><span class="p">)</span>
<span class="go">[ [ [ x x x ] [ x x ] ] [ [ ] ] ]</span>
</pre></div>
</div>
<p><strong>Example 2</strong>:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape1</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedShape</span><span class="p">(</span><span class="s1">&#39;[ [[x x] [x x x] []] [[x] [x x x x]] ]&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape2</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedShape</span><span class="p">(</span><span class="s1">&#39;[ [x] [x x x] [] [] [x x] [x] [] [x x x x] [] [x x] ]&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape1</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">shape2</span><span class="p">)</span>
<span class="go">[ [ [ [ x ] [ x x x ] ] [ [ ] [ ] [ x x ] ] [ ] ] [ [ [ x ] ] [ [ ] [ x x x x ] [ ] [ x x ] ] ] ]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape1</span><span class="o">.</span><span class="n">tot_size</span><span class="p">(</span><span class="n">shape1</span><span class="o">.</span><span class="n">num_axes</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
<span class="go">10</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape2</span><span class="o">.</span><span class="n">dim0</span>
<span class="go">10</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>other</strong> – The other shape that is to be composed with <code class="docutils literal notranslate"><span class="pre">self</span></code>.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Return a composed ragged shape.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="get-layer">
<h3>get_layer<a class="headerlink" href="#get-layer" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.RaggedShape.get_layer">
<span class="sig-prename descclassname"><span class="pre">RaggedShape.</span></span><span class="sig-name descname"><span class="pre">get_layer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">k2.ragged.RaggedShape</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">arg0</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">k2.ragged.RaggedShape</span></span></span><a class="headerlink" href="#k2.RaggedShape.get_layer" title="Permalink to this definition"></a></dt>
<dd><p>Returns a <cite>sub-shape</cite> of <code class="docutils literal notranslate"><span class="pre">self</span></code>.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedShape</span><span class="p">(</span><span class="s1">&#39;[ [[x x] [x] []] [[] [x x x] [x]] [[]] ]&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape</span><span class="o">.</span><span class="n">get_layer</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="go">[ [ x x x ] [ x x x ] [ x ] ]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape</span><span class="o">.</span><span class="n">get_layer</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="go">[ [ x x ] [ x ] [ ] [ ] [ x x x ] [ x ] [ ] ]</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>layer</strong> – Layer that is desired, from <code class="docutils literal notranslate"><span class="pre">0</span> <span class="pre">..</span> <span class="pre">src.num_axes</span> <span class="pre">-</span> <span class="pre">2</span></code> (inclusive).</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>This returned shape will have <code class="docutils literal notranslate"><span class="pre">num_axes</span> <span class="pre">==</span> <span class="pre">2</span></code>, the minimal case of
a <code class="xref py py-class docutils literal notranslate"><span class="pre">RaggedShape</span></code>.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="index">
<h3>index<a class="headerlink" href="#index" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.RaggedShape.index">
<span class="sig-prename descclassname"><span class="pre">RaggedShape.</span></span><span class="sig-name descname"><span class="pre">index</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">k2.ragged.RaggedShape</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axis</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">indexes</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">need_value_indexes</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">k2.ragged.RaggedShape</span><span class="p"><span class="pre">,</span> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#k2.RaggedShape.index" title="Permalink to this definition"></a></dt>
<dd><p>Indexing operation on a ragged shape, returns <code class="docutils literal notranslate"><span class="pre">self[indexes]</span></code>, where elements
of <code class="docutils literal notranslate"><span class="pre">indexes</span></code> are interpreted as indexes into axis <code class="docutils literal notranslate"><span class="pre">axis</span></code> of self``.</p>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p><code class="docutils literal notranslate"><span class="pre">indexes</span></code> is a 1-D tensor and <code class="docutils literal notranslate"><span class="pre">indexes.dtype</span> <span class="pre">==</span> <span class="pre">torch.int32</span></code>.</p>
</div>
<p><strong>Example 1</strong>:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">shape</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedShape</span><span class="p">(</span><span class="s1">&#39;[ [x x] [x] [x x x] ]&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">value</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="o">*</span> <span class="mi">10</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ragged</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ragged</span>
<span class="go">[ [ 0 10 ] [ 20 ] [ 30 40 50 ] ]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">i</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sub_shape</span><span class="p">,</span> <span class="n">value_indexes</span> <span class="o">=</span> <span class="n">shape</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">indexes</span><span class="o">=</span><span class="n">i</span><span class="p">,</span> <span class="n">need_value_indexes</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sub_shape</span>
<span class="go">[ [ x x ] [ x x x ] [ x ] ]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">value_indexes</span>
<span class="go">tensor([0, 1, 3, 4, 5, 2], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ragged</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">value_indexes</span><span class="o">.</span><span class="n">long</span><span class="p">()]</span>
<span class="go">tensor([ 0., 10., 30., 40., 50., 20.])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">k</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sub_shape2</span><span class="p">,</span> <span class="n">value_indexes2</span> <span class="o">=</span> <span class="n">shape</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">indexes</span><span class="o">=</span><span class="n">k</span><span class="p">,</span> <span class="n">need_value_indexes</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sub_shape2</span>
<span class="go">[ [ x x ] [ ] [ x ] [ x x ] [ x x x ] [ ] ]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">value_indexes2</span>
<span class="go">tensor([0, 1, 2, 0, 1, 3, 4, 5], dtype=torch.int32)</span>
</pre></div>
</div>
<p><strong>Example 2</strong>:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedShape</span><span class="p">(</span><span class="s1">&#39;[ [[x x] [x]] [[] [x x x] [x]] [[x] [] [] [x x]] ]&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">i</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">indexes</span><span class="o">=</span><span class="n">i</span><span class="p">)</span>
<span class="go">([ [ [ x x ] [ x ] ] [ [ x x x ] ] [ [ x ] [ ] [ x x ] ] ], tensor([0, 1, 2, 3, 4, 5, 7, 8, 9], dtype=torch.int32))</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>axis</strong> – The axis to be indexed. Must satisfy <code class="docutils literal notranslate"><span class="pre">0</span> <span class="pre">&lt;=</span> <span class="pre">axis</span> <span class="pre">&lt;</span> <span class="pre">self.num_axes</span></code>.</p></li>
<li><p><strong>indexes</strong> – Array of indexes, which will be interpreted as indexes into axis <code class="docutils literal notranslate"><span class="pre">axis</span></code>
of <code class="docutils literal notranslate"><span class="pre">self</span></code>, i.e. with <code class="docutils literal notranslate"><span class="pre">0</span> <span class="pre">&lt;=</span> <span class="pre">indexes[i]</span> <span class="pre">&lt;</span> <span class="pre">self.tot_size(axis)</span></code>.
Note that if <code class="docutils literal notranslate"><span class="pre">axis</span></code> is 0, then -1 is also a valid entry in <code class="docutils literal notranslate"><span class="pre">index</span></code>,
in which case, an empty list is returned.</p></li>
<li><p><strong>need_value_indexes</strong> – <p>If <code class="docutils literal notranslate"><span class="pre">True</span></code>, it will return a torch.Tensor containing the indexes into
<code class="docutils literal notranslate"><span class="pre">ragged_tensor.data</span></code> that <code class="docutils literal notranslate"><span class="pre">ans.data</span></code> has, as in
<code class="docutils literal notranslate"><span class="pre">ans.data</span> <span class="pre">=</span> <span class="pre">ragged_tensor.data[value_indexes]</span></code>, where <code class="docutils literal notranslate"><span class="pre">ragged_tensor</span></code>
uses <code class="docutils literal notranslate"><span class="pre">self</span></code> as its shape.</p>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>It is currently not allowed to change the order on axes less than
<code class="docutils literal notranslate"><span class="pre">axis</span></code>, i.e. if <code class="docutils literal notranslate"><span class="pre">axis</span> <span class="pre">&gt;</span> <span class="pre">0</span></code>, we require:
<code class="docutils literal notranslate"><span class="pre">IsMonotonic(self.row_ids(axis)[indexes])</span></code>.</p>
</div>
</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Return an indexed ragged shape.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="max-size">
<h3>max_size<a class="headerlink" href="#max-size" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.RaggedShape.max_size">
<span class="sig-prename descclassname"><span class="pre">RaggedShape.</span></span><span class="sig-name descname"><span class="pre">max_size</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">k2.ragged.RaggedShape</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axis</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">int</span></span></span><a class="headerlink" href="#k2.RaggedShape.max_size" title="Permalink to this definition"></a></dt>
<dd><p>Return the maximum number of elements of any sublist at the given axis.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedShape</span><span class="p">(</span><span class="s1">&#39;[ [] [x] [x x] [x x x] [x x x x] ]&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape</span><span class="o">.</span><span class="n">max_size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="go">4</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedShape</span><span class="p">(</span><span class="s1">&#39;[ [[x x] [x] [] [] []] [[x]] [[x x x x]] ]&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape</span><span class="o">.</span><span class="n">max_size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="go">5</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape</span><span class="o">.</span><span class="n">max_size</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="go">4</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>axis</strong> – <p>Compute the max size of this axis.</p>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p><code class="docutils literal notranslate"><span class="pre">axis</span></code> has to be greater than 0.</p>
</div>
</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Return the maximum number of elements of sublists at the given <code class="docutils literal notranslate"><span class="pre">axis</span></code>.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="numel">
<h3>numel<a class="headerlink" href="#numel" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.RaggedShape.numel">
<span class="sig-prename descclassname"><span class="pre">RaggedShape.</span></span><span class="sig-name descname"><span class="pre">numel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">k2.ragged.RaggedShape</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">int</span></span></span><a class="headerlink" href="#k2.RaggedShape.numel" title="Permalink to this definition"></a></dt>
<dd><p>Return the number of elements in this shape.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedShape</span><span class="p">(</span><span class="s1">&#39;[ [x] [] [x x x x x]]&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span>
<span class="go">6</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape2</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedShape</span><span class="p">(</span><span class="s1">&#39;[ [[x x] [x] [] [] []] [[x]] [[x x x x]] ]&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape2</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span>
<span class="go">8</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape3</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedShape</span><span class="p">(</span><span class="s1">&#39;[ [x x x] [x] ]&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape3</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span>
<span class="go">4</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><p>Return the number of elements in this shape.</p>
<div class="admonition hint">
<p class="admonition-title">Hint</p>
<p>It’s the number of <code class="docutils literal notranslate"><span class="pre">x</span></code>’s.</p>
</div>
</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="regular-ragged-shape">
<h3>regular_ragged_shape<a class="headerlink" href="#regular-ragged-shape" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.RaggedShape.regular_ragged_shape">
<em class="property"><span class="pre">static</span> </em><span class="sig-prename descclassname"><span class="pre">RaggedShape.</span></span><span class="sig-name descname"><span class="pre">regular_ragged_shape</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dim0</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dim1</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">k2.ragged.RaggedShape</span></span></span><a class="headerlink" href="#k2.RaggedShape.regular_ragged_shape" title="Permalink to this definition"></a></dt>
<dd><p>Create a ragged shape with 2 axes that has a regular structure.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape1</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedShape</span><span class="o">.</span><span class="n">regular_ragged_shape</span><span class="p">(</span><span class="n">dim0</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim1</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape1</span>
<span class="go">[ [ x x x ] [ x x x ] ]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape2</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">regular_ragged_shape</span><span class="p">(</span><span class="n">dim0</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">dim1</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape2</span>
<span class="go">[ [ x x ] [ x x ] [ x x ] ]</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dim0</strong> – Number of entries at axis 0.</p></li>
<li><p><strong>dim1</strong> – Number of entries in each sublist at axis 1.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Return a ragged shape on CPU.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="remove-axis">
<h3>remove_axis<a class="headerlink" href="#remove-axis" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.RaggedShape.remove_axis">
<span class="sig-prename descclassname"><span class="pre">RaggedShape.</span></span><span class="sig-name descname"><span class="pre">remove_axis</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">k2.ragged.RaggedShape</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axis</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">k2.ragged.RaggedShape</span></span></span><a class="headerlink" href="#k2.RaggedShape.remove_axis" title="Permalink to this definition"></a></dt>
<dd><p>Remove a certain axis.</p>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p><code class="docutils literal notranslate"><span class="pre">self.num_axes</span></code> MUST be greater than 2.</p>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedShape</span><span class="p">(</span><span class="s1">&#39;[ [[x] [] [x x]] [[x x x] [x x x x]] [[] [] []]]&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape</span><span class="o">.</span><span class="n">remove_axis</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="go">[ [ x ] [ ] [ x x ] [ x x x ] [ x x x x ] [ ] [ ] [ ] ]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape</span><span class="o">.</span><span class="n">remove_axis</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="go">[ [ x x x ] [ x x x x x x x ] [ ] ]</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>axis</strong> – The axis to be removed.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Return a ragged shape with one fewer axis.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="row-ids">
<h3>row_ids<a class="headerlink" href="#row-ids" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.RaggedShape.row_ids">
<span class="sig-prename descclassname"><span class="pre">RaggedShape.</span></span><span class="sig-name descname"><span class="pre">row_ids</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">k2.ragged.RaggedShape</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axis</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="headerlink" href="#k2.RaggedShape.row_ids" title="Permalink to this definition"></a></dt>
<dd><p>Return the row ids of a certain <code class="docutils literal notranslate"><span class="pre">axis</span></code>.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedShape</span><span class="p">(</span><span class="s1">&#39;[ [x x] [] [x x x] ]&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape</span><span class="o">.</span><span class="n">row_ids</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="go">tensor([0, 0, 2, 2, 2], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape2</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedShape</span><span class="p">(</span><span class="s1">&#39;[ [[x] [] [x x]] [[x x x] [x] [x x x x] [] []] ]&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape2</span><span class="o">.</span><span class="n">row_ids</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="go">tensor([0, 0, 0, 1, 1, 1, 1, 1], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape2</span><span class="o">.</span><span class="n">row_ids</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="go">tensor([0, 2, 2, 3, 3, 3, 4, 5, 5, 5, 5], dtype=torch.int32)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>axis</strong> – The axis whose row ids is to be returned.</p></li>
<li><p><strong>Hint</strong> – <code class="docutils literal notranslate"><span class="pre">axis</span> <span class="pre">&gt;=</span> <span class="pre">1</span></code>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Return the row ids of the given <code class="docutils literal notranslate"><span class="pre">axis</span></code>.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="row-splits">
<h3>row_splits<a class="headerlink" href="#row-splits" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.RaggedShape.row_splits">
<span class="sig-prename descclassname"><span class="pre">RaggedShape.</span></span><span class="sig-name descname"><span class="pre">row_splits</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">k2.ragged.RaggedShape</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axis</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="headerlink" href="#k2.RaggedShape.row_splits" title="Permalink to this definition"></a></dt>
<dd><p>Return the row splits of a certain <code class="docutils literal notranslate"><span class="pre">axis</span></code>.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedShape</span><span class="p">(</span><span class="s1">&#39;[ [x x] [] [x x x] ]&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape</span><span class="o">.</span><span class="n">row_splits</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="go">tensor([0, 2, 2, 5], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape2</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedShape</span><span class="p">(</span><span class="s1">&#39;[ [[x] [] [x x]] [[x x x] [x] [x x x x] [] []] ]&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape2</span><span class="o">.</span><span class="n">row_splits</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="go">tensor([0, 3, 8], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape2</span><span class="o">.</span><span class="n">row_splits</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="go">tensor([ 0,  1,  1,  3,  6,  7, 11, 11, 11], dtype=torch.int32)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>axis</strong> – The axis whose row splits is to be returned.</p></li>
<li><p><strong>Hint</strong> – <code class="docutils literal notranslate"><span class="pre">axis</span> <span class="pre">&gt;=</span> <span class="pre">1</span></code>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Return the row splits of the given <code class="docutils literal notranslate"><span class="pre">axis</span></code>.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="id18">
<h3>to<a class="headerlink" href="#id18" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.RaggedShape.to">
<span class="sig-prename descclassname"><span class="pre">RaggedShape.</span></span><span class="sig-name descname"><span class="pre">to</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="pre">self:</span> <span class="pre">k2.ragged.RaggedShape</span></em>, <em class="sig-param"><span class="pre">device:</span> <span class="pre">torch::Device</span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">k2.ragged.RaggedShape</span></span></span><a class="headerlink" href="#k2.RaggedShape.to" title="Permalink to this definition"></a></dt>
<dd><p>Move this shape to the specified device.</p>
<div class="admonition hint">
<p class="admonition-title">Hint</p>
<p>If the shape is already on the specified device, the returned shape
shares the underlying memory with <code class="docutils literal notranslate"><span class="pre">self</span></code>.</p>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedShape</span><span class="p">(</span><span class="s1">&#39;[[x]]&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape</span><span class="o">.</span><span class="n">device</span>
<span class="go">device(type=&#39;cpu&#39;)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape2</span> <span class="o">=</span> <span class="n">shape</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cuda&#39;</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape2</span><span class="o">.</span><span class="n">device</span>
<span class="go">device(type=&#39;cuda&#39;, index=0)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape</span>
<span class="go">[ [ x ] ]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape2</span>
<span class="go">[ [ x ] ]</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>device</strong> – An instance of <code class="docutils literal notranslate"><span class="pre">torch.device</span></code>. It can be either a CPU device or
a CUDA device.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Return a shape on the given device.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="tot-size">
<h3>tot_size<a class="headerlink" href="#tot-size" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.RaggedShape.tot_size">
<span class="sig-prename descclassname"><span class="pre">RaggedShape.</span></span><span class="sig-name descname"><span class="pre">tot_size</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">k2.ragged.RaggedShape</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axis</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">int</span></span></span><a class="headerlink" href="#k2.RaggedShape.tot_size" title="Permalink to this definition"></a></dt>
<dd><p>Return the number of elements at a certain``axis``.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedShape</span><span class="p">(</span><span class="s1">&#39;[ [x] [x x] [x x x] []]&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape</span><span class="o">.</span><span class="n">tot_size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="go">6</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span>
<span class="go">6</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape2</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedShape</span><span class="p">(</span><span class="s1">&#39;[ [[x]] [[x x]] [[x x x]] [[]] [[]] [[]] [[]] ]&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape2</span><span class="o">.</span><span class="n">tot_size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="go">7</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape2</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedShape</span><span class="p">(</span><span class="s1">&#39;[ [[x]] [[x x]] [[x x x]] [[]] [[]] [[]] [[] []] ]&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape2</span><span class="o">.</span><span class="n">tot_size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="go">8</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape2</span><span class="o">.</span><span class="n">tot_size</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="go">6</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape2</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span>
<span class="go">6</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>axis</strong> – Return the number of elements for this <code class="docutils literal notranslate"><span class="pre">axis</span></code>.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Return the number of elements at <code class="docutils literal notranslate"><span class="pre">axis</span></code>.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="tot-sizes">
<h3>tot_sizes<a class="headerlink" href="#tot-sizes" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.RaggedShape.tot_sizes">
<span class="sig-prename descclassname"><span class="pre">RaggedShape.</span></span><span class="sig-name descname"><span class="pre">tot_sizes</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">k2.ragged.RaggedShape</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">tuple</span></span></span><a class="headerlink" href="#k2.RaggedShape.tot_sizes" title="Permalink to this definition"></a></dt>
<dd><p>Return total sizes of every axis in a tuple.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedShape</span><span class="p">(</span><span class="s1">&#39;[ [x] [ ] [x x x x]]&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape</span><span class="o">.</span><span class="n">dim0</span>
<span class="go">3</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape</span><span class="o">.</span><span class="n">tot_size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="go">5</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape</span><span class="o">.</span><span class="n">tot_sizes</span><span class="p">()</span>
<span class="go">(3, 5)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape2</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedShape</span><span class="p">(</span><span class="s1">&#39;[ [[x] []] [[x x x x]]]&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape2</span><span class="o">.</span><span class="n">dim0</span>
<span class="go">2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape2</span><span class="o">.</span><span class="n">tot_size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="go">3</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape2</span><span class="o">.</span><span class="n">tot_size</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="go">5</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape2</span><span class="o">.</span><span class="n">tot_sizes</span><span class="p">()</span>
<span class="go">(2, 3, 5)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Return a tuple containing the total sizes of each axis.
<code class="docutils literal notranslate"><span class="pre">ans[i]</span></code> is the total size of axis <code class="docutils literal notranslate"><span class="pre">i</span></code> (for <code class="docutils literal notranslate"><span class="pre">i</span> <span class="pre">&gt;</span> <span class="pre">0</span></code>).
For <code class="docutils literal notranslate"><span class="pre">i=0</span></code>, it is the <code class="docutils literal notranslate"><span class="pre">dim0</span></code> of this shape.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="id19">
<h3>device<a class="headerlink" href="#id19" title="Permalink to this headline"></a></h3>
<dl class="py attribute">
<dt class="sig sig-object py" id="k2.RaggedShape.device">
<span class="sig-prename descclassname"><span class="pre">RaggedShape.</span></span><span class="sig-name descname"><span class="pre">device</span></span><a class="headerlink" href="#k2.RaggedShape.device" title="Permalink to this definition"></a></dt>
<dd><p>Return the device of this shape.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedShape</span><span class="p">(</span><span class="s1">&#39;[[]]&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape</span><span class="o">.</span><span class="n">device</span>
<span class="go">device(type=&#39;cpu&#39;)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape2</span> <span class="o">=</span> <span class="n">shape</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cuda&#39;</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape2</span><span class="o">.</span><span class="n">device</span>
<span class="go">device(type=&#39;cuda&#39;, index=0)</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="dim0">
<h3>dim0<a class="headerlink" href="#dim0" title="Permalink to this headline"></a></h3>
<dl class="py attribute">
<dt class="sig sig-object py" id="k2.RaggedShape.dim0">
<span class="sig-prename descclassname"><span class="pre">RaggedShape.</span></span><span class="sig-name descname"><span class="pre">dim0</span></span><a class="headerlink" href="#k2.RaggedShape.dim0" title="Permalink to this definition"></a></dt>
<dd><p>Return number of sublists at axis 0.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedShape</span><span class="p">(</span><span class="s1">&#39;[ [x] [] [x x x x x]]&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape</span><span class="o">.</span><span class="n">dim0</span>
<span class="go">3</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape2</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedShape</span><span class="p">(</span><span class="s1">&#39;[ [[x] []] [[]] [[x] [x x] [x x x]] [[]]]&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape2</span><span class="o">.</span><span class="n">dim0</span>
<span class="go">4</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="num-axes">
<h3>num_axes<a class="headerlink" href="#num-axes" title="Permalink to this headline"></a></h3>
<dl class="py attribute">
<dt class="sig sig-object py" id="k2.RaggedShape.num_axes">
<span class="sig-prename descclassname"><span class="pre">RaggedShape.</span></span><span class="sig-name descname"><span class="pre">num_axes</span></span><a class="headerlink" href="#k2.RaggedShape.num_axes" title="Permalink to this definition"></a></dt>
<dd><p>Return the number of axes of this shape.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedShape</span><span class="p">(</span><span class="s1">&#39;[[] []]&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape</span><span class="o">.</span><span class="n">num_axes</span>
<span class="go">2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape2</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedShape</span><span class="p">(</span><span class="s1">&#39;[ [[]] [[]]]&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape2</span><span class="o">.</span><span class="n">num_axes</span>
<span class="go">3</span>
</pre></div>
</div>
</dd></dl>

</section>
</section>
<section id="raggedtensor">
<h2>RaggedTensor<a class="headerlink" href="#raggedtensor" title="Permalink to this headline"></a></h2>
<section id="id20">
<h3>__eq__<a class="headerlink" href="#id20" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.RaggedTensor.__eq__">
<span class="sig-prename descclassname"><span class="pre">RaggedTensor.</span></span><span class="sig-name descname"><span class="pre">__eq__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">k2.ragged.RaggedTensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">other</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">k2.ragged.RaggedTensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">bool</span></span></span><a class="headerlink" href="#k2.RaggedTensor.__eq__" title="Permalink to this definition"></a></dt>
<dd><p>Compare two ragged tensors.</p>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>The two tensors MUST have the same dtype. Otherwise,
it throws an exception.</p>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">==</span>  <span class="n">b</span>
<span class="go">True</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">try</span><span class="p">:</span>
<span class="gp">... </span>  <span class="n">c</span> <span class="o">==</span> <span class="n">b</span>
<span class="gp">... </span><span class="k">except</span> <span class="ne">RuntimeError</span><span class="p">:</span>
<span class="gp">... </span>  <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;raised exception&quot;</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>other</strong> – The tensor to be compared.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Return <code class="docutils literal notranslate"><span class="pre">True</span></code> if the two tensors are equal.
Return <code class="docutils literal notranslate"><span class="pre">False</span></code> otherwise.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="id21">
<h3>__getitem__<a class="headerlink" href="#id21" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.RaggedTensor.__getitem__">
<span class="sig-prename descclassname"><span class="pre">RaggedTensor.</span></span><span class="sig-name descname"><span class="pre">__getitem__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#k2.RaggedTensor.__getitem__" title="Permalink to this definition"></a></dt>
<dd><p>Overloaded function.</p>
<ol class="arabic simple">
<li><p>__getitem__(self: k2.ragged.RaggedTensor, i: int) -&gt; object</p></li>
</ol>
<p>Select the i-th sublist along axis 0.</p>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>Support for autograd is to be implemented.</p>
</div>
<p><strong>Example 1</strong>:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">(</span><span class="s1">&#39;[ [[1 3] [] [9]]  [[8]] ]&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>
<span class="go">RaggedTensor([[[1, 3],</span>
<span class="go">               [],</span>
<span class="go">               [9]],</span>
<span class="go">              [[8]]], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="go">RaggedTensor([[1, 3],</span>
<span class="go">              [],</span>
<span class="go">              [9]], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="go">RaggedTensor([[8]], dtype=torch.int32)</span>
</pre></div>
</div>
<p><strong>Example 2</strong>:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">(</span><span class="s1">&#39;[ [1 3] [9] [8] ]&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>
<span class="go">RaggedTensor([[1, 3],</span>
<span class="go">              [9],</span>
<span class="go">              [8]], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="go">tensor([1, 3], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="go">tensor([9], dtype=torch.int32)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>i</strong> – The i-th sublist along axis 0.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Return a new ragged tensor with one fewer axis. If <cite>num_axes == 2</cite>, the
return value will be a 1D tensor.</p>
</dd>
</dl>
<ol class="arabic simple" start="2">
<li><p>__getitem__(self: k2.ragged.RaggedTensor, key: slice) -&gt; k2.ragged.RaggedTensor</p></li>
</ol>
<p>Slices sublists along axis 0 with the given range. Only support slicing step
equals to 1.</p>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>Support for autograd is to be implemented.</p>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">(</span><span class="s1">&#39;[ [[1 3] [] [9]]  [[8]] [[10 11]] ]&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>
<span class="go">RaggedTensor([[[1, 3],</span>
<span class="go">               [],</span>
<span class="go">               [9]],</span>
<span class="go">              [[8]],</span>
<span class="go">              [[10, 11]]], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">2</span><span class="p">]</span>
<span class="go">RaggedTensor([[[1, 3],</span>
<span class="go">               [],</span>
<span class="go">               [9]],</span>
<span class="go">              [[8]]], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="mi">2</span><span class="p">]</span>
<span class="go">RaggedTensor([[[8]]], dtype=torch.int32)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>key</strong> – Slice containing integer constants.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Return a new ragged tensor with the same axes as original ragged tensor, but
only contains the sublists within the range.</p>
</dd>
</dl>
<ol class="arabic simple" start="3">
<li><p>__getitem__(self: k2.ragged.RaggedTensor, key: torch.Tensor) -&gt; k2.ragged.RaggedTensor</p></li>
</ol>
<p>Slice a ragged tensor along axis 0 using a 1-D torch.int32 tensor.</p>
<p><strong>Example 1</strong>:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">k2</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">k2</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">],</span> <span class="p">[</span><span class="mi">300</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">10</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="go">tensor([1, 2, 0], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span><span class="p">[</span><span class="n">a</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>
<span class="go">RaggedTensor([[300],</span>
<span class="go">              [-10, 0, -1],</span>
<span class="go">              [10, 20]], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="go">tensor([0, 1], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span><span class="p">[</span><span class="n">a</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span>
<span class="go">RaggedTensor([[10, 20],</span>
<span class="go">              [300]], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
<span class="go">tensor([2, 3], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span><span class="p">[</span><span class="n">a</span><span class="p">[</span><span class="mi">2</span><span class="p">]]</span>
<span class="go">RaggedTensor([[-10, 0, -1],</span>
<span class="go">              [-2, 4, 5]], dtype=torch.int32)</span>
</pre></div>
</div>
<p><strong>Example 2</strong>:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">k2</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([</span> <span class="p">[[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">]],</span> <span class="p">[[],</span> <span class="p">[</span><span class="mi">2</span><span class="p">]],</span> <span class="p">[[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">]]</span> <span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">i</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
<span class="go">RaggedTensor([[[1],</span>
<span class="go">               [2, 3],</span>
<span class="go">               [0]],</span>
<span class="go">              [[10, 20]],</span>
<span class="go">              [[],</span>
<span class="go">               [2]],</span>
<span class="go">              [[1],</span>
<span class="go">               [2, 3],</span>
<span class="go">               [0]]], dtype=torch.int32)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>key</strong> – A 1-D torch.int32 tensor containing the indexes to select along
axis 0.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Return a new ragged tensor with the same number of axes as <code class="docutils literal notranslate"><span class="pre">self</span></code> but
only contains the specified sublists.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="getstate">
<h3>__getstate__<a class="headerlink" href="#getstate" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.RaggedTensor.__getstate__">
<span class="sig-prename descclassname"><span class="pre">RaggedTensor.</span></span><span class="sig-name descname"><span class="pre">__getstate__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">k2.ragged.Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">tuple</span></span></span><a class="headerlink" href="#k2.RaggedTensor.__getstate__" title="Permalink to this definition"></a></dt>
<dd><p>Requires a tensor with 2 axes or 3 axes. Other number
of axes are not implemented yet.</p>
<p>This method is to support <code class="docutils literal notranslate"><span class="pre">pickle</span></code>, e.g., used by <code class="docutils literal notranslate"><span class="pre">torch.save()</span></code>.
You are not expected to call it by yourself.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>If this tensor has 2 axes, return a tuple containing
(self.row_splits(1), “row_ids1”, self.values).
If this tensor has 3 axes, return a tuple containing
(self.row_splits(1), “row_ids1”, self.row_splits(1),
“row_ids2”, self.values)</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>“row_ids1” and “row_ids2” in the returned value is for
backward compatibility.</p>
</div>
</dd></dl>

</section>
<section id="id22">
<h3>__init__<a class="headerlink" href="#id22" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.RaggedTensor.__init__">
<span class="sig-prename descclassname"><span class="pre">RaggedTensor.</span></span><span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#k2.RaggedTensor.__init__" title="Permalink to this definition"></a></dt>
<dd><p>Overloaded function.</p>
<ol class="arabic simple">
<li><p>__init__(self: k2.ragged.RaggedTensor, data: list, dtype: object = None, device: torch::Device = device(type=’cpu’)) -&gt; None</p></li>
</ol>
<p>Create a ragged tensor with arbitrary number of axes.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>A ragged tensor has at least two axes.</p>
</div>
<p><strong>Example 1</strong>:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">5</span><span class="p">],</span> <span class="p">[],</span> <span class="p">[</span><span class="mi">9</span><span class="p">]</span> <span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>
<span class="go">RaggedTensor([[1, 2],</span>
<span class="go">              [5],</span>
<span class="go">              [],</span>
<span class="go">              [9]], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">dtype</span>
<span class="go">torch.int32</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">],</span> <span class="p">[]</span> <span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span>
<span class="go">RaggedTensor([[1, 3],</span>
<span class="go">              []], dtype=torch.float32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span><span class="o">.</span><span class="n">dtype</span>
<span class="go">torch.float32</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span>
<span class="go">RaggedTensor([[1]], dtype=torch.float64)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span><span class="o">.</span><span class="n">dtype</span>
<span class="go">torch.float64</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">d</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([</span> <span class="p">[[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]],</span> <span class="p">[[</span><span class="mi">4</span><span class="p">],</span> <span class="p">[]]</span> <span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">d</span>
<span class="go">RaggedTensor([[[1],</span>
<span class="go">               [2, 3]],</span>
<span class="go">              [[4],</span>
<span class="go">               []]], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">d</span><span class="o">.</span><span class="n">num_axes</span>
<span class="go">3</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">e</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">e</span>
<span class="go">RaggedTensor([], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">e</span><span class="o">.</span><span class="n">num_axes</span>
<span class="go">2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">e</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="n">row_splits</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="go">tensor([0], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">e</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="n">row_ids</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="go">tensor([], dtype=torch.int32)</span>
</pre></div>
</div>
<p><strong>Example 2</strong>:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([</span> <span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]],</span> <span class="p">[],</span> <span class="p">[[]]</span> <span class="p">])</span>
<span class="go">RaggedTensor([[[1, 2]],</span>
<span class="go">              [],</span>
<span class="go">              [[]]], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([</span> <span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]],</span> <span class="p">[],</span> <span class="p">[[]]</span> <span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cuda:0&#39;</span><span class="p">)</span>
<span class="go">RaggedTensor([[[1, 2]],</span>
<span class="go">              [],</span>
<span class="go">              [[]]], device=&#39;cuda:0&#39;, dtype=torch.int32)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> – A list-of sublist(s) of integers or real numbers.
It can have arbitrary number of axes (at least two).</p></li>
<li><p><strong>dtype</strong> – Optional. If None, it infers the dtype from <code class="docutils literal notranslate"><span class="pre">data</span></code>
automatically, which is either <code class="docutils literal notranslate"><span class="pre">torch.int32</span></code> or
<code class="docutils literal notranslate"><span class="pre">torch.float32</span></code>. Supported dtypes are: <code class="docutils literal notranslate"><span class="pre">torch.int32</span></code>,
<code class="docutils literal notranslate"><span class="pre">torch.float32</span></code>, and <code class="docutils literal notranslate"><span class="pre">torch.float64</span></code>.</p></li>
<li><p><strong>device</strong> – It can be either an instance of <code class="docutils literal notranslate"><span class="pre">torch.device</span></code> or
a string representing a torch device. Example
values are: <code class="docutils literal notranslate"><span class="pre">&quot;cpu&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">&quot;cuda:0&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">torch.device(&quot;cpu&quot;)</span></code>,
<code class="docutils literal notranslate"><span class="pre">torch.device(&quot;cuda&quot;,</span> <span class="pre">0)</span></code>.</p></li>
</ul>
</dd>
</dl>
<ol class="arabic simple" start="2">
<li><p>__init__(self: k2.ragged.RaggedTensor, data: list, dtype: object = None, device: str = ‘cpu’) -&gt; None</p></li>
</ol>
<p>Create a ragged tensor with arbitrary number of axes.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>A ragged tensor has at least two axes.</p>
</div>
<p><strong>Example 1</strong>:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">5</span><span class="p">],</span> <span class="p">[],</span> <span class="p">[</span><span class="mi">9</span><span class="p">]</span> <span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>
<span class="go">RaggedTensor([[1, 2],</span>
<span class="go">              [5],</span>
<span class="go">              [],</span>
<span class="go">              [9]], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">dtype</span>
<span class="go">torch.int32</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">],</span> <span class="p">[]</span> <span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span>
<span class="go">RaggedTensor([[1, 3],</span>
<span class="go">              []], dtype=torch.float32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span><span class="o">.</span><span class="n">dtype</span>
<span class="go">torch.float32</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span>
<span class="go">RaggedTensor([[1]], dtype=torch.float64)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span><span class="o">.</span><span class="n">dtype</span>
<span class="go">torch.float64</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">d</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([</span> <span class="p">[[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]],</span> <span class="p">[[</span><span class="mi">4</span><span class="p">],</span> <span class="p">[]]</span> <span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">d</span>
<span class="go">RaggedTensor([[[1],</span>
<span class="go">               [2, 3]],</span>
<span class="go">              [[4],</span>
<span class="go">               []]], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">d</span><span class="o">.</span><span class="n">num_axes</span>
<span class="go">3</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">e</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">e</span>
<span class="go">RaggedTensor([], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">e</span><span class="o">.</span><span class="n">num_axes</span>
<span class="go">2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">e</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="n">row_splits</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="go">tensor([0], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">e</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="n">row_ids</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="go">tensor([], dtype=torch.int32)</span>
</pre></div>
</div>
<p><strong>Example 2</strong>:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([</span> <span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]],</span> <span class="p">[],</span> <span class="p">[[]]</span> <span class="p">])</span>
<span class="go">RaggedTensor([[[1, 2]],</span>
<span class="go">              [],</span>
<span class="go">              [[]]], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([</span> <span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]],</span> <span class="p">[],</span> <span class="p">[[]]</span> <span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cuda:0&#39;</span><span class="p">)</span>
<span class="go">RaggedTensor([[[1, 2]],</span>
<span class="go">              [],</span>
<span class="go">              [[]]], device=&#39;cuda:0&#39;, dtype=torch.int32)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> – A list-of sublist(s) of integers or real numbers.
It can have arbitrary number of axes (at least two).</p></li>
<li><p><strong>dtype</strong> – Optional. If None, it infers the dtype from <code class="docutils literal notranslate"><span class="pre">data</span></code>
automatically, which is either <code class="docutils literal notranslate"><span class="pre">torch.int32</span></code> or
<code class="docutils literal notranslate"><span class="pre">torch.float32</span></code>. Supported dtypes are: <code class="docutils literal notranslate"><span class="pre">torch.int32</span></code>,
<code class="docutils literal notranslate"><span class="pre">torch.float32</span></code>, and <code class="docutils literal notranslate"><span class="pre">torch.float64</span></code>.</p></li>
<li><p><strong>device</strong> – It can be either an instance of <code class="docutils literal notranslate"><span class="pre">torch.device</span></code> or
a string representing a torch device. Example
values are: <code class="docutils literal notranslate"><span class="pre">&quot;cpu&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">&quot;cuda:0&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">torch.device(&quot;cpu&quot;)</span></code>,
<code class="docutils literal notranslate"><span class="pre">torch.device(&quot;cuda&quot;,</span> <span class="pre">0)</span></code>.</p></li>
</ul>
</dd>
</dl>
<ol class="arabic simple" start="3">
<li><p>__init__(self: k2.ragged.RaggedTensor, s: str, dtype: object = None, device: torch::Device = device(type=’cpu’)) -&gt; None</p></li>
</ol>
<p>Create a ragged tensor from its string representation.</p>
<p>Fields are separated by space(s) <strong>or</strong> comma(s).</p>
<p>An example string for a 2-axis ragged tensor is given below:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">5</span> <span class="mi">6</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">]</span> <span class="p">]</span>
</pre></div>
</div>
<p>An example string for a 3-axis ragged tensor is given below:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span> <span class="p">[[</span><span class="mi">1</span><span class="p">]]</span> <span class="p">[[]]</span> <span class="p">]</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">(</span><span class="s1">&#39;[ [1] [] [3 4] ]&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>
<span class="go">RaggedTensor([[1],</span>
<span class="go">              [],</span>
<span class="go">              [3, 4]], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">num_axes</span>
<span class="go">2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">dtype</span>
<span class="go">torch.int32</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">(</span><span class="s1">&#39;[ [[] [3]]  [[10]] ]&#39;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span>
<span class="go">RaggedTensor([[[],</span>
<span class="go">               [3]],</span>
<span class="go">              [[10]]], dtype=torch.float32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span><span class="o">.</span><span class="n">dtype</span>
<span class="go">torch.float32</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span><span class="o">.</span><span class="n">num_axes</span>
<span class="go">3</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">(</span><span class="s1">&#39;[[1.]]&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span><span class="o">.</span><span class="n">dtype</span>
<span class="go">torch.float32</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">d</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">(</span><span class="s1">&#39;[[1.]]&#39;</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cuda:0&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">d</span>
<span class="go">RaggedTensor([[1]], device=&#39;cuda:0&#39;, dtype=torch.float32)</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Number of spaces or commas in <code class="docutils literal notranslate"><span class="pre">s</span></code> does not affect the result.
Of course, numbers have to be separated by at least one space or comma.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>s</strong> – A string representation of a ragged tensor.</p></li>
<li><p><strong>dtype</strong> – The desired dtype of the tensor. If it is <code class="docutils literal notranslate"><span class="pre">None</span></code>, it tries
to infer the correct dtype from <code class="docutils literal notranslate"><span class="pre">s</span></code>, which is assumed to be
either <code class="docutils literal notranslate"><span class="pre">torch.int32</span></code> or <code class="docutils literal notranslate"><span class="pre">torch.float32</span></code>. Supported dtypes are:
<code class="docutils literal notranslate"><span class="pre">torch.int32</span></code>, <code class="docutils literal notranslate"><span class="pre">torch.float32</span></code>, and <code class="docutils literal notranslate"><span class="pre">torch.float64</span></code>.</p></li>
<li><p><strong>device</strong> – It can be either an instance of <code class="docutils literal notranslate"><span class="pre">torch.device</span></code> or
a string representing a torch device. Example
values are: <code class="docutils literal notranslate"><span class="pre">&quot;cpu&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">&quot;cuda:0&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">torch.device(&quot;cpu&quot;)</span></code>,
<code class="docutils literal notranslate"><span class="pre">torch.device(&quot;cuda&quot;,</span> <span class="pre">0)</span></code>.</p></li>
</ul>
</dd>
</dl>
<ol class="arabic simple" start="4">
<li><p>__init__(self: k2.ragged.RaggedTensor, s: str, dtype: object = None, device: str = device(type=’cpu’)) -&gt; None</p></li>
</ol>
<p>Create a ragged tensor from its string representation.</p>
<p>Fields are separated by space(s) <strong>or</strong> comma(s).</p>
<p>An example string for a 2-axis ragged tensor is given below:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">5</span> <span class="mi">6</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">]</span> <span class="p">]</span>
</pre></div>
</div>
<p>An example string for a 3-axis ragged tensor is given below:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span> <span class="p">[[</span><span class="mi">1</span><span class="p">]]</span> <span class="p">[[]]</span> <span class="p">]</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">(</span><span class="s1">&#39;[ [1] [] [3 4] ]&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>
<span class="go">RaggedTensor([[1],</span>
<span class="go">              [],</span>
<span class="go">              [3, 4]], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">num_axes</span>
<span class="go">2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">dtype</span>
<span class="go">torch.int32</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">(</span><span class="s1">&#39;[ [[] [3]]  [[10]] ]&#39;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span>
<span class="go">RaggedTensor([[[],</span>
<span class="go">               [3]],</span>
<span class="go">              [[10]]], dtype=torch.float32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span><span class="o">.</span><span class="n">dtype</span>
<span class="go">torch.float32</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span><span class="o">.</span><span class="n">num_axes</span>
<span class="go">3</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">(</span><span class="s1">&#39;[[1.]]&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span><span class="o">.</span><span class="n">dtype</span>
<span class="go">torch.float32</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">d</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">(</span><span class="s1">&#39;[[1.]]&#39;</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cuda:0&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">d</span>
<span class="go">RaggedTensor([[1]], device=&#39;cuda:0&#39;, dtype=torch.float32)</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Number of spaces or commas in <code class="docutils literal notranslate"><span class="pre">s</span></code> does not affect the result.
Of course, numbers have to be separated by at least one space or comma.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>s</strong> – A string representation of a ragged tensor.</p></li>
<li><p><strong>dtype</strong> – The desired dtype of the tensor. If it is <code class="docutils literal notranslate"><span class="pre">None</span></code>, it tries
to infer the correct dtype from <code class="docutils literal notranslate"><span class="pre">s</span></code>, which is assumed to be
either <code class="docutils literal notranslate"><span class="pre">torch.int32</span></code> or <code class="docutils literal notranslate"><span class="pre">torch.float32</span></code>. Supported dtypes are:
<code class="docutils literal notranslate"><span class="pre">torch.int32</span></code>, <code class="docutils literal notranslate"><span class="pre">torch.float32</span></code>, and <code class="docutils literal notranslate"><span class="pre">torch.float64</span></code>.</p></li>
<li><p><strong>device</strong> – It can be either an instance of <code class="docutils literal notranslate"><span class="pre">torch.device</span></code> or
a string representing a torch device. Example
values are: <code class="docutils literal notranslate"><span class="pre">&quot;cpu&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">&quot;cuda:0&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">torch.device(&quot;cpu&quot;)</span></code>,
<code class="docutils literal notranslate"><span class="pre">torch.device(&quot;cuda&quot;,</span> <span class="pre">0)</span></code>.</p></li>
</ul>
</dd>
</dl>
<ol class="arabic simple" start="5">
<li><p>__init__(self: k2.ragged.RaggedTensor, shape: k2.ragged.RaggedShape, value: torch.Tensor) -&gt; None</p></li>
</ol>
<p>Create a ragged tensor from a shape and a value.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedShape</span><span class="p">(</span><span class="s1">&#39;[ [x x] [] [x x x] ]&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">value</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">10</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">40</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ragged</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ragged</span>
<span class="go">RaggedTensor([[10, 0],</span>
<span class="go">              [],</span>
<span class="go">              [20, 30, 40]], dtype=torch.float32)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>shape</strong> – The shape of the tensor.</p></li>
<li><p><strong>value</strong> – The value of the tensor.</p></li>
</ul>
</dd>
</dl>
<ol class="arabic simple" start="6">
<li><p>__init__(self: k2.ragged.RaggedTensor, tensor: torch.Tensor) -&gt; None</p></li>
</ol>
<p>Create a ragged tensor from a torch tensor.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>It turns a regular tensor into a ragged tensor.</p>
</div>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>The input tensor has to have more than 1 dimension.
That is <code class="docutils literal notranslate"><span class="pre">tensor.ndim</span> <span class="pre">&gt;</span> <span class="pre">1</span></code>.</p>
<p>Also, if the input tensor is contiguous, <code class="docutils literal notranslate"><span class="pre">self</span></code>
will share the underlying memory with it. Otherwise,
memory of the input tensor is copied to create <code class="docutils literal notranslate"><span class="pre">self</span></code>.</p>
<p>Supported dtypes of the input tensor are: <code class="docutils literal notranslate"><span class="pre">torch.int32</span></code>,
<code class="docutils literal notranslate"><span class="pre">torch.float32</span></code>, and <code class="docutils literal notranslate"><span class="pre">torch.float64</span></code>.</p>
</div>
<p><strong>Example 1</strong>:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>
<span class="go">tensor([[0, 1, 2],</span>
<span class="go">        [3, 4, 5]], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span>
<span class="go">RaggedTensor([[0, 1, 2],</span>
<span class="go">              [3, 4, 5]], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">is_contiguous</span><span class="p">()</span>
<span class="go">True</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">10</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span>
<span class="go">RaggedTensor([[10, 1, 2],</span>
<span class="go">              [3, 4, 5]], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>
<span class="go">tensor([[10, -2,  2],</span>
<span class="go">        [ 3,  4,  5]], dtype=torch.int32)</span>
</pre></div>
</div>
<p><strong>Example 2</strong>:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">24</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">12</span><span class="p">)[:,</span> <span class="p">::</span><span class="mi">4</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>
<span class="go">tensor([[ 0,  4,  8],</span>
<span class="go">        [12, 16, 20]], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">is_contiguous</span><span class="p">()</span>
<span class="go">False</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span>
<span class="go">RaggedTensor([[0, 4, 8],</span>
<span class="go">              [12, 16, 20]], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">10</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span>
<span class="go">RaggedTensor([[0, 4, 8],</span>
<span class="go">              [12, 16, 20]], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>
<span class="go">tensor([[10,  4,  8],</span>
<span class="go">        [12, 16, 20]], dtype=torch.int32)</span>
</pre></div>
</div>
<p><strong>Example 3</strong>:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">24</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>
<span class="go">tensor([[[ 0.,  1.,  2.,  3.],</span>
<span class="go">         [ 4.,  5.,  6.,  7.],</span>
<span class="go">         [ 8.,  9., 10., 11.]],</span>
<span class="go">        [[12., 13., 14., 15.],</span>
<span class="go">         [16., 17., 18., 19.],</span>
<span class="go">         [20., 21., 22., 23.]]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span>
<span class="go">RaggedTensor([[[0, 1, 2, 3],</span>
<span class="go">               [4, 5, 6, 7],</span>
<span class="go">               [8, 9, 10, 11]],</span>
<span class="go">              [[12, 13, 14, 15],</span>
<span class="go">               [16, 17, 18, 19],</span>
<span class="go">               [20, 21, 22, 23]]], dtype=torch.float32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span><span class="o">.</span><span class="n">dtype</span>
<span class="go">torch.float32</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]],</span> <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cuda:0&#39;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">(</span><span class="n">c</span><span class="p">)</span>
<span class="go">RaggedTensor([[1, 2]], device=&#39;cuda:0&#39;, dtype=torch.float32)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>tensor</strong> – An N-D (N &gt; 1) tensor.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="id23">
<h3>__ne__<a class="headerlink" href="#id23" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.RaggedTensor.__ne__">
<span class="sig-prename descclassname"><span class="pre">RaggedTensor.</span></span><span class="sig-name descname"><span class="pre">__ne__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">k2.ragged.RaggedTensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">other</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">k2.ragged.RaggedTensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">bool</span></span></span><a class="headerlink" href="#k2.RaggedTensor.__ne__" title="Permalink to this definition"></a></dt>
<dd><p>Compare two ragged tensors.</p>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>The two tensors MUST have the same dtype. Otherwise,
it throws an exception.</p>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">!=</span> <span class="n">a</span>
<span class="go">False</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span> <span class="o">!=</span> <span class="n">a</span>
<span class="go">True</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>other</strong> – The tensor to be compared.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Return <code class="docutils literal notranslate"><span class="pre">True</span></code> if the two tensors are NOT equal.
Return <code class="docutils literal notranslate"><span class="pre">False</span></code> otherwise.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="id24">
<h3>__repr__<a class="headerlink" href="#id24" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.RaggedTensor.__repr__">
<span class="sig-prename descclassname"><span class="pre">RaggedTensor.</span></span><span class="sig-name descname"><span class="pre">__repr__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">k2.ragged.RaggedTensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">str</span></span></span><a class="headerlink" href="#k2.RaggedTensor.__repr__" title="Permalink to this definition"></a></dt>
<dd><p>Return a string representation of this tensor.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>
<span class="go">RaggedTensor([[1],</span>
<span class="go">              [2, 3],</span>
<span class="go">              []], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">str</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="go">&#39;RaggedTensor([[1],\n              [2, 3],\n              []], dtype=torch.int32)&#39;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]],</span> <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cuda:0&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span>
<span class="go">RaggedTensor([[1, 2]], device=&#39;cuda:0&#39;, dtype=torch.int32)</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="setstate">
<h3>__setstate__<a class="headerlink" href="#setstate" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.RaggedTensor.__setstate__">
<span class="sig-prename descclassname"><span class="pre">RaggedTensor.</span></span><span class="sig-name descname"><span class="pre">__setstate__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">k2.ragged.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">arg0</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">tuple</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#k2.RaggedTensor.__setstate__" title="Permalink to this definition"></a></dt>
<dd><p>Set the content of this class from <code class="docutils literal notranslate"><span class="pre">arg0</span></code>.</p>
<p>This method is to support <code class="docutils literal notranslate"><span class="pre">pickle</span></code>, e.g., used by torch.load().
You are not expected to call it by yourself.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>arg0</strong> – It is the return value from the method <code class="docutils literal notranslate"><span class="pre">__getstate__</span></code>.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="id25">
<h3>__str__<a class="headerlink" href="#id25" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.RaggedTensor.__str__">
<span class="sig-prename descclassname"><span class="pre">RaggedTensor.</span></span><span class="sig-name descname"><span class="pre">__str__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">k2.ragged.RaggedTensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">str</span></span></span><a class="headerlink" href="#k2.RaggedTensor.__str__" title="Permalink to this definition"></a></dt>
<dd><p>Return a string representation of this tensor.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>
<span class="go">RaggedTensor([[1],</span>
<span class="go">              [2, 3],</span>
<span class="go">              []], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">str</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="go">&#39;RaggedTensor([[1],\n              [2, 3],\n              []], dtype=torch.int32)&#39;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]],</span> <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cuda:0&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span>
<span class="go">RaggedTensor([[1, 2]], device=&#39;cuda:0&#39;, dtype=torch.int32)</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="arange">
<h3>arange<a class="headerlink" href="#arange" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.RaggedTensor.arange">
<span class="sig-prename descclassname"><span class="pre">RaggedTensor.</span></span><span class="sig-name descname"><span class="pre">arange</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">k2.ragged.RaggedTensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axis</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">begin</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">end</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">k2.ragged.RaggedTensor</span></span></span><a class="headerlink" href="#k2.RaggedTensor.arange" title="Permalink to this definition"></a></dt>
<dd><p>Return a sub-range of <code class="docutils literal notranslate"><span class="pre">self</span></code> containing indexes <code class="docutils literal notranslate"><span class="pre">begin</span></code>
through <code class="docutils literal notranslate"><span class="pre">end</span> <span class="pre">-</span> <span class="pre">1</span></code> along axis <code class="docutils literal notranslate"><span class="pre">axis</span></code> of <code class="docutils literal notranslate"><span class="pre">self</span></code>.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">axis</span></code> argument may be confusing; its behavior is equivalent to:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">axis</span><span class="p">):</span>
  <span class="bp">self</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">remove_axis</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">begin</span><span class="p">,</span> <span class="n">end</span><span class="p">)</span>
</pre></div>
</div>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>The returned tensor shares the underlying memory with <code class="docutils literal notranslate"><span class="pre">self</span></code>.</p>
</div>
<p><strong>Example 1</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([</span> <span class="p">[[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[],</span> <span class="p">[</span><span class="mi">2</span><span class="p">]],</span> <span class="p">[[],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="p">[]],</span> <span class="p">[[],</span> <span class="p">[</span><span class="mi">1</span><span class="p">]],</span> <span class="p">[[]]</span> <span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>
<span class="go">RaggedTensor([[[1],</span>
<span class="go">               [],</span>
<span class="go">               [2]],</span>
<span class="go">              [[],</span>
<span class="go">               [4, 5],</span>
<span class="go">               []],</span>
<span class="go">              [[],</span>
<span class="go">               [1]],</span>
<span class="go">              [[]]], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">num_axes</span>
<span class="go">3</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">begin</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span>
<span class="go">RaggedTensor([[[],</span>
<span class="go">               [4, 5],</span>
<span class="go">               []],</span>
<span class="go">              [[],</span>
<span class="go">               [1]]], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span><span class="o">.</span><span class="n">num_axes</span>
<span class="go">3</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">begin</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span>
<span class="go">RaggedTensor([[[],</span>
<span class="go">               [4, 5],</span>
<span class="go">               []]], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span><span class="o">.</span><span class="n">num_axes</span>
<span class="go">3</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">d</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">begin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">d</span>
<span class="go">RaggedTensor([[1],</span>
<span class="go">              [],</span>
<span class="go">              [2],</span>
<span class="go">              []], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">d</span><span class="o">.</span><span class="n">num_axes</span>
<span class="go">2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">e</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">begin</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">e</span>
<span class="go">RaggedTensor([[2],</span>
<span class="go">              [],</span>
<span class="go">              [4, 5]], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">e</span><span class="o">.</span><span class="n">num_axes</span>
<span class="go">2</span>
</pre></div>
</div>
<p><strong>Example 2</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([</span> <span class="p">[[[],</span> <span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]],[[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">8</span><span class="p">],</span> <span class="p">[],</span> <span class="p">[</span><span class="mi">9</span><span class="p">]]],</span> <span class="p">[[[</span><span class="mi">10</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="p">[]]],</span> <span class="p">[[[],</span> <span class="p">[],</span> <span class="p">[</span><span class="mi">1</span><span class="p">]]]</span> <span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">num_axes</span>
<span class="go">4</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">begin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span>
<span class="go">RaggedTensor([[[[],</span>
<span class="go">                [1],</span>
<span class="go">                [2, 3]],</span>
<span class="go">               [[5, 8],</span>
<span class="go">                [],</span>
<span class="go">                [9]]],</span>
<span class="go">              [[[10],</span>
<span class="go">                [0],</span>
<span class="go">                []]]], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span><span class="o">.</span><span class="n">num_axes</span>
<span class="go">4</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">begin</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span>
<span class="go">RaggedTensor([[[5, 8],</span>
<span class="go">               [],</span>
<span class="go">               [9]],</span>
<span class="go">              [[10],</span>
<span class="go">               [0],</span>
<span class="go">               []]], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span><span class="o">.</span><span class="n">num_axes</span>
<span class="go">3</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">d</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">begin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">d</span>
<span class="go">RaggedTensor([[],</span>
<span class="go">              [1],</span>
<span class="go">              [2, 3],</span>
<span class="go">              [5, 8],</span>
<span class="go">              []], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">d</span><span class="o">.</span><span class="n">num_axes</span>
<span class="go">2</span>
</pre></div>
</div>
<p><strong>Example 3</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="p">[],</span> <span class="p">[</span><span class="mi">3</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>
<span class="go">RaggedTensor([[0],</span>
<span class="go">              [1],</span>
<span class="go">              [2],</span>
<span class="go">              [],</span>
<span class="go">              [3]], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">num_axes</span>
<span class="go">2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">begin</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span>
<span class="go">RaggedTensor([[1],</span>
<span class="go">              [2],</span>
<span class="go">              []], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>
<span class="go">RaggedTensor([[0],</span>
<span class="go">              [-1],</span>
<span class="go">              [2],</span>
<span class="go">              [],</span>
<span class="go">              [3]], dtype=torch.int32)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>axis</strong> – The axis from which <code class="docutils literal notranslate"><span class="pre">begin</span></code> and <code class="docutils literal notranslate"><span class="pre">end</span></code> correspond to.</p></li>
<li><p><strong>begin</strong> – The beginning of the range (inclusive).</p></li>
<li><p><strong>end</strong> – The end of the range (exclusive).</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>
<section id="argmax">
<h3>argmax<a class="headerlink" href="#argmax" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.RaggedTensor.argmax">
<span class="sig-prename descclassname"><span class="pre">RaggedTensor.</span></span><span class="sig-name descname"><span class="pre">argmax</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">k2.ragged.RaggedTensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">initial_value</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">object</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="headerlink" href="#k2.RaggedTensor.argmax" title="Permalink to this definition"></a></dt>
<dd><p>Return a tensor containing maximum value indexes within each sub-list along the
last axis of <code class="docutils literal notranslate"><span class="pre">self</span></code>, i.e. the max taken over the last axis, The index is -1
if the sub-list was empty or all values in the sub-list are less
than <code class="docutils literal notranslate"><span class="pre">initial_value</span></code>.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[]</span> <span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">argmax</span><span class="p">()</span>
<span class="go">tensor([ 0, -1, -1, -1], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">initial_value</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span>
<span class="go">tensor([ 0, -1, -1, -1], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span><span class="o">.</span><span class="n">argmax</span><span class="p">()</span>
<span class="go">tensor([ 3, -1,  7], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">d</span> <span class="o">=</span> <span class="n">c</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">initial_value</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">d</span>
<span class="go">tensor([ 3, -1,  7], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">c</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="mi">7</span><span class="p">]</span>
<span class="go">(tensor(5, dtype=torch.int32), tensor(8, dtype=torch.int32))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">initial_value</span><span class="o">=</span><span class="mi">6</span><span class="p">)</span>
<span class="go">tensor([-1, -1,  7], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">&#39;cuda:0&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="go">tensor([ 3, -1,  7], device=&#39;cuda:0&#39;, dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="go">tensor([ 3, -1,  7], dtype=torch.int32)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>initial_value</strong> – A base value to compare. If values in a sublist are all less
than this value, then the <code class="docutils literal notranslate"><span class="pre">argmax</span></code> of this sublist is -1.
If a sublist is empty, the <code class="docutils literal notranslate"><span class="pre">argmax</span></code> of it is also -1.
If it is <code class="docutils literal notranslate"><span class="pre">None</span></code>, the lowest value of <code class="docutils literal notranslate"><span class="pre">self.dtype</span></code> is used.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Return a 1-D <code class="docutils literal notranslate"><span class="pre">torch.int32</span></code> tensor. It is on the same device
as <code class="docutils literal notranslate"><span class="pre">self</span></code>.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="id26">
<h3>cat<a class="headerlink" href="#id26" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.RaggedTensor.cat">
<em class="property"><span class="pre">static</span> </em><span class="sig-prename descclassname"><span class="pre">RaggedTensor.</span></span><span class="sig-name descname"><span class="pre">cat</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">srcs</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">k2.ragged.RaggedTensor</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axis</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">k2.ragged.RaggedTensor</span></span></span><a class="headerlink" href="#k2.RaggedTensor.cat" title="Permalink to this definition"></a></dt>
<dd><p>Concatenate a list of ragged tensor over a specified axis.</p>
<p><strong>Example 1</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">k2r</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">a</span><span class="p">,</span> <span class="n">a</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="go">RaggedTensor([[1],</span>
<span class="go">              [],</span>
<span class="go">              [2, 3],</span>
<span class="go">              [1],</span>
<span class="go">              [],</span>
<span class="go">              [2, 3]], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">k2r</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">a</span><span class="p">,</span> <span class="n">a</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="go">RaggedTensor([[1, 1],</span>
<span class="go">              [],</span>
<span class="go">              [2, 3, 2, 3]], dtype=torch.int32)</span>
</pre></div>
</div>
<p><strong>Example 2</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[],</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">8</span><span class="p">],</span> <span class="p">[],</span> <span class="p">[</span><span class="mi">9</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">8</span><span class="p">],</span> <span class="p">[],</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">10</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span>
<span class="go">RaggedTensor([[1, 3],</span>
<span class="go">              [],</span>
<span class="go">              [5, 8],</span>
<span class="go">              [],</span>
<span class="go">              [9],</span>
<span class="go">              [0],</span>
<span class="go">              [1, 8],</span>
<span class="go">              [],</span>
<span class="go">              [-1],</span>
<span class="go">              [10]], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span><span class="o">.</span><span class="n">num_axes</span>
<span class="go">2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">d</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">d</span>
<span class="go">RaggedTensor([[1, 3, 0],</span>
<span class="go">              [1, 8],</span>
<span class="go">              [5, 8],</span>
<span class="go">              [-1],</span>
<span class="go">              [9, 10]], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">d</span><span class="o">.</span><span class="n">num_axes</span>
<span class="go">2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="go">RaggedTensor([[1, 3, 0],</span>
<span class="go">              [1, 8],</span>
<span class="go">              [5, 8],</span>
<span class="go">              [-1],</span>
<span class="go">              [9, 10]], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">k2r</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">b</span><span class="p">,</span> <span class="n">a</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="go">RaggedTensor([[0],</span>
<span class="go">              [1, 8],</span>
<span class="go">              [],</span>
<span class="go">              [-1],</span>
<span class="go">              [10],</span>
<span class="go">              [1, 3],</span>
<span class="go">              [],</span>
<span class="go">              [5, 8],</span>
<span class="go">              [],</span>
<span class="go">              [9]], dtype=torch.int32)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>srcs</strong> – A list (or a tuple) of ragged tensors to concatenate. They <strong>MUST</strong> all
have the same dtype and on the same device.</p></li>
<li><p><strong>axis</strong> – Only 0 and 1 are supported right now. If it is 1, then
<code class="docutils literal notranslate"><span class="pre">srcs[i].dim0</span></code> must all have the same value.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Return a concatenated tensor.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="clone">
<h3>clone<a class="headerlink" href="#clone" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.RaggedTensor.clone">
<span class="sig-prename descclassname"><span class="pre">RaggedTensor.</span></span><span class="sig-name descname"><span class="pre">clone</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">k2.ragged.RaggedTensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">k2.ragged.RaggedTensor</span></span></span><a class="headerlink" href="#k2.RaggedTensor.clone" title="Permalink to this definition"></a></dt>
<dd><p>Return a copy of this tensor.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">a</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>
<span class="go">RaggedTensor([[1, 2],</span>
<span class="go">              [3]], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">10</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>
<span class="go">RaggedTensor([[10, 2],</span>
<span class="go">              [3]], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span>
<span class="go">RaggedTensor([[1, 2],</span>
<span class="go">              [3]], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span>
<span class="go">RaggedTensor([[-1, 2],</span>
<span class="go">              [3]], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>
<span class="go">RaggedTensor([[10, 2],</span>
<span class="go">              [3]], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span>
<span class="go">RaggedTensor([[10, 2],</span>
<span class="go">              [3]], dtype=torch.int32)</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="id27">
<h3>index<a class="headerlink" href="#id27" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.RaggedTensor.index">
<span class="sig-prename descclassname"><span class="pre">RaggedTensor.</span></span><span class="sig-name descname"><span class="pre">index</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#k2.RaggedTensor.index" title="Permalink to this definition"></a></dt>
<dd><p>Overloaded function.</p>
<ol class="arabic simple">
<li><p>index(self: k2.ragged.RaggedTensor, indexes: k2.ragged.RaggedTensor) -&gt; k2.ragged.RaggedTensor</p></li>
</ol>
<p>Index a ragged tensor with a ragged tensor.</p>
<p><strong>Example 1</strong>:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">src</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">11</span><span class="p">],</span> <span class="p">[</span><span class="mi">12</span><span class="p">,</span> <span class="mf">13.5</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">indexes</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">src</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">indexes</span><span class="p">)</span>
<span class="go">RaggedTensor([[[10, 11],</span>
<span class="go">               [12, 13.5]]], dtype=torch.float32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">i</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">src</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
<span class="go">RaggedTensor([[[10, 11]],</span>
<span class="go">              [[12, 13.5]],</span>
<span class="go">              [[10, 11],</span>
<span class="go">               [10, 11]]], dtype=torch.float32)</span>
</pre></div>
</div>
<p><strong>Example 2</strong>:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">src</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([</span> <span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[],</span> <span class="p">[</span><span class="mi">2</span><span class="p">]],</span> <span class="p">[[],</span> <span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]],</span> <span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">i</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">]],</span> <span class="p">[[</span><span class="mi">0</span><span class="p">]]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">src</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
<span class="go">RaggedTensor([[[[[1, 0],</span>
<span class="go">                 [],</span>
<span class="go">                 [2]],</span>
<span class="go">                [[1, 2],</span>
<span class="go">                 [-1]]],</span>
<span class="go">               [[[],</span>
<span class="go">                 [3],</span>
<span class="go">                 [0, 0, 1]]]],</span>
<span class="go">              [[[[1, 0],</span>
<span class="go">                 [],</span>
<span class="go">                 [2]]]]], dtype=torch.int32)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>indexes</strong> – <p>Its values must satisfy <code class="docutils literal notranslate"><span class="pre">0</span> <span class="pre">&lt;=</span> <span class="pre">values[i]</span> <span class="pre">&lt;</span> <span class="pre">self.dim0</span></code>.</p>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>Its dtype has to be <code class="docutils literal notranslate"><span class="pre">torch.int32</span></code>.</p>
</div>
</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Return indexed tensor.</p>
</dd>
</dl>
<ol class="arabic simple" start="2">
<li><p>index(self: k2.ragged.RaggedTensor, indexes: torch.Tensor, axis: int, need_value_indexes: bool = False) -&gt; Tuple[k2.ragged.RaggedTensor, Optional[torch.Tensor]]</p></li>
</ol>
<p>Indexing operation on ragged tensor, returns <code class="docutils literal notranslate"><span class="pre">self[indexes]</span></code>, where
the elements of <code class="docutils literal notranslate"><span class="pre">indexes</span></code> are interpreted as indexes into axis <code class="docutils literal notranslate"><span class="pre">axis</span></code> of
<code class="docutils literal notranslate"><span class="pre">self</span></code>.</p>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p><code class="docutils literal notranslate"><span class="pre">indexes</span></code> is a 1-D tensor and <code class="docutils literal notranslate"><span class="pre">indexes.dtype</span> <span class="pre">==</span> <span class="pre">torch.int32</span></code>.</p>
</div>
<p><strong>Example 1</strong>:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.25</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">i</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span><span class="p">,</span> <span class="n">value_indexes</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">need_value_indexes</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span>
<span class="go">RaggedTensor([[0, 1, 2],</span>
<span class="go">              [0, 2, 3],</span>
<span class="go">              [],</span>
<span class="go">              [3, -1.25]], dtype=torch.float32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">value_indexes</span>
<span class="go">tensor([3, 4, 5, 0, 1, 2, 6, 7], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="n">value_indexes</span><span class="o">.</span><span class="n">long</span><span class="p">()]</span>
<span class="go">tensor([ 0.0000,  1.0000,  2.0000,  0.0000,  2.0000,  3.0000,  3.0000, -1.2500])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">k</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">need_value_indexes</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="go">(RaggedTensor([[0, 1, 2],</span>
<span class="go">              [],</span>
<span class="go">              [0, 2, 3]], dtype=torch.float32), tensor([3, 4, 5, 0, 1, 2], dtype=torch.int32))</span>
</pre></div>
</div>
<p><strong>Example 2</strong>:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([</span> <span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[],</span> <span class="p">[</span><span class="mi">2</span><span class="p">]],</span> <span class="p">[[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">8</span><span class="p">],</span> <span class="p">[],</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">]]</span> <span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">i</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="n">row_ids</span><span class="p">(</span><span class="mi">1</span><span class="p">)[</span><span class="n">i</span><span class="o">.</span><span class="n">long</span><span class="p">()]</span>
<span class="go">tensor([0, 0, 0, 1, 1, 1, 1], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span><span class="p">,</span> <span class="n">value_indexes</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">need_value_indexes</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span>
<span class="go">RaggedTensor([[[1, 3],</span>
<span class="go">               [2],</span>
<span class="go">               []],</span>
<span class="go">              [[2],</span>
<span class="go">               [5, 8],</span>
<span class="go">               [-1],</span>
<span class="go">               []]], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">value_indexes</span>
<span class="go">tensor([0, 1, 2, 6, 3, 4, 5], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="n">value_indexes</span><span class="o">.</span><span class="n">long</span><span class="p">()]</span>
<span class="go">tensor([ 1,  3,  2,  2,  5,  8, -1], dtype=torch.int32)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>indexes</strong> – <p>Array of indexes, which will be interpreted as indexes into axis <code class="docutils literal notranslate"><span class="pre">axis</span></code>
of <code class="docutils literal notranslate"><span class="pre">self</span></code>, i.e. with <code class="docutils literal notranslate"><span class="pre">0</span> <span class="pre">&lt;=</span> <span class="pre">indexes[i]</span> <span class="pre">&lt;</span> <span class="pre">self.tot_size(axis)</span></code>.
Note that if <code class="docutils literal notranslate"><span class="pre">axis</span></code> is 0, then -1 is also a valid entry in <code class="docutils literal notranslate"><span class="pre">index</span></code>,
-1 as an index, which will result in an empty list (as if it were the index
into a position in <code class="docutils literal notranslate"><span class="pre">self</span></code> that had an empty list at that point).</p>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>It is currently not allowed to change the order on axes less than
<code class="docutils literal notranslate"><span class="pre">axis</span></code>, i.e. if <code class="docutils literal notranslate"><span class="pre">axis</span> <span class="pre">&gt;</span> <span class="pre">0</span></code>, we require:
<code class="docutils literal notranslate"><span class="pre">IsMonotonic(self.shape.row_ids(axis)[indexes])</span></code>.</p>
</div>
</p></li>
<li><p><strong>axis</strong> – The axis to be indexed. Must satisfy <code class="docutils literal notranslate"><span class="pre">0</span> <span class="pre">&lt;=</span> <span class="pre">axis</span> <span class="pre">&lt;</span> <span class="pre">self.num_axes</span></code>.</p></li>
<li><p><strong>need_value_indexes</strong> – If <code class="docutils literal notranslate"><span class="pre">True</span></code>, it will return a torch.Tensor containing the indexes into
<code class="docutils literal notranslate"><span class="pre">self.values</span></code> that <code class="docutils literal notranslate"><span class="pre">ans.values</span></code> has, as in
<code class="docutils literal notranslate"><span class="pre">ans.values</span> <span class="pre">=</span> <span class="pre">self.values[value_indexes]</span></code>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p>A ragged tensor, sharing the same dtype and device with <code class="docutils literal notranslate"><span class="pre">self</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">None</span></code> if <code class="docutils literal notranslate"><span class="pre">need_value_indexes</span></code> is False; a 1-D torch.tensor of
dtype <code class="docutils literal notranslate"><span class="pre">torch.int32</span></code> containing the indexes into <code class="docutils literal notranslate"><span class="pre">self.values</span></code> that
<code class="docutils literal notranslate"><span class="pre">ans.values</span></code> has.</p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Return a tuple containing</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="max">
<h3>max<a class="headerlink" href="#max" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.RaggedTensor.max">
<span class="sig-prename descclassname"><span class="pre">RaggedTensor.</span></span><span class="sig-name descname"><span class="pre">max</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">k2.ragged.RaggedTensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">initial_value</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">object</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="headerlink" href="#k2.RaggedTensor.max" title="Permalink to this definition"></a></dt>
<dd><p>Return a tensor containing the maximum of each sub-list along the last
axis of <code class="docutils literal notranslate"><span class="pre">self</span></code>. The max is taken over the last axis or <code class="docutils literal notranslate"><span class="pre">initial_value</span></code>,
whichever was larger.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([</span> <span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[],</span> <span class="p">[]],</span> <span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">8</span><span class="p">]]</span> <span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>
<span class="go">tensor([          3,           5, -2147483648, -2147483648,           9,</span>
<span class="go">        -2147483648,           8], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">initial_value</span><span class="o">=-</span><span class="mi">10</span><span class="p">)</span>
<span class="go">tensor([  3,   5, -10, -10,   9, -10,   8], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">initial_value</span><span class="o">=</span><span class="mi">7</span><span class="p">)</span>
<span class="go">tensor([7, 7, 7, 7, 9, 7, 8], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">)</span>
<span class="go">tensor([ 3.,  5., -3., -3.,  9., -3.,  8.])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">&#39;cuda:0&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span>
<span class="go">tensor([ 3,  5, -2, -2,  9, -2,  8], device=&#39;cuda:0&#39;, dtype=torch.int32)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>initial_value</strong> – The base value to compare. If values in a sublist are all less
than this value, then the max of this sublist is <code class="docutils literal notranslate"><span class="pre">initial_value</span></code>.
If a sublist is empty, its max is also <code class="docutils literal notranslate"><span class="pre">initial_value</span></code>.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Return 1-D tensor containing the max value of each sublist.
It shares the same dtype and device with <code class="docutils literal notranslate"><span class="pre">self</span></code>.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="min">
<h3>min<a class="headerlink" href="#min" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.RaggedTensor.min">
<span class="sig-prename descclassname"><span class="pre">RaggedTensor.</span></span><span class="sig-name descname"><span class="pre">min</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">k2.ragged.RaggedTensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">initial_value</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">object</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="headerlink" href="#k2.RaggedTensor.min" title="Permalink to this definition"></a></dt>
<dd><p>Return a tensor containing the minimum of each sub-list along the last
axis of <code class="docutils literal notranslate"><span class="pre">self</span></code>. The min is taken over the last axis or <code class="docutils literal notranslate"><span class="pre">initial_value</span></code>,
whichever was smaller.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([</span> <span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[],</span> <span class="p">[]],</span> <span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">8</span><span class="p">]]</span> <span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">min</span><span class="p">()</span>
<span class="go">tensor([ 0.0000e+00, -1.0000e+00,  3.4028e+38,  3.4028e+38,  1.0000e+00,</span>
<span class="go">         3.4028e+38,  2.0000e+00])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">initial_value</span><span class="o">=</span><span class="nb">float</span><span class="p">(</span><span class="s1">&#39;inf&#39;</span><span class="p">))</span>
<span class="go">tensor([ 0., -1., inf, inf,  1., inf,  2.])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
<span class="go">tensor([  0.,  -1., 100., 100.,   1., 100.,   2.])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>
<span class="go">tensor([ 0, -1, 20, 20,  1, 20,  2], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">&#39;cuda:0&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="mi">15</span><span class="p">)</span>
<span class="go">tensor([ 0., -1., 15., 15.,  1., 15.,  2.], device=&#39;cuda:0&#39;)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>initial_value</strong> – The base value to compare. If values in a sublist are all larger
than this value, then the minimum of this sublist is <code class="docutils literal notranslate"><span class="pre">initial_value</span></code>.
If a sublist is empty, its minimum is also <code class="docutils literal notranslate"><span class="pre">initial_value</span></code>.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Return 1-D tensor containing the minimum of each sublist.
It shares the same dtype and device with <code class="docutils literal notranslate"><span class="pre">self</span></code>.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="normalize">
<h3>normalize<a class="headerlink" href="#normalize" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.RaggedTensor.normalize">
<span class="sig-prename descclassname"><span class="pre">RaggedTensor.</span></span><span class="sig-name descname"><span class="pre">normalize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">k2.ragged.RaggedTensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_log</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">k2.ragged.RaggedTensor</span></span></span><a class="headerlink" href="#k2.RaggedTensor.normalize" title="Permalink to this definition"></a></dt>
<dd><p>Normalize a ragged tensor over the last axis.</p>
<p>If <code class="docutils literal notranslate"><span class="pre">use_log</span></code> is <code class="docutils literal notranslate"><span class="pre">True</span></code>, the normalization per sublist is done as follows:</p>
<blockquote>
<div><ol class="arabic simple">
<li><p>Compute the log sum per sublist</p></li>
</ol>
<p>2. Subtract the log sum computed above from the sublist and return
it</p>
</div></blockquote>
<p>If <code class="docutils literal notranslate"><span class="pre">use_log</span></code> is <code class="docutils literal notranslate"><span class="pre">False</span></code>, the normalization per sublist is done as follows:</p>
<blockquote>
<div><ol class="arabic simple">
<li><p>Compute the sum per sublist</p></li>
<li><p>Divide the sublist by the above sum and return the resulting sublist</p></li>
</ol>
</div></blockquote>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If a sublist contains 3 elements <code class="docutils literal notranslate"><span class="pre">[a,</span> <span class="pre">b,</span> <span class="pre">c]</span></code>, then the log sum
is defined as:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">s</span> <span class="o">=</span> <span class="n">log</span><span class="p">(</span><span class="n">exp</span><span class="p">(</span><span class="n">a</span><span class="p">)</span> <span class="o">+</span> <span class="n">exp</span><span class="p">(</span><span class="n">b</span><span class="p">)</span> <span class="o">+</span> <span class="n">exp</span><span class="p">(</span><span class="n">c</span><span class="p">))</span>
</pre></div>
</div>
<p>The resulting sublist looks like below if <code class="docutils literal notranslate"><span class="pre">use_log</span></code> is <code class="docutils literal notranslate"><span class="pre">True</span></code>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="n">a</span> <span class="o">-</span> <span class="n">s</span><span class="p">,</span> <span class="n">b</span> <span class="o">-</span> <span class="n">s</span><span class="p">,</span> <span class="n">c</span> <span class="o">-</span> <span class="n">s</span><span class="p">]</span>
</pre></div>
</div>
<p>If <code class="docutils literal notranslate"><span class="pre">use_log</span></code> is <code class="docutils literal notranslate"><span class="pre">False</span></code>, the resulting sublist looks like:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="n">a</span><span class="o">/</span><span class="p">(</span><span class="n">a</span><span class="o">+</span><span class="n">b</span><span class="o">+</span><span class="n">c</span><span class="p">),</span> <span class="n">b</span><span class="o">/</span><span class="p">(</span><span class="n">a</span><span class="o">+</span><span class="n">b</span><span class="o">+</span><span class="n">c</span><span class="p">),</span> <span class="n">c</span><span class="o">/</span><span class="p">(</span><span class="n">a</span><span class="o">+</span><span class="n">b</span><span class="o">+</span><span class="n">c</span><span class="p">)]</span>
</pre></div>
</div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">],</span> <span class="p">[],</span> <span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">use_log</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="go">RaggedTensor([[0.25, 0.75],</span>
<span class="go">              [],</span>
<span class="go">              [1],</span>
<span class="go">              [0.2, 0.8]], dtype=torch.float32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">use_log</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="go">RaggedTensor([[-0.798139, -0.598139],</span>
<span class="go">              [],</span>
<span class="go">              [0],</span>
<span class="go">              [-1.03749, -0.437488]], dtype=torch.float32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([</span> <span class="p">[[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">],</span> <span class="p">[]],</span> <span class="p">[[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">]]</span> <span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">use_log</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="go">RaggedTensor([[[0.25, 0.75],</span>
<span class="go">               []],</span>
<span class="go">              [[1],</span>
<span class="go">               [0.2, 0.8]]], dtype=torch.float32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">use_log</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="go">RaggedTensor([[[-0.798139, -0.598139],</span>
<span class="go">               []],</span>
<span class="go">              [[0],</span>
<span class="go">               [-1.03749, -0.437488]]], dtype=torch.float32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">num_axes</span>
<span class="go">2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span><span class="o">.</span><span class="n">num_axes</span>
<span class="go">3</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">])</span><span class="o">.</span><span class="n">exp</span><span class="p">()</span> <span class="o">/</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">])</span><span class="o">.</span><span class="n">exp</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">())</span><span class="o">.</span><span class="n">log</span><span class="p">()</span>
<span class="go">tensor([-0.7981, -0.5981])</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>use_log</strong> – It indicates which kind of normalization to be applied.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Returns a 1-D tensor, sharing the same dtype and device with <code class="docutils literal notranslate"><span class="pre">self</span></code>.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="id28">
<h3>numel<a class="headerlink" href="#id28" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.RaggedTensor.numel">
<span class="sig-prename descclassname"><span class="pre">RaggedTensor.</span></span><span class="sig-name descname"><span class="pre">numel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">k2.ragged.RaggedTensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">int</span></span></span><a class="headerlink" href="#k2.RaggedTensor.numel" title="Permalink to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Return number of elements in this tensor. It equals to
<code class="docutils literal notranslate"><span class="pre">self.values.numel()</span></code>.</p>
</dd>
</dl>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span>
<span class="go">5</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">(</span><span class="s1">&#39;[ [[1] [] []]  [[2 3]]]&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span>
<span class="go">3</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">(</span><span class="s1">&#39;[[1] [] [3 4 5 6]]&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span>
<span class="go">5</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="pad">
<h3>pad<a class="headerlink" href="#pad" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.RaggedTensor.pad">
<span class="sig-prename descclassname"><span class="pre">RaggedTensor.</span></span><span class="sig-name descname"><span class="pre">pad</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">k2.ragged.RaggedTensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding_value</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">object</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="headerlink" href="#k2.RaggedTensor.pad" title="Permalink to this definition"></a></dt>
<dd><p>Pad a ragged tensor with 2-axes to a 2-D torch tensor.</p>
<p>For example, if <code class="docutils literal notranslate"><span class="pre">self</span></code> has the following values:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span> <span class="p">[</span><span class="mi">1</span> <span class="mi">2</span> <span class="mi">3</span><span class="p">]</span> <span class="p">[</span><span class="mi">4</span><span class="p">]</span> <span class="p">[</span><span class="mi">5</span> <span class="mi">6</span> <span class="mi">7</span> <span class="mi">8</span><span class="p">]</span> <span class="p">]</span>
</pre></div>
</div>
<p>Then it returns a 2-D tensor as follows if <code class="docutils literal notranslate"><span class="pre">padding_value</span></code> is 0 and
mode is <code class="docutils literal notranslate"><span class="pre">constant</span></code>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">]])</span>
</pre></div>
</div>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>It requires that <code class="docutils literal notranslate"><span class="pre">self.num_axes</span> <span class="pre">==</span> <span class="pre">2</span></code>.</p>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">2</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="s1">&#39;constant&#39;</span><span class="p">,</span> <span class="n">padding_value</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="go">tensor([[ 1, -1, -1, -1, -1],</span>
<span class="go">        [-1, -1, -1, -1, -1],</span>
<span class="go">        [ 2,  3, -1, -1, -1],</span>
<span class="go">        [ 5,  8,  9,  8,  2]], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="s1">&#39;replicate&#39;</span><span class="p">,</span> <span class="n">padding_value</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="go">tensor([[ 1,  1,  1,  1,  1],</span>
<span class="go">        [-1, -1, -1, -1, -1],</span>
<span class="go">        [ 2,  3,  3,  3,  3],</span>
<span class="go">        [ 5,  8,  9,  8,  2]], dtype=torch.int32)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>mode</strong> – Valid values are: <code class="docutils literal notranslate"><span class="pre">constant</span></code>, <code class="docutils literal notranslate"><span class="pre">replicate</span></code>. If it is
<code class="docutils literal notranslate"><span class="pre">constant</span></code>, the given <code class="docutils literal notranslate"><span class="pre">padding_value</span></code> is used for filling.
If it is <code class="docutils literal notranslate"><span class="pre">replicate</span></code>, the last entry in a list is used for filling.
If a list is empty, then the given <cite>padding_value</cite> is also used for filling.</p></li>
<li><p><strong>padding_value</strong> – The filling value.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A 2-D torch tensor, sharing the same dtype and device with <code class="docutils literal notranslate"><span class="pre">self</span></code>.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="id29">
<h3>remove_axis<a class="headerlink" href="#id29" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.RaggedTensor.remove_axis">
<span class="sig-prename descclassname"><span class="pre">RaggedTensor.</span></span><span class="sig-name descname"><span class="pre">remove_axis</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">k2.ragged.RaggedTensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axis</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">k2.ragged.RaggedTensor</span></span></span><a class="headerlink" href="#k2.RaggedTensor.remove_axis" title="Permalink to this definition"></a></dt>
<dd><p>Remove an axis; if it is not the first or last axis, this is done by appending
lists (effectively the axis is combined with the following axis).  If it is the
last axis it is just removed and the number of elements may be changed.</p>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>The tensor has to have more than two axes.</p>
</div>
<p><strong>Example 1</strong>:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([</span> <span class="p">[[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]],</span> <span class="p">[[],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[]],</span> <span class="p">[[</span><span class="mi">0</span><span class="p">]],</span> <span class="p">[[]]</span> <span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>
<span class="go">RaggedTensor([[[1],</span>
<span class="go">               [],</span>
<span class="go">               [0, -1]],</span>
<span class="go">              [[],</span>
<span class="go">               [2, 3],</span>
<span class="go">               []],</span>
<span class="go">              [[0]],</span>
<span class="go">              [[]]], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">num_axes</span>
<span class="go">3</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">remove_axis</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span>
<span class="go">RaggedTensor([[1],</span>
<span class="go">              [],</span>
<span class="go">              [0, -1],</span>
<span class="go">              [],</span>
<span class="go">              [2, 3],</span>
<span class="go">              [],</span>
<span class="go">              [0],</span>
<span class="go">              []], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">remove_axis</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span>
<span class="go">RaggedTensor([[1, 0, -1],</span>
<span class="go">              [2, 3],</span>
<span class="go">              [0],</span>
<span class="go">              []], dtype=torch.int32)</span>
</pre></div>
</div>
<p><strong>Example 2</strong>:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([</span> <span class="p">[[[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[],</span> <span class="p">[</span><span class="mi">2</span><span class="p">]]],</span> <span class="p">[[[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[],</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span> <span class="p">[]]],</span> <span class="p">[[[],</span> <span class="p">[</span><span class="mi">0</span><span class="p">]]]</span> <span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">num_axes</span>
<span class="go">4</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>
<span class="go">RaggedTensor([[[[1],</span>
<span class="go">                [],</span>
<span class="go">                [2]]],</span>
<span class="go">              [[[3, 4],</span>
<span class="go">                [],</span>
<span class="go">                [5, 6],</span>
<span class="go">                []]],</span>
<span class="go">              [[[],</span>
<span class="go">                [0]]]], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">remove_axis</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span>
<span class="go">RaggedTensor([[[1],</span>
<span class="go">               [],</span>
<span class="go">               [2]],</span>
<span class="go">              [[3, 4],</span>
<span class="go">               [],</span>
<span class="go">               [5, 6],</span>
<span class="go">               []],</span>
<span class="go">              [[],</span>
<span class="go">               [0]]], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">remove_axis</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span>
<span class="go">RaggedTensor([[[1],</span>
<span class="go">               [],</span>
<span class="go">               [2]],</span>
<span class="go">              [[3, 4],</span>
<span class="go">               [],</span>
<span class="go">               [5, 6],</span>
<span class="go">               []],</span>
<span class="go">              [[],</span>
<span class="go">               [0]]], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">d</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">remove_axis</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">d</span>
<span class="go">RaggedTensor([[[1, 2]],</span>
<span class="go">              [[3, 4, 5, 6]],</span>
<span class="go">              [[0]]], dtype=torch.int32)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>axis</strong> – The axis to move.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Return a ragged tensor with one fewer axes.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="remove-values-eq">
<h3>remove_values_eq<a class="headerlink" href="#remove-values-eq" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.RaggedTensor.remove_values_eq">
<span class="sig-prename descclassname"><span class="pre">RaggedTensor.</span></span><span class="sig-name descname"><span class="pre">remove_values_eq</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">k2.ragged.RaggedTensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">object</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">k2.ragged.RaggedTensor</span></span></span><a class="headerlink" href="#k2.RaggedTensor.remove_values_eq" title="Permalink to this definition"></a></dt>
<dd><p>Returns a ragged tensor after removing all ‘values’ that equal a provided
target.  Leaves all layers of the shape except for the last one unaffected.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>
<span class="go">RaggedTensor([[1, 2, 3, 0, 3, 2],</span>
<span class="go">              [],</span>
<span class="go">              [3, 2, 3],</span>
<span class="go">              [3]], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">remove_values_eq</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span>
<span class="go">RaggedTensor([[1, 2, 0, 2],</span>
<span class="go">              [],</span>
<span class="go">              [2],</span>
<span class="go">              []], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">remove_values_eq</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span>
<span class="go">RaggedTensor([[1, 3, 0, 3],</span>
<span class="go">              [],</span>
<span class="go">              [3, 3],</span>
<span class="go">              [3]], dtype=torch.int32)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>target</strong> – The target value to delete.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Return a ragged tensor whose values don’t contain the <code class="docutils literal notranslate"><span class="pre">target</span></code>.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="remove-values-leq">
<h3>remove_values_leq<a class="headerlink" href="#remove-values-leq" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.RaggedTensor.remove_values_leq">
<span class="sig-prename descclassname"><span class="pre">RaggedTensor.</span></span><span class="sig-name descname"><span class="pre">remove_values_leq</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">k2.ragged.RaggedTensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cutoff</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">object</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">k2.ragged.RaggedTensor</span></span></span><a class="headerlink" href="#k2.RaggedTensor.remove_values_leq" title="Permalink to this definition"></a></dt>
<dd><p>Returns a ragged tensor after removing all ‘values’ that are
equal to or less than a provided cutoff.
Leaves all layers of the shape except for the last one unaffected.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>
<span class="go">RaggedTensor([[1, 2, 3, 0, 3, 2],</span>
<span class="go">              [],</span>
<span class="go">              [3, 2, 3],</span>
<span class="go">              [3]], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">remove_values_leq</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span>
<span class="go">RaggedTensor([[],</span>
<span class="go">              [],</span>
<span class="go">              [],</span>
<span class="go">              []], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">remove_values_leq</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span>
<span class="go">RaggedTensor([[3, 3],</span>
<span class="go">              [],</span>
<span class="go">              [3, 3],</span>
<span class="go">              [3]], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">d</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">remove_values_leq</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">d</span>
<span class="go">RaggedTensor([[2, 3, 3, 2],</span>
<span class="go">              [],</span>
<span class="go">              [3, 2, 3],</span>
<span class="go">              [3]], dtype=torch.int32)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>cutoff</strong> – Values less than or equal to this <code class="docutils literal notranslate"><span class="pre">cutoff</span></code> are deleted.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Return a ragged tensor whose values are all above <code class="docutils literal notranslate"><span class="pre">cutoff</span></code>.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="id30">
<h3><a href="#id109"><span class="problematic" id="id110">requires_grad_</span></a><a class="headerlink" href="#id30" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.RaggedTensor.requires_grad_">
<span class="sig-prename descclassname"><span class="pre">RaggedTensor.</span></span><span class="sig-name descname"><span class="pre">requires_grad_</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">k2.ragged.RaggedTensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">requires_grad</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">k2.ragged.RaggedTensor</span></span></span><a class="headerlink" href="#k2.RaggedTensor.requires_grad_" title="Permalink to this definition"></a></dt>
<dd><p>Change if autograd should record operations on this tensor: Set
this tensor’s <a class="reference internal" href="#k2.RaggedTensor.requires_grad" title="k2.RaggedTensor.requires_grad"><code class="xref py py-attr docutils literal notranslate"><span class="pre">requires_grad</span></code></a> attribute <strong>in-place</strong>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If this tensor is not a float tensor, PyTorch will throw a
RuntimeError exception.</p>
</div>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>This method ends with an underscore, meaning it changes this tensor
<strong>in-place</strong>.</p>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">requires_grad</span>
<span class="go">False</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="go">RaggedTensor([[1]], dtype=torch.float64)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">requires_grad</span>
<span class="go">True</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>requires_grad</strong> – If autograd should record operations on this tensor.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Return this tensor.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="sort">
<h3><a href="#id111"><span class="problematic" id="id112">sort_</span></a><a class="headerlink" href="#sort" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.RaggedTensor.sort_">
<span class="sig-prename descclassname"><span class="pre">RaggedTensor.</span></span><span class="sig-name descname"><span class="pre">sort_</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">k2.ragged.RaggedTensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">descending</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">need_new2old_indexes</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#k2.RaggedTensor.sort_" title="Permalink to this definition"></a></dt>
<dd><p>Sort a ragged tensor over the last axis <strong>in-place</strong>.</p>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p><code class="docutils literal notranslate"><span class="pre">sort_</span></code> ends with an underscore, meaning this operation
changes <code class="docutils literal notranslate"><span class="pre">self</span></code> <strong>in-place</strong>.</p>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mf">0.</span><span class="p">]</span> <span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a_clone</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">sort_</span><span class="p">(</span><span class="n">descending</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">need_new2old_indexes</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span>
<span class="go">tensor([1, 0, 2, 4, 5, 3, 7, 6, 8], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>
<span class="go">RaggedTensor([[3, 1, 0],</span>
<span class="go">              [5, 3, 2],</span>
<span class="go">              [],</span>
<span class="go">              [3, 1, 0]], dtype=torch.float32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a_clone</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="n">b</span><span class="o">.</span><span class="n">long</span><span class="p">()]</span>
<span class="go">tensor([3., 1., 0., 5., 3., 2., 3., 1., 0.])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a_clone</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">sort_</span><span class="p">(</span><span class="n">descending</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">need_new2old_indexes</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span>
<span class="go">tensor([2, 1, 0, 5, 4, 3, 8, 7, 6], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>
<span class="go">RaggedTensor([[0, 1, 3],</span>
<span class="go">              [2, 3, 5],</span>
<span class="go">              [],</span>
<span class="go">              [0, 1, 3]], dtype=torch.float32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a_clone</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="n">c</span><span class="o">.</span><span class="n">long</span><span class="p">()]</span>
<span class="go">tensor([0., 1., 3., 2., 3., 5., 0., 1., 3.])</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>descending</strong> – <code class="docutils literal notranslate"><span class="pre">True</span></code> to sort in <strong>descending</strong> order.
<code class="docutils literal notranslate"><span class="pre">False</span></code> to sort in <strong>ascending</strong> order.</p></li>
<li><p><strong>need_new2old_indexes</strong> – If <code class="docutils literal notranslate"><span class="pre">True</span></code>, also returns a 1-D tensor, containing the indexes mapping
from the sorted elements to the unsorted elements. We can use
<code class="docutils literal notranslate"><span class="pre">self.clone().values[returned_tensor]</span></code> to get a sorted tensor.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>If <code class="docutils literal notranslate"><span class="pre">need_new2old_indexes</span></code> is False, returns None. Otherwise, returns
a 1-D tensor of dtype <code class="docutils literal notranslate"><span class="pre">torch.int32</span></code>.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="sum">
<h3>sum<a class="headerlink" href="#sum" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.RaggedTensor.sum">
<span class="sig-prename descclassname"><span class="pre">RaggedTensor.</span></span><span class="sig-name descname"><span class="pre">sum</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">k2.ragged.RaggedTensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">initial_value</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">float</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="headerlink" href="#k2.RaggedTensor.sum" title="Permalink to this definition"></a></dt>
<dd><p>Compute the sum of sublists over the last axis of this tensor.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If a sublist is empty, the sum for it is the provided
<code class="docutils literal notranslate"><span class="pre">initial_value</span></code>.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This operation supports autograd if this tensor is a float tensor,
i.e., with dtype being torch.float32 or torch.float64.</p>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">(</span><span class="s1">&#39;[ [[1 2] [] [5]]  [[10]] ]&#39;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="go">RaggedTensor([[[1, 2],</span>
<span class="go">               [],</span>
<span class="go">               [5]],</span>
<span class="go">              [[10]]], dtype=torch.float32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span> <span class="o">=</span> <span class="p">(</span><span class="n">b</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">4</span><span class="p">))</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">grad</span>
<span class="go">tensor([0., 0., 2., 3.])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span>
<span class="go">tensor([ 3.,  0.,  5., 10.], grad_fn=&lt;SumFunction&gt;&gt;)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span>
<span class="go">tensor(40., grad_fn=&lt;SumBackward0&gt;)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>initial_value</strong> – This value is added to the sum of each sublist. So when
a sublist is empty, its sum is this value.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Return a 1-D tensor with the same dtype of this tensor
containing the computed sum.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="id31">
<h3>to<a class="headerlink" href="#id31" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.RaggedTensor.to">
<span class="sig-prename descclassname"><span class="pre">RaggedTensor.</span></span><span class="sig-name descname"><span class="pre">to</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#k2.RaggedTensor.to" title="Permalink to this definition"></a></dt>
<dd><p>Overloaded function.</p>
<ol class="arabic simple">
<li><p>to(self: k2.ragged.RaggedTensor, device: torch::Device) -&gt; k2.ragged.RaggedTensor</p></li>
</ol>
<p>Transfer this tensor to a given device.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If <code class="docutils literal notranslate"><span class="pre">self</span></code> is already on the specified device, return a
ragged tensor sharing the underlying memory with <code class="docutils literal notranslate"><span class="pre">self</span></code>.
Otherwise, a new tensor is returned.</p>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">device</span>
<span class="go">device(type=&#39;cpu&#39;)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cuda&#39;</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span><span class="o">.</span><span class="n">device</span>
<span class="go">device(type=&#39;cuda&#39;, index=0)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>device</strong> – The target device to move this tensor.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Return a tensor on the given device.</p>
</dd>
</dl>
<ol class="arabic simple" start="2">
<li><p>to(self: k2.ragged.RaggedTensor, device: str) -&gt; k2.ragged.RaggedTensor</p></li>
</ol>
<p>Transfer this tensor to a given device.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If <code class="docutils literal notranslate"><span class="pre">self</span></code> is already on the specified device, return a
ragged tensor sharing the underlying memory with <code class="docutils literal notranslate"><span class="pre">self</span></code>.
Otherwise, a new tensor is returned.</p>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">device</span>
<span class="go">device(type=&#39;cpu&#39;)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">&#39;cuda:0&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span><span class="o">.</span><span class="n">device</span>
<span class="go">device(type=&#39;cuda&#39;, index=0)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span> <span class="o">=</span> <span class="n">b</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span><span class="o">.</span><span class="n">device</span>
<span class="go">device(type=&#39;cpu&#39;)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">d</span> <span class="o">=</span> <span class="n">c</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">&#39;cuda:1&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">d</span><span class="o">.</span><span class="n">device</span>
<span class="go">device(type=&#39;cuda&#39;, index=1)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>device</strong> – The target device to move this tensor.
Note: The device is represented as a string.
Valid strings are: “cpu”, “cuda:0”, “cuda:1”, etc.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Return a tensor on the given device.</p>
</dd>
</dl>
<ol class="arabic simple" start="3">
<li><p>to(self: k2.ragged.RaggedTensor, dtype: torch::dtype) -&gt; k2.ragged.RaggedTensor</p></li>
</ol>
<p>Convert this tensor to a specific dtype.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If <code class="docutils literal notranslate"><span class="pre">self</span></code> is already of the specified <cite>dtype</cite>, return
a ragged tensor sharing the underlying memory with <code class="docutils literal notranslate"><span class="pre">self</span></code>.
Otherwise, a new tensor is returned.</p>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">dtype</span>
<span class="go">torch.int32</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span><span class="o">.</span><span class="n">dtype</span>
<span class="go">torch.float64</span>
</pre></div>
</div>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>Currently, only support dtypes <code class="docutils literal notranslate"><span class="pre">torch.int32</span></code>, <code class="docutils literal notranslate"><span class="pre">torch.float32</span></code>, and
<code class="docutils literal notranslate"><span class="pre">torch.float64</span></code>. We can support other types if needed.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>dtype</strong> – The <cite>dtype</cite> this tensor should be converted to.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Return a tensor of the given <cite>dtype</cite>.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="id32">
<h3>to_str_simple<a class="headerlink" href="#id32" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.RaggedTensor.to_str_simple">
<span class="sig-prename descclassname"><span class="pre">RaggedTensor.</span></span><span class="sig-name descname"><span class="pre">to_str_simple</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">k2.ragged.RaggedTensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">str</span></span></span><a class="headerlink" href="#k2.RaggedTensor.to_str_simple" title="Permalink to this definition"></a></dt>
<dd><p>Convert a ragged tensor to a string representation, which
is more compact than <code class="docutils literal notranslate"><span class="pre">self.__str__</span></code>.</p>
<p>An example output is given below:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">RaggedTensor</span><span class="p">([[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[],</span> <span class="p">[</span><span class="mi">0</span><span class="p">]],</span> <span class="p">[[</span><span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mf">10.5</span><span class="p">]]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([</span> <span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[],</span> <span class="p">[</span><span class="mi">0</span><span class="p">]],</span> <span class="p">[[</span><span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mf">10.5</span><span class="p">]]</span> <span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>
<span class="go">RaggedTensor([[[1, 2, 3],</span>
<span class="go">               [],</span>
<span class="go">               [0]],</span>
<span class="go">              [[2],</span>
<span class="go">               [3, 10.5]]], dtype=torch.float32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">str</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="go">&#39;RaggedTensor([[[1, 2, 3],\n               [],\n               [0]],\n              [[2],\n               [3, 10.5]]], dtype=torch.float32)&#39;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">to_str_simple</span><span class="p">()</span>
<span class="go">&#39;RaggedTensor([[[1, 2, 3], [], [0]], [[2], [3, 10.5]]], dtype=torch.float32)&#39;</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="tolist">
<h3>tolist<a class="headerlink" href="#tolist" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.RaggedTensor.tolist">
<span class="sig-prename descclassname"><span class="pre">RaggedTensor.</span></span><span class="sig-name descname"><span class="pre">tolist</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">k2.ragged.RaggedTensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">list</span></span></span><a class="headerlink" href="#k2.RaggedTensor.tolist" title="Permalink to this definition"></a></dt>
<dd><p>Turn a ragged tensor into a list of lists [of lists..].</p>
<div class="admonition hint">
<p class="admonition-title">Hint</p>
<p>You can pass the returned list to the constructor of <code class="xref py py-class docutils literal notranslate"><span class="pre">RaggedTensor</span></code>.</p>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([</span> <span class="p">[[],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="p">[]],</span> <span class="p">[[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">]],</span> <span class="p">[[],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[],</span> <span class="p">[]]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
<span class="go">[[[], [1, 2], [3], []], [[5, 6, 7]], [[], [0, 2, 3], [], []]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">tolist</span><span class="p">())</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">==</span> <span class="n">b</span>
<span class="go">True</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([[</span><span class="mf">1.</span><span class="p">],</span> <span class="p">[</span><span class="mf">2.</span><span class="p">],</span> <span class="p">[],</span> <span class="p">[</span><span class="mf">3.25</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
<span class="go">[[1.0], [2.0], [], [3.25, 2.5]]</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A list of list of lists [of lists …] containing the same elements
and structure as <code class="docutils literal notranslate"><span class="pre">self</span></code>.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="id33">
<h3>tot_size<a class="headerlink" href="#id33" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.RaggedTensor.tot_size">
<span class="sig-prename descclassname"><span class="pre">RaggedTensor.</span></span><span class="sig-name descname"><span class="pre">tot_size</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">k2.ragged.RaggedTensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axis</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">int</span></span></span><a class="headerlink" href="#k2.RaggedTensor.tot_size" title="Permalink to this definition"></a></dt>
<dd><p>Return the number of elements of an given axis. If axis is 0, it’s
equivalent to the property <code class="docutils literal notranslate"><span class="pre">dim0</span></code>.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">(</span><span class="s1">&#39;[ [1 2 3] [] [5 8 ] ]&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">tot_size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="go">3</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">tot_size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="go">5</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">(</span><span class="s1">&#39;[ [[1 2 3] [] [5 8]] [[] [1 5 9 10 -1] [] [] []] ]&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span><span class="o">.</span><span class="n">tot_size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="go">2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span><span class="o">.</span><span class="n">tot_size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="go">8</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span><span class="o">.</span><span class="n">tot_size</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="go">10</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="unique">
<h3>unique<a class="headerlink" href="#unique" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.RaggedTensor.unique">
<span class="sig-prename descclassname"><span class="pre">RaggedTensor.</span></span><span class="sig-name descname"><span class="pre">unique</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">k2.ragged.RaggedTensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">need_num_repeats</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">need_new2old_indexes</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">k2.ragged.RaggedTensor</span><span class="p"><span class="pre">,</span> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">k2.ragged.RaggedTensor</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#k2.RaggedTensor.unique" title="Permalink to this definition"></a></dt>
<dd><p>If <code class="docutils literal notranslate"><span class="pre">self</span></code> has two axes, this will return the unique sub-lists
(in a possibly different order, but without repeats).
If <code class="docutils literal notranslate"><span class="pre">self</span></code> has 3 axes, it will do the above but separately for each
index on axis 0; if more than 3 axes, the earliest axes will be ignored.</p>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>It does not completely guarantee that all unique sequences will be
present in the output, as it relies on hashing and ignores collisions.
If several sequences have the same hash, only one of them is kept, even
if the actual content in the sequence is different.</p>
</div>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>Even if there are no repeated sequences, the output may be different
from <code class="docutils literal notranslate"><span class="pre">self</span></code>. That is, <cite>new2old_indexes</cite> may NOT be an identity map even
if nothing was removed.</p>
</div>
<p><strong>Example 1</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">unique</span><span class="p">()</span>
<span class="go">(RaggedTensor([[1],</span>
<span class="go">              [2],</span>
<span class="go">              [3],</span>
<span class="go">              [3, 1]], dtype=torch.int32), None, None)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">need_num_repeats</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">need_new2old_indexes</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="go">(RaggedTensor([[1],</span>
<span class="go">              [2],</span>
<span class="go">              [3],</span>
<span class="go">              [3, 1]], dtype=torch.int32), RaggedTensor([[2, 1, 1, 2]], dtype=torch.int32), tensor([2, 5, 1, 0], dtype=torch.int32))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">need_num_repeats</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="go">(RaggedTensor([[1],</span>
<span class="go">              [2],</span>
<span class="go">              [3],</span>
<span class="go">              [3, 1]], dtype=torch.int32), RaggedTensor([[2, 1, 1, 2]], dtype=torch.int32), None)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">need_new2old_indexes</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="go">(RaggedTensor([[1],</span>
<span class="go">              [2],</span>
<span class="go">              [3],</span>
<span class="go">              [3, 1]], dtype=torch.int32), None, tensor([2, 5, 1, 0], dtype=torch.int32))</span>
</pre></div>
</div>
<p><strong>Example 2</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]],</span> <span class="p">[[</span><span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">]],</span> <span class="p">[[],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[],</span> <span class="p">[</span><span class="mi">3</span><span class="p">]]</span> <span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">unique</span><span class="p">()</span>
<span class="go">(RaggedTensor([[[1, 2],</span>
<span class="go">               [2, 1]],</span>
<span class="go">              [[2],</span>
<span class="go">               [3],</span>
<span class="go">               [0, 1]],</span>
<span class="go">              [[],</span>
<span class="go">               [3],</span>
<span class="go">               [2, 3]]], dtype=torch.int32), None, None)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">need_num_repeats</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">need_new2old_indexes</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="go">(RaggedTensor([[[1, 2],</span>
<span class="go">               [2, 1]],</span>
<span class="go">              [[2],</span>
<span class="go">               [3],</span>
<span class="go">               [0, 1]],</span>
<span class="go">              [[],</span>
<span class="go">               [3],</span>
<span class="go">               [2, 3]]], dtype=torch.int32), RaggedTensor([[3, 1],</span>
<span class="go">              [2, 1, 1],</span>
<span class="go">              [2, 1, 1]], dtype=torch.int32), tensor([ 0,  1,  5,  4,  6,  8, 11,  9], dtype=torch.int32))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">need_num_repeats</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="go">(RaggedTensor([[[1, 2],</span>
<span class="go">               [2, 1]],</span>
<span class="go">              [[2],</span>
<span class="go">               [3],</span>
<span class="go">               [0, 1]],</span>
<span class="go">              [[],</span>
<span class="go">               [3],</span>
<span class="go">               [2, 3]]], dtype=torch.int32), RaggedTensor([[3, 1],</span>
<span class="go">              [2, 1, 1],</span>
<span class="go">              [2, 1, 1]], dtype=torch.int32), None)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">need_new2old_indexes</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="go">(RaggedTensor([[[1, 2],</span>
<span class="go">               [2, 1]],</span>
<span class="go">              [[2],</span>
<span class="go">               [3],</span>
<span class="go">               [0, 1]],</span>
<span class="go">              [[],</span>
<span class="go">               [3],</span>
<span class="go">               [2, 3]]], dtype=torch.int32), None, tensor([ 0,  1,  5,  4,  6,  8, 11,  9], dtype=torch.int32))</span>
</pre></div>
</div>
<p><strong>Example 3</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
<span class="go">(RaggedTensor([[1],</span>
<span class="go">              [2],</span>
<span class="go">              [3]], dtype=torch.int32), RaggedTensor([[1, 1, 1]], dtype=torch.int32), tensor([0, 2, 1], dtype=torch.int32))</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>need_num_repeats</strong> – If True, it also returns the number of repeats of each sequence.</p></li>
<li><p><strong>need_new2old_indexes</strong> – <p>If true, it returns an extra 1-D tensor <cite>new2old_indexes</cite>.
If <cite>src</cite> has 2 axes, this tensor contains <cite>src_idx0</cite>;
if <cite>src</cite> has 3 axes, this tensor contains <cite>src_idx01</cite>.</p>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>For repeated sublists, only one of them is kept.
The choice of which one to keep is <strong>deterministic</strong> and
is an implementation detail.</p>
</div>
</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p>ans: A ragged tensor with the same number of axes as <code class="docutils literal notranslate"><span class="pre">self</span></code> and possibly
fewer elements due to removing repeated sequences on the last axis
(and with the last-but-one indexes possibly in a different order).</p></li>
<li><p>num_repeats: A tensor containing number of repeats of each returned
sequence if <code class="docutils literal notranslate"><span class="pre">need_num_repeats</span></code> is True; it is <code class="docutils literal notranslate"><span class="pre">None</span></code> otherwise.
If it is not <code class="docutils literal notranslate"><span class="pre">None</span></code>, <code class="docutils literal notranslate"><span class="pre">num_repeats.num_axes</span></code> is always 2.
If <code class="docutils literal notranslate"><span class="pre">ans.num_axes</span></code> is 2, then <code class="docutils literal notranslate"><span class="pre">num_repeats.dim0</span> <span class="pre">==</span> <span class="pre">1</span></code> and
<code class="docutils literal notranslate"><span class="pre">num_repeats.numel()</span> <span class="pre">==</span> <span class="pre">ans.dim0</span></code>.
If <code class="docutils literal notranslate"><span class="pre">ans.num_axes</span></code> is 3, then <code class="docutils literal notranslate"><span class="pre">num_repeats.dim0</span> <span class="pre">==</span> <span class="pre">ans.dim0</span></code> and
<code class="docutils literal notranslate"><span class="pre">num_repeats.numel()</span> <span class="pre">==</span> <span class="pre">ans.tot_size(1)</span></code>.</p></li>
<li><p>new2old_indexes: A 1-D tensor whose i-th element specifies the
input sublist that the i-th output sublist corresponds to.</p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Returns a tuple containing</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="id34">
<h3>device<a class="headerlink" href="#id34" title="Permalink to this headline"></a></h3>
<dl class="py attribute">
<dt class="sig sig-object py" id="k2.RaggedTensor.device">
<span class="sig-prename descclassname"><span class="pre">RaggedTensor.</span></span><span class="sig-name descname"><span class="pre">device</span></span><a class="headerlink" href="#k2.RaggedTensor.device" title="Permalink to this definition"></a></dt>
<dd><p>Return the device of this tensor.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">device</span>
<span class="go">device(type=&#39;cpu&#39;)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cuda&#39;</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span><span class="o">.</span><span class="n">device</span>
<span class="go">device(type=&#39;cuda&#39;, index=0)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span><span class="o">.</span><span class="n">device</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cuda:0&#39;</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="id35">
<h3>dim0<a class="headerlink" href="#id35" title="Permalink to this headline"></a></h3>
<dl class="py attribute">
<dt class="sig sig-object py" id="k2.RaggedTensor.dim0">
<span class="sig-prename descclassname"><span class="pre">RaggedTensor.</span></span><span class="sig-name descname"><span class="pre">dim0</span></span><a class="headerlink" href="#k2.RaggedTensor.dim0" title="Permalink to this definition"></a></dt>
<dd><p>Return number of sublists at axis 0.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[]</span> <span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">dim0</span>
<span class="go">5</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">(</span><span class="s1">&#39;[ [[]] [[] []]]&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span><span class="o">.</span><span class="n">dim0</span>
<span class="go">2</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="dtype">
<h3>dtype<a class="headerlink" href="#dtype" title="Permalink to this headline"></a></h3>
<dl class="py attribute">
<dt class="sig sig-object py" id="k2.RaggedTensor.dtype">
<span class="sig-prename descclassname"><span class="pre">RaggedTensor.</span></span><span class="sig-name descname"><span class="pre">dtype</span></span><a class="headerlink" href="#k2.RaggedTensor.dtype" title="Permalink to this definition"></a></dt>
<dd><p>Return the dtype of this tensor.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">dtype</span>
<span class="go">torch.int32</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">dtype</span>
<span class="go">torch.float32</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([[</span><span class="mi">3</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span><span class="o">.</span><span class="n">dtype</span>
<span class="go">torch.float64</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="id36">
<h3>grad<a class="headerlink" href="#id36" title="Permalink to this headline"></a></h3>
<dl class="py attribute">
<dt class="sig sig-object py" id="k2.RaggedTensor.grad">
<span class="sig-prename descclassname"><span class="pre">RaggedTensor.</span></span><span class="sig-name descname"><span class="pre">grad</span></span><a class="headerlink" href="#k2.RaggedTensor.grad" title="Permalink to this definition"></a></dt>
<dd><p>This attribute is <code class="docutils literal notranslate"><span class="pre">None</span></code> by default. PyTorch will set it
during <code class="docutils literal notranslate"><span class="pre">backward()</span></code>.</p>
<p>The attribute will contain the gradients computed and future
calls to <code class="docutils literal notranslate"><span class="pre">backward()</span></code> will accumulate (add) gradients into it.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span> <span class="p">[]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="go">RaggedTensor([[1, 2],</span>
<span class="go">              [3],</span>
<span class="go">              [5, 6],</span>
<span class="go">              []], dtype=torch.float32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span>
<span class="go">tensor([ 3.,  3., 11.,  0.], grad_fn=&lt;SumFunction&gt;&gt;)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span> <span class="o">=</span> <span class="n">b</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">grad</span>
<span class="go">tensor([0., 0., 1., 2., 2.])</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="is-cuda">
<h3>is_cuda<a class="headerlink" href="#is-cuda" title="Permalink to this headline"></a></h3>
<dl class="py attribute">
<dt class="sig sig-object py" id="k2.RaggedTensor.is_cuda">
<span class="sig-prename descclassname"><span class="pre">RaggedTensor.</span></span><span class="sig-name descname"><span class="pre">is_cuda</span></span><a class="headerlink" href="#k2.RaggedTensor.is_cuda" title="Permalink to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Return <code class="docutils literal notranslate"><span class="pre">True</span></code> if the tensor is stored on the GPU, <code class="docutils literal notranslate"><span class="pre">False</span></code>
otherwise.</p>
</dd>
</dl>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">is_cuda</span>
<span class="go">False</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cuda&#39;</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span><span class="o">.</span><span class="n">is_cuda</span>
<span class="go">True</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="id37">
<h3>num_axes<a class="headerlink" href="#id37" title="Permalink to this headline"></a></h3>
<dl class="py attribute">
<dt class="sig sig-object py" id="k2.RaggedTensor.num_axes">
<span class="sig-prename descclassname"><span class="pre">RaggedTensor.</span></span><span class="sig-name descname"><span class="pre">num_axes</span></span><a class="headerlink" href="#k2.RaggedTensor.num_axes" title="Permalink to this definition"></a></dt>
<dd><p>Return the number of axes of this tensor.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">(</span><span class="s1">&#39;[ [] [] [] [] ]&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">num_axes</span>
<span class="go">2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">(</span><span class="s1">&#39;[ [[] []] [[]] ]&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span><span class="o">.</span><span class="n">num_axes</span>
<span class="go">3</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span> <span class="o">=</span> <span class="n">k24</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="s1">&#39;[ [ [[] [1]] [[3 4] []] ]  [ [[1]] [[2] [3 4]] ] ]&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span><span class="o">.</span><span class="n">num_axes</span>
<span class="go">4</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Return number of axes of this tensor, which is at least 2.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="id38">
<h3>requires_grad<a class="headerlink" href="#id38" title="Permalink to this headline"></a></h3>
<dl class="py attribute">
<dt class="sig sig-object py" id="k2.RaggedTensor.requires_grad">
<span class="sig-prename descclassname"><span class="pre">RaggedTensor.</span></span><span class="sig-name descname"><span class="pre">requires_grad</span></span><a class="headerlink" href="#k2.RaggedTensor.requires_grad" title="Permalink to this definition"></a></dt>
<dd><p>Return <code class="docutils literal notranslate"><span class="pre">True</span></code> if gradients need to be computed for this tensor.
Return <code class="docutils literal notranslate"><span class="pre">False</span></code> otherwise.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">requires_grad</span>
<span class="go">False</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">True</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">requires_grad</span>
<span class="go">True</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="id39">
<h3>shape<a class="headerlink" href="#id39" title="Permalink to this headline"></a></h3>
<dl class="py attribute">
<dt class="sig sig-object py" id="k2.RaggedTensor.shape">
<span class="sig-prename descclassname"><span class="pre">RaggedTensor.</span></span><span class="sig-name descname"><span class="pre">shape</span></span><a class="headerlink" href="#k2.RaggedTensor.shape" title="Permalink to this definition"></a></dt>
<dd><p>Return the shape of this tensor.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[],</span> <span class="p">[</span><span class="mi">3</span><span class="p">]</span> <span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">shape</span>
<span class="go">[ [ x x ] [ ] [ x ] ]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">type</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="go">&lt;class &#39;k2.ragged.RaggedShape&#39;&gt;</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="values">
<h3>values<a class="headerlink" href="#values" title="Permalink to this headline"></a></h3>
<dl class="py attribute">
<dt class="sig sig-object py" id="k2.RaggedTensor.values">
<span class="sig-prename descclassname"><span class="pre">RaggedTensor.</span></span><span class="sig-name descname"><span class="pre">values</span></span><a class="headerlink" href="#k2.RaggedTensor.values" title="Permalink to this definition"></a></dt>
<dd><p>Return the underlying memory as a 1-D tensor.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[],</span> <span class="p">[</span><span class="mi">5</span><span class="p">],</span> <span class="p">[],</span> <span class="p">[</span><span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">10</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">values</span>
<span class="go">tensor([ 1,  2,  5,  8,  9, 10], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">isinstance</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span>
<span class="go">True</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>
<span class="go">RaggedTensor([[1, 2],</span>
<span class="go">              [],</span>
<span class="go">              [5],</span>
<span class="go">              [],</span>
<span class="go">              [8, -1, 10]], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">3</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>
<span class="go">RaggedTensor([[1, 2],</span>
<span class="go">              [],</span>
<span class="go">              [5],</span>
<span class="go">              [],</span>
<span class="go">              [-3, -1, 10]], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>
<span class="go">RaggedTensor([[1, 2],</span>
<span class="go">              [],</span>
<span class="go">              [-2],</span>
<span class="go">              [],</span>
<span class="go">              [-3, -1, 10]], dtype=torch.int32)</span>
</pre></div>
</div>
</dd></dl>

</section>
</section>
<section id="symboltable">
<h2>SymbolTable<a class="headerlink" href="#symboltable" title="Permalink to this headline"></a></h2>
<section id="add">
<h3>add<a class="headerlink" href="#add" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.SymbolTable.add">
<span class="sig-prename descclassname"><span class="pre">SymbolTable.</span></span><span class="sig-name descname"><span class="pre">add</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">symbol</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">index</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/k2-fsa/k2/blob/master/k2/python/k2/symbol_table.py#L154-L184"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#k2.SymbolTable.add" title="Permalink to this definition"></a></dt>
<dd><p>Add a new symbol to the SymbolTable.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>symbol</strong> (<em>~Symbol</em>) – The symbol to be added.</p></li>
<li><p><strong>index</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>]) – Optional int id to which the symbol should be assigned.
If it is not available, a ValueError will be raised.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>The int id to which the symbol has been assigned.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="from-file">
<h3>from_file<a class="headerlink" href="#from-file" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.SymbolTable.from_file">
<em class="property"><span class="pre">static</span> </em><span class="sig-prename descclassname"><span class="pre">SymbolTable.</span></span><span class="sig-name descname"><span class="pre">from_file</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">filename</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/k2-fsa/k2/blob/master/k2/python/k2/symbol_table.py#L108-L131"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#k2.SymbolTable.from_file" title="Permalink to this definition"></a></dt>
<dd><p>Build a symbol table from file.</p>
<p>Every line in the symbol table file has two fields separated by
space(s), tab(s) or both. The following is an example file:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">&lt;</span><span class="n">eps</span><span class="o">&gt;</span> <span class="mi">0</span>
<span class="n">a</span> <span class="mi">1</span>
<span class="n">b</span> <span class="mi">2</span>
<span class="n">c</span> <span class="mi">3</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>filename</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – Name of the symbol table file. Its format is documented above.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">SymbolTable</span></code></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>An instance of <code class="xref py py-class docutils literal notranslate"><span class="pre">SymbolTable</span></code>.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="id40">
<h3>from_str<a class="headerlink" href="#id40" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.SymbolTable.from_str">
<em class="property"><span class="pre">static</span> </em><span class="sig-prename descclassname"><span class="pre">SymbolTable.</span></span><span class="sig-name descname"><span class="pre">from_str</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">s</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/k2-fsa/k2/blob/master/k2/python/k2/symbol_table.py#L75-L106"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#k2.SymbolTable.from_str" title="Permalink to this definition"></a></dt>
<dd><p>Build a symbol table from a string.</p>
<p>The string consists of lines. Every line has two fields separated
by space(s), tab(s) or both. The first field is the symbol and the
second the integer id of the symbol.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>s</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – The input string with the format described above.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">SymbolTable</span></code></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>An instance of <code class="xref py py-class docutils literal notranslate"><span class="pre">SymbolTable</span></code>.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="get">
<h3>get<a class="headerlink" href="#get" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.SymbolTable.get">
<span class="sig-prename descclassname"><span class="pre">SymbolTable.</span></span><span class="sig-name descname"><span class="pre">get</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">k</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/k2-fsa/k2/blob/master/k2/python/k2/symbol_table.py#L186-L201"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#k2.SymbolTable.get" title="Permalink to this definition"></a></dt>
<dd><p>Get a symbol for an id or get an id for a symbol</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>k</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>, ~Symbol]) – If it is an id, it tries to find the symbol corresponding
to the id; if it is a symbol, it tries to find the id
corresponding to the symbol.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[~Symbol, <code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>]</p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>An id or a symbol depending on the given <cite>k</cite>.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="merge">
<h3>merge<a class="headerlink" href="#merge" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.SymbolTable.merge">
<span class="sig-prename descclassname"><span class="pre">SymbolTable.</span></span><span class="sig-name descname"><span class="pre">merge</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">other</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/k2-fsa/k2/blob/master/k2/python/k2/symbol_table.py#L203-L220"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#k2.SymbolTable.merge" title="Permalink to this definition"></a></dt>
<dd><p>Create a union of two SymbolTables.
Raises an AssertionError if the same IDs are occupied by
different symbols.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>other</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">SymbolTable</span></code>) – A symbol table to merge with <code class="docutils literal notranslate"><span class="pre">self</span></code>.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">SymbolTable</span></code></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A new symbol table.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="to-file">
<h3>to_file<a class="headerlink" href="#to-file" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.SymbolTable.to_file">
<span class="sig-prename descclassname"><span class="pre">SymbolTable.</span></span><span class="sig-name descname"><span class="pre">to_file</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">filename</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/k2-fsa/k2/blob/master/k2/python/k2/symbol_table.py#L133-L152"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#k2.SymbolTable.to_file" title="Permalink to this definition"></a></dt>
<dd><p>Serialize the SymbolTable to a file.</p>
<p>Every line in the symbol table file has two fields separated by
space(s), tab(s) or both. The following is an example file:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">&lt;</span><span class="n">eps</span><span class="o">&gt;</span> <span class="mi">0</span>
<span class="n">a</span> <span class="mi">1</span>
<span class="n">b</span> <span class="mi">2</span>
<span class="n">c</span> <span class="mi">3</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>filename</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – Name of the symbol table file. Its format is documented above.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="ids">
<h3>ids<a class="headerlink" href="#ids" title="Permalink to this headline"></a></h3>
<dl class="py attribute">
<dt class="sig sig-object py" id="k2.SymbolTable.ids">
<span class="sig-prename descclassname"><span class="pre">SymbolTable.</span></span><span class="sig-name descname"><span class="pre">ids</span></span><a class="headerlink" href="#k2.SymbolTable.ids" title="Permalink to this definition"></a></dt>
<dd><p>Returns a list of integer IDs corresponding to the symbols.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>]</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="symbols">
<h3>symbols<a class="headerlink" href="#symbols" title="Permalink to this headline"></a></h3>
<dl class="py attribute">
<dt class="sig sig-object py" id="k2.SymbolTable.symbols">
<span class="sig-prename descclassname"><span class="pre">SymbolTable.</span></span><span class="sig-name descname"><span class="pre">symbols</span></span><a class="headerlink" href="#k2.SymbolTable.symbols" title="Permalink to this definition"></a></dt>
<dd><p>Returns a list of symbols (e.g., strings) corresponding to
the integer IDs.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[~Symbol]</p>
</dd>
</dl>
</dd></dl>

</section>
</section>
</section>
<section id="k2-ragged">
<h1>k2.ragged<a class="headerlink" href="#k2-ragged" title="Permalink to this headline"></a></h1>
<section id="id41">
<h2>cat<a class="headerlink" href="#id41" title="Permalink to this headline"></a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="k2.ragged.cat">
<span class="sig-prename descclassname"><span class="pre">k2.ragged.</span></span><span class="sig-name descname"><span class="pre">cat</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">srcs</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">k2.ragged.RaggedTensor</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axis</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">k2.ragged.RaggedTensor</span></span></span><a class="headerlink" href="#k2.ragged.cat" title="Permalink to this definition"></a></dt>
<dd><p>Concatenate a list of ragged tensor over a specified axis.</p>
<p><strong>Example 1</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">k2r</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">a</span><span class="p">,</span> <span class="n">a</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="go">RaggedTensor([[1],</span>
<span class="go">              [],</span>
<span class="go">              [2, 3],</span>
<span class="go">              [1],</span>
<span class="go">              [],</span>
<span class="go">              [2, 3]], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">k2r</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">a</span><span class="p">,</span> <span class="n">a</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="go">RaggedTensor([[1, 1],</span>
<span class="go">              [],</span>
<span class="go">              [2, 3, 2, 3]], dtype=torch.int32)</span>
</pre></div>
</div>
<p><strong>Example 2</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[],</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">8</span><span class="p">],</span> <span class="p">[],</span> <span class="p">[</span><span class="mi">9</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">8</span><span class="p">],</span> <span class="p">[],</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">10</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span>
<span class="go">RaggedTensor([[1, 3],</span>
<span class="go">              [],</span>
<span class="go">              [5, 8],</span>
<span class="go">              [],</span>
<span class="go">              [9],</span>
<span class="go">              [0],</span>
<span class="go">              [1, 8],</span>
<span class="go">              [],</span>
<span class="go">              [-1],</span>
<span class="go">              [10]], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span><span class="o">.</span><span class="n">num_axes</span>
<span class="go">2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">d</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">d</span>
<span class="go">RaggedTensor([[1, 3, 0],</span>
<span class="go">              [1, 8],</span>
<span class="go">              [5, 8],</span>
<span class="go">              [-1],</span>
<span class="go">              [9, 10]], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">d</span><span class="o">.</span><span class="n">num_axes</span>
<span class="go">2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="go">RaggedTensor([[1, 3, 0],</span>
<span class="go">              [1, 8],</span>
<span class="go">              [5, 8],</span>
<span class="go">              [-1],</span>
<span class="go">              [9, 10]], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">k2r</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">b</span><span class="p">,</span> <span class="n">a</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="go">RaggedTensor([[0],</span>
<span class="go">              [1, 8],</span>
<span class="go">              [],</span>
<span class="go">              [-1],</span>
<span class="go">              [10],</span>
<span class="go">              [1, 3],</span>
<span class="go">              [],</span>
<span class="go">              [5, 8],</span>
<span class="go">              [],</span>
<span class="go">              [9]], dtype=torch.int32)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>srcs</strong> – A list (or a tuple) of ragged tensors to concatenate. They <strong>MUST</strong> all
have the same dtype and on the same device.</p></li>
<li><p><strong>axis</strong> – Only 0 and 1 are supported right now. If it is 1, then
<code class="docutils literal notranslate"><span class="pre">srcs[i].dim0</span></code> must all have the same value.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Return a concatenated tensor.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="create-ragged-shape2">
<h2>create_ragged_shape2<a class="headerlink" href="#create-ragged-shape2" title="Permalink to this headline"></a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="k2.ragged.create_ragged_shape2">
<span class="sig-prename descclassname"><span class="pre">k2.ragged.</span></span><span class="sig-name descname"><span class="pre">create_ragged_shape2</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">row_splits</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">row_ids</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cached_tot_size</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">-</span> <span class="pre">1</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">k2.ragged.RaggedShape</span></span></span><a class="headerlink" href="#k2.ragged.create_ragged_shape2" title="Permalink to this definition"></a></dt>
<dd><p>Construct a RaggedShape from row_ids and/or row_splits vectors.  For
the overall concepts, please see comments in k2/csrc/utils.h.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedShape</span><span class="p">(</span><span class="s1">&#39;[[x x] [x]]&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">k2r</span><span class="o">.</span><span class="n">create_ragged_shape2</span><span class="p">(</span><span class="n">shape</span><span class="o">.</span><span class="n">row_splits</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="n">shape</span><span class="o">.</span><span class="n">row_ids</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
<span class="go">[ [ x x ] [ x ] ]</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>row_splits</strong> – Optionally, a torch.Tensor with dtype=torch.int32 and one axis</p></li>
<li><p><strong>row_ids</strong> – Optionally, a torch.Tensor with dtype=torch.int32 and one axis.</p></li>
<li><p><strong>cached_tot_size</strong> – The number of elements (length of row_ids, even if row_ids
is not provided); would be identical to the last element of row_splits,
but can avoid a GPU to CPU transfer if known.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>An instance of <code class="xref py py-class docutils literal notranslate"><span class="pre">RaggedShape</span></code>, with <code class="docutils literal notranslate"><span class="pre">ans.num_axes</span> <span class="pre">==</span> <span class="pre">2</span></code>.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="create-ragged-tensor">
<h2>create_ragged_tensor<a class="headerlink" href="#create-ragged-tensor" title="Permalink to this headline"></a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="k2.ragged.create_ragged_tensor">
<span class="sig-prename descclassname"><span class="pre">k2.ragged.</span></span><span class="sig-name descname"><span class="pre">create_ragged_tensor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#k2.ragged.create_ragged_tensor" title="Permalink to this definition"></a></dt>
<dd><p>Overloaded function.</p>
<ol class="arabic simple">
<li><p>create_ragged_tensor(data: list, dtype: object = None, device: torch::Device = device(type=’cpu’)) -&gt; k2.ragged.RaggedTensor</p></li>
</ol>
<p>Create a ragged tensor with arbitrary number of axes.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>A ragged tensor has at least two axes.</p>
</div>
<div class="admonition hint">
<p class="admonition-title">Hint</p>
<p>The returned tensor is on CPU.</p>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">create_ragged_tensor</span><span class="p">([</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">5</span><span class="p">],</span> <span class="p">[],</span> <span class="p">[</span><span class="mi">9</span><span class="p">]</span> <span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>
<span class="go">RaggedTensor([[1, 2],</span>
<span class="go">              [5],</span>
<span class="go">              [],</span>
<span class="go">              [9]], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">dtype</span>
<span class="go">torch.int32</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">create_ragged_tensor</span><span class="p">([</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">],</span> <span class="p">[]</span> <span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span>
<span class="go">RaggedTensor([[1, 3],</span>
<span class="go">              []], dtype=torch.float32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span><span class="o">.</span><span class="n">dtype</span>
<span class="go">torch.float32</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">create_ragged_tensor</span><span class="p">([</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span><span class="o">.</span><span class="n">dtype</span>
<span class="go">torch.float64</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">d</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">create_ragged_tensor</span><span class="p">([</span> <span class="p">[[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]],</span> <span class="p">[[</span><span class="mi">4</span><span class="p">],</span> <span class="p">[]]</span> <span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">d</span>
<span class="go">RaggedTensor([[[1],</span>
<span class="go">               [2, 3]],</span>
<span class="go">              [[4],</span>
<span class="go">               []]], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">d</span><span class="o">.</span><span class="n">num_axes</span>
<span class="go">3</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">e</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">create_ragged_tensor</span><span class="p">([])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">e</span>
<span class="go">RaggedTensor([], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">e</span><span class="o">.</span><span class="n">num_axes</span>
<span class="go">2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">e</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="n">row_splits</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="go">tensor([0], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">e</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="n">row_ids</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="go">tensor([], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">f</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">create_ragged_tensor</span><span class="p">([</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[],</span> <span class="p">[</span><span class="mi">3</span><span class="p">]</span> <span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cuda&#39;</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">f</span>
<span class="go">RaggedTensor([[1, 2],</span>
<span class="go">              [],</span>
<span class="go">              [3]], device=&#39;cuda:0&#39;, dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">e</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">create_ragged_tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[]],</span> <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cuda:1&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">e</span>
<span class="go">RaggedTensor([[1],</span>
<span class="go">              []], device=&#39;cuda:1&#39;, dtype=torch.int32)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> – A list-of sublist(s) of integers or real numbers.
It can have arbitrary number of axes (at least two).</p></li>
<li><p><strong>dtype</strong> – Optional. If None, it infers the dtype from <code class="docutils literal notranslate"><span class="pre">data</span></code>
automatically, which is either <code class="docutils literal notranslate"><span class="pre">torch.int32</span></code> or
<code class="docutils literal notranslate"><span class="pre">torch.float32</span></code>. Supported dtypes are: <code class="docutils literal notranslate"><span class="pre">torch.int32</span></code>,
<code class="docutils literal notranslate"><span class="pre">torch.float32</span></code>, and <code class="docutils literal notranslate"><span class="pre">torch.float64</span></code>.</p></li>
<li><p><strong>device</strong> – It can be either an instance of <code class="docutils literal notranslate"><span class="pre">torch.device</span></code> or
a string representing a torch device. Example
values are: <code class="docutils literal notranslate"><span class="pre">&quot;cpu&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">&quot;cuda:0&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">torch.device(&quot;cpu&quot;)</span></code>,
<code class="docutils literal notranslate"><span class="pre">torch.device(&quot;cuda&quot;,</span> <span class="pre">0)</span></code>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Return a ragged tensor.</p>
</dd>
</dl>
<ol class="arabic simple" start="2">
<li><p>create_ragged_tensor(data: list, dtype: object = None, device: str = ‘cpu’) -&gt; k2.ragged.RaggedTensor</p></li>
</ol>
<p>Create a ragged tensor with arbitrary number of axes.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>A ragged tensor has at least two axes.</p>
</div>
<div class="admonition hint">
<p class="admonition-title">Hint</p>
<p>The returned tensor is on CPU.</p>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">create_ragged_tensor</span><span class="p">([</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">5</span><span class="p">],</span> <span class="p">[],</span> <span class="p">[</span><span class="mi">9</span><span class="p">]</span> <span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>
<span class="go">RaggedTensor([[1, 2],</span>
<span class="go">              [5],</span>
<span class="go">              [],</span>
<span class="go">              [9]], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">dtype</span>
<span class="go">torch.int32</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">create_ragged_tensor</span><span class="p">([</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">],</span> <span class="p">[]</span> <span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span>
<span class="go">RaggedTensor([[1, 3],</span>
<span class="go">              []], dtype=torch.float32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span><span class="o">.</span><span class="n">dtype</span>
<span class="go">torch.float32</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">create_ragged_tensor</span><span class="p">([</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span><span class="o">.</span><span class="n">dtype</span>
<span class="go">torch.float64</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">d</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">create_ragged_tensor</span><span class="p">([</span> <span class="p">[[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]],</span> <span class="p">[[</span><span class="mi">4</span><span class="p">],</span> <span class="p">[]]</span> <span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">d</span>
<span class="go">RaggedTensor([[[1],</span>
<span class="go">               [2, 3]],</span>
<span class="go">              [[4],</span>
<span class="go">               []]], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">d</span><span class="o">.</span><span class="n">num_axes</span>
<span class="go">3</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">e</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">create_ragged_tensor</span><span class="p">([])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">e</span>
<span class="go">RaggedTensor([], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">e</span><span class="o">.</span><span class="n">num_axes</span>
<span class="go">2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">e</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="n">row_splits</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="go">tensor([0], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">e</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="n">row_ids</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="go">tensor([], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">f</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">create_ragged_tensor</span><span class="p">([</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[],</span> <span class="p">[</span><span class="mi">3</span><span class="p">]</span> <span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cuda&#39;</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">f</span>
<span class="go">RaggedTensor([[1, 2],</span>
<span class="go">              [],</span>
<span class="go">              [3]], device=&#39;cuda:0&#39;, dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">e</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">create_ragged_tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[]],</span> <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cuda:1&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">e</span>
<span class="go">RaggedTensor([[1],</span>
<span class="go">              []], device=&#39;cuda:1&#39;, dtype=torch.int32)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> – A list-of sublist(s) of integers or real numbers.
It can have arbitrary number of axes (at least two).</p></li>
<li><p><strong>dtype</strong> – Optional. If None, it infers the dtype from <code class="docutils literal notranslate"><span class="pre">data</span></code>
automatically, which is either <code class="docutils literal notranslate"><span class="pre">torch.int32</span></code> or
<code class="docutils literal notranslate"><span class="pre">torch.float32</span></code>. Supported dtypes are: <code class="docutils literal notranslate"><span class="pre">torch.int32</span></code>,
<code class="docutils literal notranslate"><span class="pre">torch.float32</span></code>, and <code class="docutils literal notranslate"><span class="pre">torch.float64</span></code>.</p></li>
<li><p><strong>device</strong> – It can be either an instance of <code class="docutils literal notranslate"><span class="pre">torch.device</span></code> or
a string representing a torch device. Example
values are: <code class="docutils literal notranslate"><span class="pre">&quot;cpu&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">&quot;cuda:0&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">torch.device(&quot;cpu&quot;)</span></code>,
<code class="docutils literal notranslate"><span class="pre">torch.device(&quot;cuda&quot;,</span> <span class="pre">0)</span></code>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Return a ragged tensor.</p>
</dd>
</dl>
<ol class="arabic simple" start="3">
<li><p>create_ragged_tensor(s: str, dtype: object = None, device: torch::Device = device(type=’cpu’)) -&gt; k2.ragged.RaggedTensor</p></li>
</ol>
<p>Create a ragged tensor from its string representation.</p>
<p>Fields are separated by space(s) <strong>or</strong> comma(s).</p>
<p>An example string for a 2-axis ragged tensor is given below:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">5</span> <span class="mi">6</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">]</span> <span class="p">]</span>
</pre></div>
</div>
<p>An example string for a 3-axis ragged tensor is given below:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span> <span class="p">[[</span><span class="mi">1</span><span class="p">]]</span> <span class="p">[[]]</span> <span class="p">]</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">create_ragged_tensor</span><span class="p">(</span><span class="s1">&#39;[ [1] [] [3 4] ]&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>
<span class="go">RaggedTensor([[1],</span>
<span class="go">              [],</span>
<span class="go">              [3, 4]], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">num_axes</span>
<span class="go">2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">dtype</span>
<span class="go">torch.int32</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">create_ragged_tensor</span><span class="p">(</span><span class="s1">&#39;[ [[] [3]]  [[10]] ]&#39;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span>
<span class="go">[ [ [ ] [ 3 ] ] [ [ 10 ] ] ]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span><span class="o">.</span><span class="n">dtype</span>
<span class="go">torch.float32</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span><span class="o">.</span><span class="n">num_axes</span>
<span class="go">3</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">create_ragged_tensor</span><span class="p">(</span><span class="s1">&#39;[[1.]]&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span><span class="o">.</span><span class="n">dtype</span>
<span class="go">torch.float32</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Number of spaces or commas in <code class="docutils literal notranslate"><span class="pre">s</span></code> does not affect the result.
Of course, numbers have to be separated by at least one space or comma.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>s</strong> – A string representation of a ragged tensor.</p></li>
<li><p><strong>dtype</strong> – The desired dtype of the tensor. If it is <code class="docutils literal notranslate"><span class="pre">None</span></code>, it tries
to infer the correct dtype from <code class="docutils literal notranslate"><span class="pre">s</span></code>, which is assumed to be
either <code class="docutils literal notranslate"><span class="pre">torch.int32</span></code> or <code class="docutils literal notranslate"><span class="pre">torch.float32</span></code>. Supported dtypes are:
<code class="docutils literal notranslate"><span class="pre">torch.int32</span></code>, <code class="docutils literal notranslate"><span class="pre">torch.float32</span></code>, and <code class="docutils literal notranslate"><span class="pre">torch.float64</span></code>.</p></li>
<li><p><strong>device</strong> – It can be either an instance of <code class="docutils literal notranslate"><span class="pre">torch.device</span></code> or
a string representing a torch device. Example
values are: <code class="docutils literal notranslate"><span class="pre">&quot;cpu&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">&quot;cuda:0&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">torch.device(&quot;cpu&quot;)</span></code>,
<code class="docutils literal notranslate"><span class="pre">torch.device(&quot;cuda&quot;,</span> <span class="pre">0)</span></code>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Return a ragged tensor.</p>
</dd>
</dl>
<ol class="arabic simple" start="4">
<li><p>create_ragged_tensor(s: str, dtype: object = None, device: str = ‘cpu’) -&gt; k2.ragged.RaggedTensor</p></li>
</ol>
<p>Create a ragged tensor from its string representation.</p>
<p>Fields are separated by space(s) <strong>or</strong> comma(s).</p>
<p>An example string for a 2-axis ragged tensor is given below:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">5</span> <span class="mi">6</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">]</span> <span class="p">]</span>
</pre></div>
</div>
<p>An example string for a 3-axis ragged tensor is given below:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span> <span class="p">[[</span><span class="mi">1</span><span class="p">]]</span> <span class="p">[[]]</span> <span class="p">]</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">create_ragged_tensor</span><span class="p">(</span><span class="s1">&#39;[ [1] [] [3 4] ]&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>
<span class="go">RaggedTensor([[1],</span>
<span class="go">              [],</span>
<span class="go">              [3, 4]], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">num_axes</span>
<span class="go">2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">dtype</span>
<span class="go">torch.int32</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">create_ragged_tensor</span><span class="p">(</span><span class="s1">&#39;[ [[] [3]]  [[10]] ]&#39;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span>
<span class="go">[ [ [ ] [ 3 ] ] [ [ 10 ] ] ]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span><span class="o">.</span><span class="n">dtype</span>
<span class="go">torch.float32</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span><span class="o">.</span><span class="n">num_axes</span>
<span class="go">3</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">create_ragged_tensor</span><span class="p">(</span><span class="s1">&#39;[[1.]]&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span><span class="o">.</span><span class="n">dtype</span>
<span class="go">torch.float32</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Number of spaces or commas in <code class="docutils literal notranslate"><span class="pre">s</span></code> does not affect the result.
Of course, numbers have to be separated by at least one space or comma.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>s</strong> – A string representation of a ragged tensor.</p></li>
<li><p><strong>dtype</strong> – The desired dtype of the tensor. If it is <code class="docutils literal notranslate"><span class="pre">None</span></code>, it tries
to infer the correct dtype from <code class="docutils literal notranslate"><span class="pre">s</span></code>, which is assumed to be
either <code class="docutils literal notranslate"><span class="pre">torch.int32</span></code> or <code class="docutils literal notranslate"><span class="pre">torch.float32</span></code>. Supported dtypes are:
<code class="docutils literal notranslate"><span class="pre">torch.int32</span></code>, <code class="docutils literal notranslate"><span class="pre">torch.float32</span></code>, and <code class="docutils literal notranslate"><span class="pre">torch.float64</span></code>.</p></li>
<li><p><strong>device</strong> – It can be either an instance of <code class="docutils literal notranslate"><span class="pre">torch.device</span></code> or
a string representing a torch device. Example
values are: <code class="docutils literal notranslate"><span class="pre">&quot;cpu&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">&quot;cuda:0&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">torch.device(&quot;cpu&quot;)</span></code>,
<code class="docutils literal notranslate"><span class="pre">torch.device(&quot;cuda&quot;,</span> <span class="pre">0)</span></code>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Return a ragged tensor.</p>
</dd>
</dl>
<ol class="arabic simple" start="5">
<li><p>create_ragged_tensor(tensor: torch.Tensor) -&gt; k2.ragged.RaggedTensor</p></li>
</ol>
<p>Create a ragged tensor from a torch tensor.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>It turns a regular tensor into a ragged tensor.</p>
</div>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>The input tensor has to have more than 1 dimension.
That is <code class="docutils literal notranslate"><span class="pre">tensor.ndim</span> <span class="pre">&gt;</span> <span class="pre">1</span></code>.</p>
<p>Also, if the input tensor is contiguous, <code class="docutils literal notranslate"><span class="pre">self</span></code>
will share the underlying memory with it. Otherwise,
memory of the input tensor is copied to create <code class="docutils literal notranslate"><span class="pre">self</span></code>.</p>
<p>Supported dtypes of the input tensor are: <code class="docutils literal notranslate"><span class="pre">torch.int32</span></code>,
<code class="docutils literal notranslate"><span class="pre">torch.float32</span></code>, and <code class="docutils literal notranslate"><span class="pre">torch.float64</span></code>.</p>
</div>
<p><strong>Example 1</strong>:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">create_ragged_tensor</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>
<span class="go">tensor([[0, 1, 2],</span>
<span class="go">        [3, 4, 5]], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span>
<span class="go">RaggedTensor([[0, 1, 2],</span>
<span class="go">              [3, 4, 5]], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span><span class="o">.</span><span class="n">dtype</span>
<span class="go">torch.int32</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">is_contiguous</span><span class="p">()</span>
<span class="go">True</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">10</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span>
<span class="go">RaggedTensor([[10, 1, 2],</span>
<span class="go">              [3, 4, 5]], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>
<span class="go">tensor([[10, -2,  2],</span>
<span class="go">        [ 3,  4,  5]], dtype=torch.int32)</span>
</pre></div>
</div>
<p><strong>Example 2</strong>:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">24</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">12</span><span class="p">)[:,</span> <span class="p">::</span><span class="mi">4</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>
<span class="go">tensor([[ 0,  4,  8],</span>
<span class="go">        [12, 16, 20]], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">is_contiguous</span><span class="p">()</span>
<span class="go">False</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">create_ragged_tensor</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span>
<span class="go">RaggedTensor([[0, 4, 8],</span>
<span class="go">              [12, 16, 20]], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span><span class="o">.</span><span class="n">dtype</span>
<span class="go">torch.int32</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">10</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span>
<span class="go">RaggedTensor([[0, 4, 8],</span>
<span class="go">              [12, 16, 20]], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>
<span class="go">tensor([[10,  4,  8],</span>
<span class="go">        [12, 16, 20]], dtype=torch.int32)</span>
</pre></div>
</div>
<p><strong>Example 3</strong>:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">24</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>
<span class="go">tensor([[[ 0.,  1.,  2.,  3.],</span>
<span class="go">         [ 4.,  5.,  6.,  7.],</span>
<span class="go">         [ 8.,  9., 10., 11.]],</span>
<span class="go">        [[12., 13., 14., 15.],</span>
<span class="go">         [16., 17., 18., 19.],</span>
<span class="go">         [20., 21., 22., 23.]]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">create_ragged_tensor</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span>
<span class="go">RaggedTensor([[[0, 1, 2, 3],</span>
<span class="go">               [4, 5, 6, 7],</span>
<span class="go">               [8, 9, 10, 11]],</span>
<span class="go">              [[12, 13, 14, 15],</span>
<span class="go">               [16, 17, 18, 19],</span>
<span class="go">               [20, 21, 22, 23]]], dtype=torch.float32)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>tensor</strong> – An N-D (N &gt; 1) tensor.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Return a ragged tensor.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="id42">
<h2>index<a class="headerlink" href="#id42" title="Permalink to this headline"></a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="k2.ragged.index">
<span class="sig-prename descclassname"><span class="pre">k2.ragged.</span></span><span class="sig-name descname"><span class="pre">index</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">src</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">indexes</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">k2.ragged.RaggedTensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">default_value</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">object</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">k2.ragged.RaggedTensor</span></span></span><a class="headerlink" href="#k2.ragged.index" title="Permalink to this definition"></a></dt>
<dd><p>Use a ragged tensor to index a 1-d torch tensor.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">i</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span> <span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">src</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span> <span class="o">*</span> <span class="mi">10</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">src</span>
<span class="go">tensor([ 0, 10, 20, 30, 40, 50], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">k2r</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">src</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>
<span class="go">RaggedTensor([[10, 50, 30],</span>
<span class="go">              [0, 20]], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">k</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([</span> <span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">]],</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">]]</span> <span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">k2r</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">src</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span>
<span class="go">RaggedTensor([[[10, 50, 30],</span>
<span class="go">               [0]],</span>
<span class="go">              [[0, 20],</span>
<span class="go">               [10, 30]]], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">n</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">k2r</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">src</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>
<span class="go">RaggedTensor([[10, 0],</span>
<span class="go">              [0, 0],</span>
<span class="go">              [0]], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">k2r</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">src</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">default_value</span><span class="o">=-</span><span class="mi">2</span><span class="p">)</span>
<span class="go">RaggedTensor([[10, -2],</span>
<span class="go">              [-2, 0],</span>
<span class="go">              [-2]], dtype=torch.int32)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>src</strong> – A 1-D torch tensor.</p></li>
<li><p><strong>indexes</strong> – A ragged tensor with dtype <code class="docutils literal notranslate"><span class="pre">torch.int32</span></code>.</p></li>
<li><p><strong>default_value</strong> – Used only when an entry in <code class="docutils literal notranslate"><span class="pre">indexes</span></code> is -1, in which case
it returns <code class="docutils literal notranslate"><span class="pre">default_value</span></code> as -1 is not a valid index.
If it is <code class="docutils literal notranslate"><span class="pre">None</span></code> and an entry in <code class="docutils literal notranslate"><span class="pre">indexes</span></code> is -1, 0 is returned.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Return a ragged tensor with the same dtype and device as <code class="docutils literal notranslate"><span class="pre">src</span></code>.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="index-and-sum">
<h2>index_and_sum<a class="headerlink" href="#index-and-sum" title="Permalink to this headline"></a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="k2.ragged.index_and_sum">
<span class="sig-prename descclassname"><span class="pre">k2.ragged.</span></span><span class="sig-name descname"><span class="pre">index_and_sum</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">src</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">indexes</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">k2.ragged.RaggedTensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="headerlink" href="#k2.ragged.index_and_sum" title="Permalink to this definition"></a></dt>
<dd><p>Index a 1-D tensor with a ragged tensor of indexes, perform
a sum-per-sublist operation, and return the resulting 1-D tensor.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">i</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">src</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="o">*</span> <span class="mi">10</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">src</span>
<span class="go">tensor([ 0., 10., 20., 30., 40., 50.])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">k2r</span><span class="o">.</span><span class="n">index_and_sum</span><span class="p">(</span><span class="n">src</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>
<span class="go">tensor([90., 50.])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">k</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">k2r</span><span class="o">.</span><span class="n">index_and_sum</span><span class="p">(</span><span class="n">src</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span>
<span class="go">tensor([30.,  0., 70.])</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>src</strong> – A 1-D tensor.</p></li>
<li><p><strong>indexes</strong> – A ragged tensor with two axes. Its dtype MUST be <code class="docutils literal notranslate"><span class="pre">torch.int32</span></code>.
For instance, it can be the arc map returned from the function
<code class="docutils literal notranslate"><span class="pre">remove_epsilon</span></code>. If an index is -1, the resulting sublist
is 0.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Return a 1-D tensor with the same dtype and device as <code class="docutils literal notranslate"><span class="pre">src</span></code>.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="random-ragged-shape">
<h2>random_ragged_shape<a class="headerlink" href="#random-ragged-shape" title="Permalink to this headline"></a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="k2.ragged.random_ragged_shape">
<span class="sig-prename descclassname"><span class="pre">k2.ragged.</span></span><span class="sig-name descname"><span class="pre">random_ragged_shape</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">set_row_ids</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_num_axes</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_num_axes</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">4</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_num_elements</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_num_elements</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">2000</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">k2.ragged.RaggedShape</span></span></span><a class="headerlink" href="#k2.ragged.random_ragged_shape" title="Permalink to this definition"></a></dt>
<dd><p>RandomRaggedShape</p>
</dd></dl>

</section>
<section id="id43">
<h2>regular_ragged_shape<a class="headerlink" href="#id43" title="Permalink to this headline"></a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="k2.ragged.regular_ragged_shape">
<span class="sig-prename descclassname"><span class="pre">k2.ragged.</span></span><span class="sig-name descname"><span class="pre">regular_ragged_shape</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dim0</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dim1</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">k2.ragged.RaggedShape</span></span></span><a class="headerlink" href="#k2.ragged.regular_ragged_shape" title="Permalink to this definition"></a></dt>
<dd><p>Create a ragged shape with 2 axes that has a regular structure.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape1</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedShape</span><span class="o">.</span><span class="n">regular_ragged_shape</span><span class="p">(</span><span class="n">dim0</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim1</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape1</span>
<span class="go">[ [ x x x ] [ x x x ] ]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape2</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">regular_ragged_shape</span><span class="p">(</span><span class="n">dim0</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">dim1</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape2</span>
<span class="go">[ [ x x ] [ x x ] [ x x ] ]</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dim0</strong> – Number of entries at axis 0.</p></li>
<li><p><strong>dim1</strong> – Number of entries in each sublist at axis 1.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Return a ragged shape on CPU.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="id44">
<h2>RaggedShape<a class="headerlink" href="#id44" title="Permalink to this headline"></a></h2>
<section id="id45">
<h3>__eq__<a class="headerlink" href="#id45" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.ragged.RaggedShape.__eq__">
<span class="sig-prename descclassname"><span class="pre">RaggedShape.</span></span><span class="sig-name descname"><span class="pre">__eq__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">k2.ragged.RaggedShape</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">other</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">k2.ragged.RaggedShape</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">bool</span></span></span><a class="headerlink" href="#k2.ragged.RaggedShape.__eq__" title="Permalink to this definition"></a></dt>
<dd><p>Return <code class="docutils literal notranslate"><span class="pre">True</span></code> if two shapes are equal. Otherwise, return <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>The two shapes have to be on the same device. Otherwise, it throws
an exception.</p>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape1</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedShape</span><span class="p">(</span><span class="s1">&#39;[ [] [x] ]&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape2</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedShape</span><span class="p">(</span><span class="s1">&#39;[ [x] [x] ]&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape3</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedShape</span><span class="p">(</span><span class="s1">&#39;[ [x] [x] ]&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape1</span> <span class="o">==</span> <span class="n">shape2</span>
<span class="go">False</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape3</span> <span class="o">==</span> <span class="n">shape2</span>
<span class="go">True</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>other</strong> – The shape that we want to compare with <code class="docutils literal notranslate"><span class="pre">self</span></code>.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Return <code class="docutils literal notranslate"><span class="pre">True</span></code> if the two shapes are the same.
Return <code class="docutils literal notranslate"><span class="pre">False</span></code> otherwise.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="id46">
<h3>__getitem__<a class="headerlink" href="#id46" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.ragged.RaggedShape.__getitem__">
<span class="sig-prename descclassname"><span class="pre">RaggedShape.</span></span><span class="sig-name descname"><span class="pre">__getitem__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">k2.ragged.RaggedShape</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">i</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">k2.ragged.RaggedShape</span></span></span><a class="headerlink" href="#k2.ragged.RaggedShape.__getitem__" title="Permalink to this definition"></a></dt>
<dd><p>Select the i-th sublist along axis 0.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>It requires that this shape has at least 3 axes.</p>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedShape</span><span class="p">(</span><span class="s1">&#39;[ [[x] [x x]] [[x x x] [] [x x]] ]&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="go">[ [ x ] [ x x ] ]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="go">[ [ x x x ] [ ] [ x x ] ]</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>i</strong> – The i-th sublist along axis 0.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Return a new ragged shape with one fewer axis.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="id47">
<h3>__init__<a class="headerlink" href="#id47" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.ragged.RaggedShape.__init__">
<span class="sig-prename descclassname"><span class="pre">RaggedShape.</span></span><span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">k2.ragged.RaggedShape</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">s</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#k2.ragged.RaggedShape.__init__" title="Permalink to this definition"></a></dt>
<dd><p>Construct a ragged shape from a string.</p>
<p>An example string for a ragged shape with 2 axes is:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span> <span class="p">[</span><span class="n">x</span> <span class="n">x</span><span class="p">]</span> <span class="p">[</span> <span class="p">]</span> <span class="p">[</span><span class="n">x</span><span class="p">]</span> <span class="p">]</span>
</pre></div>
</div>
<p>An example string for a ragged shape with 3 axes is:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span> <span class="p">[[</span><span class="n">x</span><span class="p">]</span> <span class="p">[]]</span> <span class="p">[[</span><span class="n">x</span><span class="p">]</span> <span class="p">[</span><span class="n">x</span> <span class="n">x</span><span class="p">]]</span> <span class="p">]</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedShape</span><span class="p">(</span><span class="s1">&#39;[ [x] [] [x x] ]&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape</span>
<span class="go">[ [ x ] [ ] [ x x ] ]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape2</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedShape</span><span class="p">(</span><span class="s1">&#39;[ [[x] [] [x x]] [[]] ]&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape2</span>
<span class="go">[ [ [ x ] [ ] [ x x ] ] [ [ ] ] ]</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="id48">
<h3>__ne__<a class="headerlink" href="#id48" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.ragged.RaggedShape.__ne__">
<span class="sig-prename descclassname"><span class="pre">RaggedShape.</span></span><span class="sig-name descname"><span class="pre">__ne__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">k2.ragged.RaggedShape</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">other</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">k2.ragged.RaggedShape</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">bool</span></span></span><a class="headerlink" href="#k2.ragged.RaggedShape.__ne__" title="Permalink to this definition"></a></dt>
<dd><p>Return <code class="docutils literal notranslate"><span class="pre">True</span></code> if two shapes are not equal. Otherwise, return <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>The two shapes have to be on the same device. Otherwise, it throws
an exception.</p>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape1</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedShape</span><span class="p">(</span><span class="s1">&#39;[ [] [x] ]&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape2</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedShape</span><span class="p">(</span><span class="s1">&#39;[ [x] [x] ]&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape3</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedShape</span><span class="p">(</span><span class="s1">&#39;[ [x] [x] ]&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape1</span> <span class="o">!=</span> <span class="n">shape2</span>
<span class="go">True</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape2</span> <span class="o">!=</span> <span class="n">shape3</span>
<span class="go">False</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>other</strong> – The shape that we want to compare with <code class="docutils literal notranslate"><span class="pre">self</span></code>.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Return <code class="docutils literal notranslate"><span class="pre">True</span></code> if the two shapes are not equal.
Return <code class="docutils literal notranslate"><span class="pre">False</span></code> otherwise.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="id49">
<h3>__repr__<a class="headerlink" href="#id49" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.ragged.RaggedShape.__repr__">
<span class="sig-prename descclassname"><span class="pre">RaggedShape.</span></span><span class="sig-name descname"><span class="pre">__repr__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">k2.ragged.RaggedShape</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">str</span></span></span><a class="headerlink" href="#k2.ragged.RaggedShape.__repr__" title="Permalink to this definition"></a></dt>
<dd><p>Return a string representation of this shape.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedShape</span><span class="p">(</span><span class="s1">&#39;[ [x] [] [x x ] ]&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
<span class="go">[ [ x ] [ ] [ x x ] ]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape</span>
<span class="go">[ [ x ] [ ] [ x x ] ]</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="id50">
<h3>__str__<a class="headerlink" href="#id50" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.ragged.RaggedShape.__str__">
<span class="sig-prename descclassname"><span class="pre">RaggedShape.</span></span><span class="sig-name descname"><span class="pre">__str__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">k2.ragged.RaggedShape</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">str</span></span></span><a class="headerlink" href="#k2.ragged.RaggedShape.__str__" title="Permalink to this definition"></a></dt>
<dd><p>Return a string representation of this shape.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedShape</span><span class="p">(</span><span class="s1">&#39;[ [x] [] [x x ] ]&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
<span class="go">[ [ x ] [ ] [ x x ] ]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape</span>
<span class="go">[ [ x ] [ ] [ x x ] ]</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="id51">
<h3>compose<a class="headerlink" href="#id51" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.ragged.RaggedShape.compose">
<span class="sig-prename descclassname"><span class="pre">RaggedShape.</span></span><span class="sig-name descname"><span class="pre">compose</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">k2.ragged.RaggedShape</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">other</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">k2.ragged.RaggedShape</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">k2.ragged.RaggedShape</span></span></span><a class="headerlink" href="#k2.ragged.RaggedShape.compose" title="Permalink to this definition"></a></dt>
<dd><p>Compose <code class="docutils literal notranslate"><span class="pre">self</span></code> with a given shape.</p>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p><code class="docutils literal notranslate"><span class="pre">other</span></code> and <code class="docutils literal notranslate"><span class="pre">self</span></code> MUST be on the same device.</p>
</div>
<div class="admonition hint">
<p class="admonition-title">Hint</p>
<p>In order to compose <code class="docutils literal notranslate"><span class="pre">self</span></code> with <code class="docutils literal notranslate"><span class="pre">other</span></code>, it has to
satisfy <code class="docutils literal notranslate"><span class="pre">self.tot_size(self.num_axes</span> <span class="pre">-</span> <span class="pre">1)</span> <span class="pre">==</span> <span class="pre">other.dim0</span></code></p>
</div>
<p><strong>Example 1</strong>:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape1</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedShape</span><span class="p">(</span><span class="s1">&#39;[ [x x] [x] ]&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape2</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedShape</span><span class="p">(</span><span class="s1">&#39;[ [x x x] [x x] [] ]&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape1</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">shape2</span><span class="p">)</span>
<span class="go">[ [ [ x x x ] [ x x ] ] [ [ ] ] ]</span>
</pre></div>
</div>
<p><strong>Example 2</strong>:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape1</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedShape</span><span class="p">(</span><span class="s1">&#39;[ [[x x] [x x x] []] [[x] [x x x x]] ]&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape2</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedShape</span><span class="p">(</span><span class="s1">&#39;[ [x] [x x x] [] [] [x x] [x] [] [x x x x] [] [x x] ]&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape1</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">shape2</span><span class="p">)</span>
<span class="go">[ [ [ [ x ] [ x x x ] ] [ [ ] [ ] [ x x ] ] [ ] ] [ [ [ x ] ] [ [ ] [ x x x x ] [ ] [ x x ] ] ] ]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape1</span><span class="o">.</span><span class="n">tot_size</span><span class="p">(</span><span class="n">shape1</span><span class="o">.</span><span class="n">num_axes</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
<span class="go">10</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape2</span><span class="o">.</span><span class="n">dim0</span>
<span class="go">10</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>other</strong> – The other shape that is to be composed with <code class="docutils literal notranslate"><span class="pre">self</span></code>.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Return a composed ragged shape.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="id52">
<h3>get_layer<a class="headerlink" href="#id52" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.ragged.RaggedShape.get_layer">
<span class="sig-prename descclassname"><span class="pre">RaggedShape.</span></span><span class="sig-name descname"><span class="pre">get_layer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">k2.ragged.RaggedShape</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">arg0</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">k2.ragged.RaggedShape</span></span></span><a class="headerlink" href="#k2.ragged.RaggedShape.get_layer" title="Permalink to this definition"></a></dt>
<dd><p>Returns a <cite>sub-shape</cite> of <code class="docutils literal notranslate"><span class="pre">self</span></code>.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedShape</span><span class="p">(</span><span class="s1">&#39;[ [[x x] [x] []] [[] [x x x] [x]] [[]] ]&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape</span><span class="o">.</span><span class="n">get_layer</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="go">[ [ x x x ] [ x x x ] [ x ] ]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape</span><span class="o">.</span><span class="n">get_layer</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="go">[ [ x x ] [ x ] [ ] [ ] [ x x x ] [ x ] [ ] ]</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>layer</strong> – Layer that is desired, from <code class="docutils literal notranslate"><span class="pre">0</span> <span class="pre">..</span> <span class="pre">src.num_axes</span> <span class="pre">-</span> <span class="pre">2</span></code> (inclusive).</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>This returned shape will have <code class="docutils literal notranslate"><span class="pre">num_axes</span> <span class="pre">==</span> <span class="pre">2</span></code>, the minimal case of
a <code class="xref py py-class docutils literal notranslate"><span class="pre">RaggedShape</span></code>.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="id53">
<h3>index<a class="headerlink" href="#id53" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.ragged.RaggedShape.index">
<span class="sig-prename descclassname"><span class="pre">RaggedShape.</span></span><span class="sig-name descname"><span class="pre">index</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">k2.ragged.RaggedShape</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axis</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">indexes</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">need_value_indexes</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">k2.ragged.RaggedShape</span><span class="p"><span class="pre">,</span> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#k2.ragged.RaggedShape.index" title="Permalink to this definition"></a></dt>
<dd><p>Indexing operation on a ragged shape, returns <code class="docutils literal notranslate"><span class="pre">self[indexes]</span></code>, where elements
of <code class="docutils literal notranslate"><span class="pre">indexes</span></code> are interpreted as indexes into axis <code class="docutils literal notranslate"><span class="pre">axis</span></code> of self``.</p>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p><code class="docutils literal notranslate"><span class="pre">indexes</span></code> is a 1-D tensor and <code class="docutils literal notranslate"><span class="pre">indexes.dtype</span> <span class="pre">==</span> <span class="pre">torch.int32</span></code>.</p>
</div>
<p><strong>Example 1</strong>:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">shape</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedShape</span><span class="p">(</span><span class="s1">&#39;[ [x x] [x] [x x x] ]&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">value</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="o">*</span> <span class="mi">10</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ragged</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ragged</span>
<span class="go">[ [ 0 10 ] [ 20 ] [ 30 40 50 ] ]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">i</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sub_shape</span><span class="p">,</span> <span class="n">value_indexes</span> <span class="o">=</span> <span class="n">shape</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">indexes</span><span class="o">=</span><span class="n">i</span><span class="p">,</span> <span class="n">need_value_indexes</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sub_shape</span>
<span class="go">[ [ x x ] [ x x x ] [ x ] ]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">value_indexes</span>
<span class="go">tensor([0, 1, 3, 4, 5, 2], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ragged</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">value_indexes</span><span class="o">.</span><span class="n">long</span><span class="p">()]</span>
<span class="go">tensor([ 0., 10., 30., 40., 50., 20.])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">k</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sub_shape2</span><span class="p">,</span> <span class="n">value_indexes2</span> <span class="o">=</span> <span class="n">shape</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">indexes</span><span class="o">=</span><span class="n">k</span><span class="p">,</span> <span class="n">need_value_indexes</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sub_shape2</span>
<span class="go">[ [ x x ] [ ] [ x ] [ x x ] [ x x x ] [ ] ]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">value_indexes2</span>
<span class="go">tensor([0, 1, 2, 0, 1, 3, 4, 5], dtype=torch.int32)</span>
</pre></div>
</div>
<p><strong>Example 2</strong>:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedShape</span><span class="p">(</span><span class="s1">&#39;[ [[x x] [x]] [[] [x x x] [x]] [[x] [] [] [x x]] ]&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">i</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">indexes</span><span class="o">=</span><span class="n">i</span><span class="p">)</span>
<span class="go">([ [ [ x x ] [ x ] ] [ [ x x x ] ] [ [ x ] [ ] [ x x ] ] ], tensor([0, 1, 2, 3, 4, 5, 7, 8, 9], dtype=torch.int32))</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>axis</strong> – The axis to be indexed. Must satisfy <code class="docutils literal notranslate"><span class="pre">0</span> <span class="pre">&lt;=</span> <span class="pre">axis</span> <span class="pre">&lt;</span> <span class="pre">self.num_axes</span></code>.</p></li>
<li><p><strong>indexes</strong> – Array of indexes, which will be interpreted as indexes into axis <code class="docutils literal notranslate"><span class="pre">axis</span></code>
of <code class="docutils literal notranslate"><span class="pre">self</span></code>, i.e. with <code class="docutils literal notranslate"><span class="pre">0</span> <span class="pre">&lt;=</span> <span class="pre">indexes[i]</span> <span class="pre">&lt;</span> <span class="pre">self.tot_size(axis)</span></code>.
Note that if <code class="docutils literal notranslate"><span class="pre">axis</span></code> is 0, then -1 is also a valid entry in <code class="docutils literal notranslate"><span class="pre">index</span></code>,
in which case, an empty list is returned.</p></li>
<li><p><strong>need_value_indexes</strong> – <p>If <code class="docutils literal notranslate"><span class="pre">True</span></code>, it will return a torch.Tensor containing the indexes into
<code class="docutils literal notranslate"><span class="pre">ragged_tensor.data</span></code> that <code class="docutils literal notranslate"><span class="pre">ans.data</span></code> has, as in
<code class="docutils literal notranslate"><span class="pre">ans.data</span> <span class="pre">=</span> <span class="pre">ragged_tensor.data[value_indexes]</span></code>, where <code class="docutils literal notranslate"><span class="pre">ragged_tensor</span></code>
uses <code class="docutils literal notranslate"><span class="pre">self</span></code> as its shape.</p>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>It is currently not allowed to change the order on axes less than
<code class="docutils literal notranslate"><span class="pre">axis</span></code>, i.e. if <code class="docutils literal notranslate"><span class="pre">axis</span> <span class="pre">&gt;</span> <span class="pre">0</span></code>, we require:
<code class="docutils literal notranslate"><span class="pre">IsMonotonic(self.row_ids(axis)[indexes])</span></code>.</p>
</div>
</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Return an indexed ragged shape.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="id54">
<h3>max_size<a class="headerlink" href="#id54" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.ragged.RaggedShape.max_size">
<span class="sig-prename descclassname"><span class="pre">RaggedShape.</span></span><span class="sig-name descname"><span class="pre">max_size</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">k2.ragged.RaggedShape</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axis</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">int</span></span></span><a class="headerlink" href="#k2.ragged.RaggedShape.max_size" title="Permalink to this definition"></a></dt>
<dd><p>Return the maximum number of elements of any sublist at the given axis.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedShape</span><span class="p">(</span><span class="s1">&#39;[ [] [x] [x x] [x x x] [x x x x] ]&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape</span><span class="o">.</span><span class="n">max_size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="go">4</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedShape</span><span class="p">(</span><span class="s1">&#39;[ [[x x] [x] [] [] []] [[x]] [[x x x x]] ]&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape</span><span class="o">.</span><span class="n">max_size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="go">5</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape</span><span class="o">.</span><span class="n">max_size</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="go">4</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>axis</strong> – <p>Compute the max size of this axis.</p>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p><code class="docutils literal notranslate"><span class="pre">axis</span></code> has to be greater than 0.</p>
</div>
</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Return the maximum number of elements of sublists at the given <code class="docutils literal notranslate"><span class="pre">axis</span></code>.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="id55">
<h3>numel<a class="headerlink" href="#id55" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.ragged.RaggedShape.numel">
<span class="sig-prename descclassname"><span class="pre">RaggedShape.</span></span><span class="sig-name descname"><span class="pre">numel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">k2.ragged.RaggedShape</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">int</span></span></span><a class="headerlink" href="#k2.ragged.RaggedShape.numel" title="Permalink to this definition"></a></dt>
<dd><p>Return the number of elements in this shape.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedShape</span><span class="p">(</span><span class="s1">&#39;[ [x] [] [x x x x x]]&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span>
<span class="go">6</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape2</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedShape</span><span class="p">(</span><span class="s1">&#39;[ [[x x] [x] [] [] []] [[x]] [[x x x x]] ]&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape2</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span>
<span class="go">8</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape3</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedShape</span><span class="p">(</span><span class="s1">&#39;[ [x x x] [x] ]&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape3</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span>
<span class="go">4</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><p>Return the number of elements in this shape.</p>
<div class="admonition hint">
<p class="admonition-title">Hint</p>
<p>It’s the number of <code class="docutils literal notranslate"><span class="pre">x</span></code>’s.</p>
</div>
</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="id56">
<h3>regular_ragged_shape<a class="headerlink" href="#id56" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.ragged.RaggedShape.regular_ragged_shape">
<em class="property"><span class="pre">static</span> </em><span class="sig-prename descclassname"><span class="pre">RaggedShape.</span></span><span class="sig-name descname"><span class="pre">regular_ragged_shape</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dim0</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dim1</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">k2.ragged.RaggedShape</span></span></span><a class="headerlink" href="#k2.ragged.RaggedShape.regular_ragged_shape" title="Permalink to this definition"></a></dt>
<dd><p>Create a ragged shape with 2 axes that has a regular structure.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape1</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedShape</span><span class="o">.</span><span class="n">regular_ragged_shape</span><span class="p">(</span><span class="n">dim0</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim1</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape1</span>
<span class="go">[ [ x x x ] [ x x x ] ]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape2</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">regular_ragged_shape</span><span class="p">(</span><span class="n">dim0</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">dim1</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape2</span>
<span class="go">[ [ x x ] [ x x ] [ x x ] ]</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dim0</strong> – Number of entries at axis 0.</p></li>
<li><p><strong>dim1</strong> – Number of entries in each sublist at axis 1.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Return a ragged shape on CPU.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="id57">
<h3>remove_axis<a class="headerlink" href="#id57" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.ragged.RaggedShape.remove_axis">
<span class="sig-prename descclassname"><span class="pre">RaggedShape.</span></span><span class="sig-name descname"><span class="pre">remove_axis</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">k2.ragged.RaggedShape</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axis</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">k2.ragged.RaggedShape</span></span></span><a class="headerlink" href="#k2.ragged.RaggedShape.remove_axis" title="Permalink to this definition"></a></dt>
<dd><p>Remove a certain axis.</p>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p><code class="docutils literal notranslate"><span class="pre">self.num_axes</span></code> MUST be greater than 2.</p>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedShape</span><span class="p">(</span><span class="s1">&#39;[ [[x] [] [x x]] [[x x x] [x x x x]] [[] [] []]]&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape</span><span class="o">.</span><span class="n">remove_axis</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="go">[ [ x ] [ ] [ x x ] [ x x x ] [ x x x x ] [ ] [ ] [ ] ]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape</span><span class="o">.</span><span class="n">remove_axis</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="go">[ [ x x x ] [ x x x x x x x ] [ ] ]</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>axis</strong> – The axis to be removed.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Return a ragged shape with one fewer axis.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="id58">
<h3>row_ids<a class="headerlink" href="#id58" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.ragged.RaggedShape.row_ids">
<span class="sig-prename descclassname"><span class="pre">RaggedShape.</span></span><span class="sig-name descname"><span class="pre">row_ids</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">k2.ragged.RaggedShape</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axis</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="headerlink" href="#k2.ragged.RaggedShape.row_ids" title="Permalink to this definition"></a></dt>
<dd><p>Return the row ids of a certain <code class="docutils literal notranslate"><span class="pre">axis</span></code>.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedShape</span><span class="p">(</span><span class="s1">&#39;[ [x x] [] [x x x] ]&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape</span><span class="o">.</span><span class="n">row_ids</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="go">tensor([0, 0, 2, 2, 2], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape2</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedShape</span><span class="p">(</span><span class="s1">&#39;[ [[x] [] [x x]] [[x x x] [x] [x x x x] [] []] ]&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape2</span><span class="o">.</span><span class="n">row_ids</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="go">tensor([0, 0, 0, 1, 1, 1, 1, 1], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape2</span><span class="o">.</span><span class="n">row_ids</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="go">tensor([0, 2, 2, 3, 3, 3, 4, 5, 5, 5, 5], dtype=torch.int32)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>axis</strong> – The axis whose row ids is to be returned.</p></li>
<li><p><strong>Hint</strong> – <code class="docutils literal notranslate"><span class="pre">axis</span> <span class="pre">&gt;=</span> <span class="pre">1</span></code>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Return the row ids of the given <code class="docutils literal notranslate"><span class="pre">axis</span></code>.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="id59">
<h3>row_splits<a class="headerlink" href="#id59" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.ragged.RaggedShape.row_splits">
<span class="sig-prename descclassname"><span class="pre">RaggedShape.</span></span><span class="sig-name descname"><span class="pre">row_splits</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">k2.ragged.RaggedShape</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axis</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="headerlink" href="#k2.ragged.RaggedShape.row_splits" title="Permalink to this definition"></a></dt>
<dd><p>Return the row splits of a certain <code class="docutils literal notranslate"><span class="pre">axis</span></code>.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedShape</span><span class="p">(</span><span class="s1">&#39;[ [x x] [] [x x x] ]&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape</span><span class="o">.</span><span class="n">row_splits</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="go">tensor([0, 2, 2, 5], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape2</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedShape</span><span class="p">(</span><span class="s1">&#39;[ [[x] [] [x x]] [[x x x] [x] [x x x x] [] []] ]&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape2</span><span class="o">.</span><span class="n">row_splits</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="go">tensor([0, 3, 8], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape2</span><span class="o">.</span><span class="n">row_splits</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="go">tensor([ 0,  1,  1,  3,  6,  7, 11, 11, 11], dtype=torch.int32)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>axis</strong> – The axis whose row splits is to be returned.</p></li>
<li><p><strong>Hint</strong> – <code class="docutils literal notranslate"><span class="pre">axis</span> <span class="pre">&gt;=</span> <span class="pre">1</span></code>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Return the row splits of the given <code class="docutils literal notranslate"><span class="pre">axis</span></code>.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="id60">
<h3>to<a class="headerlink" href="#id60" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.ragged.RaggedShape.to">
<span class="sig-prename descclassname"><span class="pre">RaggedShape.</span></span><span class="sig-name descname"><span class="pre">to</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="pre">self:</span> <span class="pre">k2.ragged.RaggedShape</span></em>, <em class="sig-param"><span class="pre">device:</span> <span class="pre">torch::Device</span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">k2.ragged.RaggedShape</span></span></span><a class="headerlink" href="#k2.ragged.RaggedShape.to" title="Permalink to this definition"></a></dt>
<dd><p>Move this shape to the specified device.</p>
<div class="admonition hint">
<p class="admonition-title">Hint</p>
<p>If the shape is already on the specified device, the returned shape
shares the underlying memory with <code class="docutils literal notranslate"><span class="pre">self</span></code>.</p>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedShape</span><span class="p">(</span><span class="s1">&#39;[[x]]&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape</span><span class="o">.</span><span class="n">device</span>
<span class="go">device(type=&#39;cpu&#39;)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape2</span> <span class="o">=</span> <span class="n">shape</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cuda&#39;</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape2</span><span class="o">.</span><span class="n">device</span>
<span class="go">device(type=&#39;cuda&#39;, index=0)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape</span>
<span class="go">[ [ x ] ]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape2</span>
<span class="go">[ [ x ] ]</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>device</strong> – An instance of <code class="docutils literal notranslate"><span class="pre">torch.device</span></code>. It can be either a CPU device or
a CUDA device.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Return a shape on the given device.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="id61">
<h3>tot_size<a class="headerlink" href="#id61" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.ragged.RaggedShape.tot_size">
<span class="sig-prename descclassname"><span class="pre">RaggedShape.</span></span><span class="sig-name descname"><span class="pre">tot_size</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">k2.ragged.RaggedShape</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axis</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">int</span></span></span><a class="headerlink" href="#k2.ragged.RaggedShape.tot_size" title="Permalink to this definition"></a></dt>
<dd><p>Return the number of elements at a certain``axis``.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedShape</span><span class="p">(</span><span class="s1">&#39;[ [x] [x x] [x x x] []]&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape</span><span class="o">.</span><span class="n">tot_size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="go">6</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span>
<span class="go">6</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape2</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedShape</span><span class="p">(</span><span class="s1">&#39;[ [[x]] [[x x]] [[x x x]] [[]] [[]] [[]] [[]] ]&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape2</span><span class="o">.</span><span class="n">tot_size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="go">7</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape2</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedShape</span><span class="p">(</span><span class="s1">&#39;[ [[x]] [[x x]] [[x x x]] [[]] [[]] [[]] [[] []] ]&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape2</span><span class="o">.</span><span class="n">tot_size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="go">8</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape2</span><span class="o">.</span><span class="n">tot_size</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="go">6</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape2</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span>
<span class="go">6</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>axis</strong> – Return the number of elements for this <code class="docutils literal notranslate"><span class="pre">axis</span></code>.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Return the number of elements at <code class="docutils literal notranslate"><span class="pre">axis</span></code>.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="id62">
<h3>tot_sizes<a class="headerlink" href="#id62" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.ragged.RaggedShape.tot_sizes">
<span class="sig-prename descclassname"><span class="pre">RaggedShape.</span></span><span class="sig-name descname"><span class="pre">tot_sizes</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">k2.ragged.RaggedShape</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">tuple</span></span></span><a class="headerlink" href="#k2.ragged.RaggedShape.tot_sizes" title="Permalink to this definition"></a></dt>
<dd><p>Return total sizes of every axis in a tuple.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedShape</span><span class="p">(</span><span class="s1">&#39;[ [x] [ ] [x x x x]]&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape</span><span class="o">.</span><span class="n">dim0</span>
<span class="go">3</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape</span><span class="o">.</span><span class="n">tot_size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="go">5</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape</span><span class="o">.</span><span class="n">tot_sizes</span><span class="p">()</span>
<span class="go">(3, 5)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape2</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedShape</span><span class="p">(</span><span class="s1">&#39;[ [[x] []] [[x x x x]]]&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape2</span><span class="o">.</span><span class="n">dim0</span>
<span class="go">2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape2</span><span class="o">.</span><span class="n">tot_size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="go">3</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape2</span><span class="o">.</span><span class="n">tot_size</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="go">5</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape2</span><span class="o">.</span><span class="n">tot_sizes</span><span class="p">()</span>
<span class="go">(2, 3, 5)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Return a tuple containing the total sizes of each axis.
<code class="docutils literal notranslate"><span class="pre">ans[i]</span></code> is the total size of axis <code class="docutils literal notranslate"><span class="pre">i</span></code> (for <code class="docutils literal notranslate"><span class="pre">i</span> <span class="pre">&gt;</span> <span class="pre">0</span></code>).
For <code class="docutils literal notranslate"><span class="pre">i=0</span></code>, it is the <code class="docutils literal notranslate"><span class="pre">dim0</span></code> of this shape.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="id63">
<h3>device<a class="headerlink" href="#id63" title="Permalink to this headline"></a></h3>
<dl class="py attribute">
<dt class="sig sig-object py" id="k2.ragged.RaggedShape.device">
<span class="sig-prename descclassname"><span class="pre">RaggedShape.</span></span><span class="sig-name descname"><span class="pre">device</span></span><a class="headerlink" href="#k2.ragged.RaggedShape.device" title="Permalink to this definition"></a></dt>
<dd><p>Return the device of this shape.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedShape</span><span class="p">(</span><span class="s1">&#39;[[]]&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape</span><span class="o">.</span><span class="n">device</span>
<span class="go">device(type=&#39;cpu&#39;)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape2</span> <span class="o">=</span> <span class="n">shape</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cuda&#39;</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape2</span><span class="o">.</span><span class="n">device</span>
<span class="go">device(type=&#39;cuda&#39;, index=0)</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="id64">
<h3>dim0<a class="headerlink" href="#id64" title="Permalink to this headline"></a></h3>
<dl class="py attribute">
<dt class="sig sig-object py" id="k2.ragged.RaggedShape.dim0">
<span class="sig-prename descclassname"><span class="pre">RaggedShape.</span></span><span class="sig-name descname"><span class="pre">dim0</span></span><a class="headerlink" href="#k2.ragged.RaggedShape.dim0" title="Permalink to this definition"></a></dt>
<dd><p>Return number of sublists at axis 0.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedShape</span><span class="p">(</span><span class="s1">&#39;[ [x] [] [x x x x x]]&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape</span><span class="o">.</span><span class="n">dim0</span>
<span class="go">3</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape2</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedShape</span><span class="p">(</span><span class="s1">&#39;[ [[x] []] [[]] [[x] [x x] [x x x]] [[]]]&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape2</span><span class="o">.</span><span class="n">dim0</span>
<span class="go">4</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="id65">
<h3>num_axes<a class="headerlink" href="#id65" title="Permalink to this headline"></a></h3>
<dl class="py attribute">
<dt class="sig sig-object py" id="k2.ragged.RaggedShape.num_axes">
<span class="sig-prename descclassname"><span class="pre">RaggedShape.</span></span><span class="sig-name descname"><span class="pre">num_axes</span></span><a class="headerlink" href="#k2.ragged.RaggedShape.num_axes" title="Permalink to this definition"></a></dt>
<dd><p>Return the number of axes of this shape.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedShape</span><span class="p">(</span><span class="s1">&#39;[[] []]&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape</span><span class="o">.</span><span class="n">num_axes</span>
<span class="go">2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape2</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedShape</span><span class="p">(</span><span class="s1">&#39;[ [[]] [[]]]&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape2</span><span class="o">.</span><span class="n">num_axes</span>
<span class="go">3</span>
</pre></div>
</div>
</dd></dl>

</section>
</section>
<section id="id66">
<h2>RaggedTensor<a class="headerlink" href="#id66" title="Permalink to this headline"></a></h2>
<section id="id67">
<h3>__eq__<a class="headerlink" href="#id67" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.ragged.RaggedTensor.__eq__">
<span class="sig-prename descclassname"><span class="pre">RaggedTensor.</span></span><span class="sig-name descname"><span class="pre">__eq__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">k2.ragged.RaggedTensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">other</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">k2.ragged.RaggedTensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">bool</span></span></span><a class="headerlink" href="#k2.ragged.RaggedTensor.__eq__" title="Permalink to this definition"></a></dt>
<dd><p>Compare two ragged tensors.</p>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>The two tensors MUST have the same dtype. Otherwise,
it throws an exception.</p>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">==</span>  <span class="n">b</span>
<span class="go">True</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">try</span><span class="p">:</span>
<span class="gp">... </span>  <span class="n">c</span> <span class="o">==</span> <span class="n">b</span>
<span class="gp">... </span><span class="k">except</span> <span class="ne">RuntimeError</span><span class="p">:</span>
<span class="gp">... </span>  <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;raised exception&quot;</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>other</strong> – The tensor to be compared.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Return <code class="docutils literal notranslate"><span class="pre">True</span></code> if the two tensors are equal.
Return <code class="docutils literal notranslate"><span class="pre">False</span></code> otherwise.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="id68">
<h3>__getitem__<a class="headerlink" href="#id68" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.ragged.RaggedTensor.__getitem__">
<span class="sig-prename descclassname"><span class="pre">RaggedTensor.</span></span><span class="sig-name descname"><span class="pre">__getitem__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#k2.ragged.RaggedTensor.__getitem__" title="Permalink to this definition"></a></dt>
<dd><p>Overloaded function.</p>
<ol class="arabic simple">
<li><p>__getitem__(self: k2.ragged.RaggedTensor, i: int) -&gt; object</p></li>
</ol>
<p>Select the i-th sublist along axis 0.</p>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>Support for autograd is to be implemented.</p>
</div>
<p><strong>Example 1</strong>:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">(</span><span class="s1">&#39;[ [[1 3] [] [9]]  [[8]] ]&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>
<span class="go">RaggedTensor([[[1, 3],</span>
<span class="go">               [],</span>
<span class="go">               [9]],</span>
<span class="go">              [[8]]], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="go">RaggedTensor([[1, 3],</span>
<span class="go">              [],</span>
<span class="go">              [9]], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="go">RaggedTensor([[8]], dtype=torch.int32)</span>
</pre></div>
</div>
<p><strong>Example 2</strong>:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">(</span><span class="s1">&#39;[ [1 3] [9] [8] ]&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>
<span class="go">RaggedTensor([[1, 3],</span>
<span class="go">              [9],</span>
<span class="go">              [8]], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="go">tensor([1, 3], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="go">tensor([9], dtype=torch.int32)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>i</strong> – The i-th sublist along axis 0.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Return a new ragged tensor with one fewer axis. If <cite>num_axes == 2</cite>, the
return value will be a 1D tensor.</p>
</dd>
</dl>
<ol class="arabic simple" start="2">
<li><p>__getitem__(self: k2.ragged.RaggedTensor, key: slice) -&gt; k2.ragged.RaggedTensor</p></li>
</ol>
<p>Slices sublists along axis 0 with the given range. Only support slicing step
equals to 1.</p>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>Support for autograd is to be implemented.</p>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">(</span><span class="s1">&#39;[ [[1 3] [] [9]]  [[8]] [[10 11]] ]&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>
<span class="go">RaggedTensor([[[1, 3],</span>
<span class="go">               [],</span>
<span class="go">               [9]],</span>
<span class="go">              [[8]],</span>
<span class="go">              [[10, 11]]], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">2</span><span class="p">]</span>
<span class="go">RaggedTensor([[[1, 3],</span>
<span class="go">               [],</span>
<span class="go">               [9]],</span>
<span class="go">              [[8]]], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="mi">2</span><span class="p">]</span>
<span class="go">RaggedTensor([[[8]]], dtype=torch.int32)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>key</strong> – Slice containing integer constants.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Return a new ragged tensor with the same axes as original ragged tensor, but
only contains the sublists within the range.</p>
</dd>
</dl>
<ol class="arabic simple" start="3">
<li><p>__getitem__(self: k2.ragged.RaggedTensor, key: torch.Tensor) -&gt; k2.ragged.RaggedTensor</p></li>
</ol>
<p>Slice a ragged tensor along axis 0 using a 1-D torch.int32 tensor.</p>
<p><strong>Example 1</strong>:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">k2</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">k2</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">],</span> <span class="p">[</span><span class="mi">300</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">10</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="go">tensor([1, 2, 0], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span><span class="p">[</span><span class="n">a</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>
<span class="go">RaggedTensor([[300],</span>
<span class="go">              [-10, 0, -1],</span>
<span class="go">              [10, 20]], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="go">tensor([0, 1], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span><span class="p">[</span><span class="n">a</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span>
<span class="go">RaggedTensor([[10, 20],</span>
<span class="go">              [300]], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
<span class="go">tensor([2, 3], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span><span class="p">[</span><span class="n">a</span><span class="p">[</span><span class="mi">2</span><span class="p">]]</span>
<span class="go">RaggedTensor([[-10, 0, -1],</span>
<span class="go">              [-2, 4, 5]], dtype=torch.int32)</span>
</pre></div>
</div>
<p><strong>Example 2</strong>:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">k2</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([</span> <span class="p">[[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">]],</span> <span class="p">[[],</span> <span class="p">[</span><span class="mi">2</span><span class="p">]],</span> <span class="p">[[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">]]</span> <span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">i</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
<span class="go">RaggedTensor([[[1],</span>
<span class="go">               [2, 3],</span>
<span class="go">               [0]],</span>
<span class="go">              [[10, 20]],</span>
<span class="go">              [[],</span>
<span class="go">               [2]],</span>
<span class="go">              [[1],</span>
<span class="go">               [2, 3],</span>
<span class="go">               [0]]], dtype=torch.int32)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>key</strong> – A 1-D torch.int32 tensor containing the indexes to select along
axis 0.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Return a new ragged tensor with the same number of axes as <code class="docutils literal notranslate"><span class="pre">self</span></code> but
only contains the specified sublists.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="id69">
<h3>__getstate__<a class="headerlink" href="#id69" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.ragged.RaggedTensor.__getstate__">
<span class="sig-prename descclassname"><span class="pre">RaggedTensor.</span></span><span class="sig-name descname"><span class="pre">__getstate__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">k2.ragged.Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">tuple</span></span></span><a class="headerlink" href="#k2.ragged.RaggedTensor.__getstate__" title="Permalink to this definition"></a></dt>
<dd><p>Requires a tensor with 2 axes or 3 axes. Other number
of axes are not implemented yet.</p>
<p>This method is to support <code class="docutils literal notranslate"><span class="pre">pickle</span></code>, e.g., used by <code class="docutils literal notranslate"><span class="pre">torch.save()</span></code>.
You are not expected to call it by yourself.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>If this tensor has 2 axes, return a tuple containing
(self.row_splits(1), “row_ids1”, self.values).
If this tensor has 3 axes, return a tuple containing
(self.row_splits(1), “row_ids1”, self.row_splits(1),
“row_ids2”, self.values)</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>“row_ids1” and “row_ids2” in the returned value is for
backward compatibility.</p>
</div>
</dd></dl>

</section>
<section id="id70">
<h3>__init__<a class="headerlink" href="#id70" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.ragged.RaggedTensor.__init__">
<span class="sig-prename descclassname"><span class="pre">RaggedTensor.</span></span><span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#k2.ragged.RaggedTensor.__init__" title="Permalink to this definition"></a></dt>
<dd><p>Overloaded function.</p>
<ol class="arabic simple">
<li><p>__init__(self: k2.ragged.RaggedTensor, data: list, dtype: object = None, device: torch::Device = device(type=’cpu’)) -&gt; None</p></li>
</ol>
<p>Create a ragged tensor with arbitrary number of axes.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>A ragged tensor has at least two axes.</p>
</div>
<p><strong>Example 1</strong>:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">5</span><span class="p">],</span> <span class="p">[],</span> <span class="p">[</span><span class="mi">9</span><span class="p">]</span> <span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>
<span class="go">RaggedTensor([[1, 2],</span>
<span class="go">              [5],</span>
<span class="go">              [],</span>
<span class="go">              [9]], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">dtype</span>
<span class="go">torch.int32</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">],</span> <span class="p">[]</span> <span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span>
<span class="go">RaggedTensor([[1, 3],</span>
<span class="go">              []], dtype=torch.float32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span><span class="o">.</span><span class="n">dtype</span>
<span class="go">torch.float32</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span>
<span class="go">RaggedTensor([[1]], dtype=torch.float64)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span><span class="o">.</span><span class="n">dtype</span>
<span class="go">torch.float64</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">d</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([</span> <span class="p">[[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]],</span> <span class="p">[[</span><span class="mi">4</span><span class="p">],</span> <span class="p">[]]</span> <span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">d</span>
<span class="go">RaggedTensor([[[1],</span>
<span class="go">               [2, 3]],</span>
<span class="go">              [[4],</span>
<span class="go">               []]], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">d</span><span class="o">.</span><span class="n">num_axes</span>
<span class="go">3</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">e</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">e</span>
<span class="go">RaggedTensor([], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">e</span><span class="o">.</span><span class="n">num_axes</span>
<span class="go">2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">e</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="n">row_splits</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="go">tensor([0], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">e</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="n">row_ids</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="go">tensor([], dtype=torch.int32)</span>
</pre></div>
</div>
<p><strong>Example 2</strong>:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([</span> <span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]],</span> <span class="p">[],</span> <span class="p">[[]]</span> <span class="p">])</span>
<span class="go">RaggedTensor([[[1, 2]],</span>
<span class="go">              [],</span>
<span class="go">              [[]]], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([</span> <span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]],</span> <span class="p">[],</span> <span class="p">[[]]</span> <span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cuda:0&#39;</span><span class="p">)</span>
<span class="go">RaggedTensor([[[1, 2]],</span>
<span class="go">              [],</span>
<span class="go">              [[]]], device=&#39;cuda:0&#39;, dtype=torch.int32)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> – A list-of sublist(s) of integers or real numbers.
It can have arbitrary number of axes (at least two).</p></li>
<li><p><strong>dtype</strong> – Optional. If None, it infers the dtype from <code class="docutils literal notranslate"><span class="pre">data</span></code>
automatically, which is either <code class="docutils literal notranslate"><span class="pre">torch.int32</span></code> or
<code class="docutils literal notranslate"><span class="pre">torch.float32</span></code>. Supported dtypes are: <code class="docutils literal notranslate"><span class="pre">torch.int32</span></code>,
<code class="docutils literal notranslate"><span class="pre">torch.float32</span></code>, and <code class="docutils literal notranslate"><span class="pre">torch.float64</span></code>.</p></li>
<li><p><strong>device</strong> – It can be either an instance of <code class="docutils literal notranslate"><span class="pre">torch.device</span></code> or
a string representing a torch device. Example
values are: <code class="docutils literal notranslate"><span class="pre">&quot;cpu&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">&quot;cuda:0&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">torch.device(&quot;cpu&quot;)</span></code>,
<code class="docutils literal notranslate"><span class="pre">torch.device(&quot;cuda&quot;,</span> <span class="pre">0)</span></code>.</p></li>
</ul>
</dd>
</dl>
<ol class="arabic simple" start="2">
<li><p>__init__(self: k2.ragged.RaggedTensor, data: list, dtype: object = None, device: str = ‘cpu’) -&gt; None</p></li>
</ol>
<p>Create a ragged tensor with arbitrary number of axes.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>A ragged tensor has at least two axes.</p>
</div>
<p><strong>Example 1</strong>:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">5</span><span class="p">],</span> <span class="p">[],</span> <span class="p">[</span><span class="mi">9</span><span class="p">]</span> <span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>
<span class="go">RaggedTensor([[1, 2],</span>
<span class="go">              [5],</span>
<span class="go">              [],</span>
<span class="go">              [9]], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">dtype</span>
<span class="go">torch.int32</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">],</span> <span class="p">[]</span> <span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span>
<span class="go">RaggedTensor([[1, 3],</span>
<span class="go">              []], dtype=torch.float32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span><span class="o">.</span><span class="n">dtype</span>
<span class="go">torch.float32</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span>
<span class="go">RaggedTensor([[1]], dtype=torch.float64)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span><span class="o">.</span><span class="n">dtype</span>
<span class="go">torch.float64</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">d</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([</span> <span class="p">[[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]],</span> <span class="p">[[</span><span class="mi">4</span><span class="p">],</span> <span class="p">[]]</span> <span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">d</span>
<span class="go">RaggedTensor([[[1],</span>
<span class="go">               [2, 3]],</span>
<span class="go">              [[4],</span>
<span class="go">               []]], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">d</span><span class="o">.</span><span class="n">num_axes</span>
<span class="go">3</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">e</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">e</span>
<span class="go">RaggedTensor([], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">e</span><span class="o">.</span><span class="n">num_axes</span>
<span class="go">2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">e</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="n">row_splits</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="go">tensor([0], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">e</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="n">row_ids</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="go">tensor([], dtype=torch.int32)</span>
</pre></div>
</div>
<p><strong>Example 2</strong>:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([</span> <span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]],</span> <span class="p">[],</span> <span class="p">[[]]</span> <span class="p">])</span>
<span class="go">RaggedTensor([[[1, 2]],</span>
<span class="go">              [],</span>
<span class="go">              [[]]], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([</span> <span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]],</span> <span class="p">[],</span> <span class="p">[[]]</span> <span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cuda:0&#39;</span><span class="p">)</span>
<span class="go">RaggedTensor([[[1, 2]],</span>
<span class="go">              [],</span>
<span class="go">              [[]]], device=&#39;cuda:0&#39;, dtype=torch.int32)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> – A list-of sublist(s) of integers or real numbers.
It can have arbitrary number of axes (at least two).</p></li>
<li><p><strong>dtype</strong> – Optional. If None, it infers the dtype from <code class="docutils literal notranslate"><span class="pre">data</span></code>
automatically, which is either <code class="docutils literal notranslate"><span class="pre">torch.int32</span></code> or
<code class="docutils literal notranslate"><span class="pre">torch.float32</span></code>. Supported dtypes are: <code class="docutils literal notranslate"><span class="pre">torch.int32</span></code>,
<code class="docutils literal notranslate"><span class="pre">torch.float32</span></code>, and <code class="docutils literal notranslate"><span class="pre">torch.float64</span></code>.</p></li>
<li><p><strong>device</strong> – It can be either an instance of <code class="docutils literal notranslate"><span class="pre">torch.device</span></code> or
a string representing a torch device. Example
values are: <code class="docutils literal notranslate"><span class="pre">&quot;cpu&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">&quot;cuda:0&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">torch.device(&quot;cpu&quot;)</span></code>,
<code class="docutils literal notranslate"><span class="pre">torch.device(&quot;cuda&quot;,</span> <span class="pre">0)</span></code>.</p></li>
</ul>
</dd>
</dl>
<ol class="arabic simple" start="3">
<li><p>__init__(self: k2.ragged.RaggedTensor, s: str, dtype: object = None, device: torch::Device = device(type=’cpu’)) -&gt; None</p></li>
</ol>
<p>Create a ragged tensor from its string representation.</p>
<p>Fields are separated by space(s) <strong>or</strong> comma(s).</p>
<p>An example string for a 2-axis ragged tensor is given below:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">5</span> <span class="mi">6</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">]</span> <span class="p">]</span>
</pre></div>
</div>
<p>An example string for a 3-axis ragged tensor is given below:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span> <span class="p">[[</span><span class="mi">1</span><span class="p">]]</span> <span class="p">[[]]</span> <span class="p">]</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">(</span><span class="s1">&#39;[ [1] [] [3 4] ]&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>
<span class="go">RaggedTensor([[1],</span>
<span class="go">              [],</span>
<span class="go">              [3, 4]], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">num_axes</span>
<span class="go">2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">dtype</span>
<span class="go">torch.int32</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">(</span><span class="s1">&#39;[ [[] [3]]  [[10]] ]&#39;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span>
<span class="go">RaggedTensor([[[],</span>
<span class="go">               [3]],</span>
<span class="go">              [[10]]], dtype=torch.float32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span><span class="o">.</span><span class="n">dtype</span>
<span class="go">torch.float32</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span><span class="o">.</span><span class="n">num_axes</span>
<span class="go">3</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">(</span><span class="s1">&#39;[[1.]]&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span><span class="o">.</span><span class="n">dtype</span>
<span class="go">torch.float32</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">d</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">(</span><span class="s1">&#39;[[1.]]&#39;</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cuda:0&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">d</span>
<span class="go">RaggedTensor([[1]], device=&#39;cuda:0&#39;, dtype=torch.float32)</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Number of spaces or commas in <code class="docutils literal notranslate"><span class="pre">s</span></code> does not affect the result.
Of course, numbers have to be separated by at least one space or comma.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>s</strong> – A string representation of a ragged tensor.</p></li>
<li><p><strong>dtype</strong> – The desired dtype of the tensor. If it is <code class="docutils literal notranslate"><span class="pre">None</span></code>, it tries
to infer the correct dtype from <code class="docutils literal notranslate"><span class="pre">s</span></code>, which is assumed to be
either <code class="docutils literal notranslate"><span class="pre">torch.int32</span></code> or <code class="docutils literal notranslate"><span class="pre">torch.float32</span></code>. Supported dtypes are:
<code class="docutils literal notranslate"><span class="pre">torch.int32</span></code>, <code class="docutils literal notranslate"><span class="pre">torch.float32</span></code>, and <code class="docutils literal notranslate"><span class="pre">torch.float64</span></code>.</p></li>
<li><p><strong>device</strong> – It can be either an instance of <code class="docutils literal notranslate"><span class="pre">torch.device</span></code> or
a string representing a torch device. Example
values are: <code class="docutils literal notranslate"><span class="pre">&quot;cpu&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">&quot;cuda:0&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">torch.device(&quot;cpu&quot;)</span></code>,
<code class="docutils literal notranslate"><span class="pre">torch.device(&quot;cuda&quot;,</span> <span class="pre">0)</span></code>.</p></li>
</ul>
</dd>
</dl>
<ol class="arabic simple" start="4">
<li><p>__init__(self: k2.ragged.RaggedTensor, s: str, dtype: object = None, device: str = device(type=’cpu’)) -&gt; None</p></li>
</ol>
<p>Create a ragged tensor from its string representation.</p>
<p>Fields are separated by space(s) <strong>or</strong> comma(s).</p>
<p>An example string for a 2-axis ragged tensor is given below:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">5</span> <span class="mi">6</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">]</span> <span class="p">]</span>
</pre></div>
</div>
<p>An example string for a 3-axis ragged tensor is given below:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span> <span class="p">[[</span><span class="mi">1</span><span class="p">]]</span> <span class="p">[[]]</span> <span class="p">]</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">(</span><span class="s1">&#39;[ [1] [] [3 4] ]&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>
<span class="go">RaggedTensor([[1],</span>
<span class="go">              [],</span>
<span class="go">              [3, 4]], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">num_axes</span>
<span class="go">2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">dtype</span>
<span class="go">torch.int32</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">(</span><span class="s1">&#39;[ [[] [3]]  [[10]] ]&#39;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span>
<span class="go">RaggedTensor([[[],</span>
<span class="go">               [3]],</span>
<span class="go">              [[10]]], dtype=torch.float32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span><span class="o">.</span><span class="n">dtype</span>
<span class="go">torch.float32</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span><span class="o">.</span><span class="n">num_axes</span>
<span class="go">3</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">(</span><span class="s1">&#39;[[1.]]&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span><span class="o">.</span><span class="n">dtype</span>
<span class="go">torch.float32</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">d</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">(</span><span class="s1">&#39;[[1.]]&#39;</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cuda:0&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">d</span>
<span class="go">RaggedTensor([[1]], device=&#39;cuda:0&#39;, dtype=torch.float32)</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Number of spaces or commas in <code class="docutils literal notranslate"><span class="pre">s</span></code> does not affect the result.
Of course, numbers have to be separated by at least one space or comma.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>s</strong> – A string representation of a ragged tensor.</p></li>
<li><p><strong>dtype</strong> – The desired dtype of the tensor. If it is <code class="docutils literal notranslate"><span class="pre">None</span></code>, it tries
to infer the correct dtype from <code class="docutils literal notranslate"><span class="pre">s</span></code>, which is assumed to be
either <code class="docutils literal notranslate"><span class="pre">torch.int32</span></code> or <code class="docutils literal notranslate"><span class="pre">torch.float32</span></code>. Supported dtypes are:
<code class="docutils literal notranslate"><span class="pre">torch.int32</span></code>, <code class="docutils literal notranslate"><span class="pre">torch.float32</span></code>, and <code class="docutils literal notranslate"><span class="pre">torch.float64</span></code>.</p></li>
<li><p><strong>device</strong> – It can be either an instance of <code class="docutils literal notranslate"><span class="pre">torch.device</span></code> or
a string representing a torch device. Example
values are: <code class="docutils literal notranslate"><span class="pre">&quot;cpu&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">&quot;cuda:0&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">torch.device(&quot;cpu&quot;)</span></code>,
<code class="docutils literal notranslate"><span class="pre">torch.device(&quot;cuda&quot;,</span> <span class="pre">0)</span></code>.</p></li>
</ul>
</dd>
</dl>
<ol class="arabic simple" start="5">
<li><p>__init__(self: k2.ragged.RaggedTensor, shape: k2.ragged.RaggedShape, value: torch.Tensor) -&gt; None</p></li>
</ol>
<p>Create a ragged tensor from a shape and a value.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedShape</span><span class="p">(</span><span class="s1">&#39;[ [x x] [] [x x x] ]&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">value</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">10</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">40</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ragged</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ragged</span>
<span class="go">RaggedTensor([[10, 0],</span>
<span class="go">              [],</span>
<span class="go">              [20, 30, 40]], dtype=torch.float32)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>shape</strong> – The shape of the tensor.</p></li>
<li><p><strong>value</strong> – The value of the tensor.</p></li>
</ul>
</dd>
</dl>
<ol class="arabic simple" start="6">
<li><p>__init__(self: k2.ragged.RaggedTensor, tensor: torch.Tensor) -&gt; None</p></li>
</ol>
<p>Create a ragged tensor from a torch tensor.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>It turns a regular tensor into a ragged tensor.</p>
</div>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>The input tensor has to have more than 1 dimension.
That is <code class="docutils literal notranslate"><span class="pre">tensor.ndim</span> <span class="pre">&gt;</span> <span class="pre">1</span></code>.</p>
<p>Also, if the input tensor is contiguous, <code class="docutils literal notranslate"><span class="pre">self</span></code>
will share the underlying memory with it. Otherwise,
memory of the input tensor is copied to create <code class="docutils literal notranslate"><span class="pre">self</span></code>.</p>
<p>Supported dtypes of the input tensor are: <code class="docutils literal notranslate"><span class="pre">torch.int32</span></code>,
<code class="docutils literal notranslate"><span class="pre">torch.float32</span></code>, and <code class="docutils literal notranslate"><span class="pre">torch.float64</span></code>.</p>
</div>
<p><strong>Example 1</strong>:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>
<span class="go">tensor([[0, 1, 2],</span>
<span class="go">        [3, 4, 5]], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span>
<span class="go">RaggedTensor([[0, 1, 2],</span>
<span class="go">              [3, 4, 5]], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">is_contiguous</span><span class="p">()</span>
<span class="go">True</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">10</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span>
<span class="go">RaggedTensor([[10, 1, 2],</span>
<span class="go">              [3, 4, 5]], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>
<span class="go">tensor([[10, -2,  2],</span>
<span class="go">        [ 3,  4,  5]], dtype=torch.int32)</span>
</pre></div>
</div>
<p><strong>Example 2</strong>:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">24</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">12</span><span class="p">)[:,</span> <span class="p">::</span><span class="mi">4</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>
<span class="go">tensor([[ 0,  4,  8],</span>
<span class="go">        [12, 16, 20]], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">is_contiguous</span><span class="p">()</span>
<span class="go">False</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span>
<span class="go">RaggedTensor([[0, 4, 8],</span>
<span class="go">              [12, 16, 20]], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">10</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span>
<span class="go">RaggedTensor([[0, 4, 8],</span>
<span class="go">              [12, 16, 20]], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>
<span class="go">tensor([[10,  4,  8],</span>
<span class="go">        [12, 16, 20]], dtype=torch.int32)</span>
</pre></div>
</div>
<p><strong>Example 3</strong>:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">24</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>
<span class="go">tensor([[[ 0.,  1.,  2.,  3.],</span>
<span class="go">         [ 4.,  5.,  6.,  7.],</span>
<span class="go">         [ 8.,  9., 10., 11.]],</span>
<span class="go">        [[12., 13., 14., 15.],</span>
<span class="go">         [16., 17., 18., 19.],</span>
<span class="go">         [20., 21., 22., 23.]]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span>
<span class="go">RaggedTensor([[[0, 1, 2, 3],</span>
<span class="go">               [4, 5, 6, 7],</span>
<span class="go">               [8, 9, 10, 11]],</span>
<span class="go">              [[12, 13, 14, 15],</span>
<span class="go">               [16, 17, 18, 19],</span>
<span class="go">               [20, 21, 22, 23]]], dtype=torch.float32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span><span class="o">.</span><span class="n">dtype</span>
<span class="go">torch.float32</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]],</span> <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cuda:0&#39;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">(</span><span class="n">c</span><span class="p">)</span>
<span class="go">RaggedTensor([[1, 2]], device=&#39;cuda:0&#39;, dtype=torch.float32)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>tensor</strong> – An N-D (N &gt; 1) tensor.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="id71">
<h3>__ne__<a class="headerlink" href="#id71" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.ragged.RaggedTensor.__ne__">
<span class="sig-prename descclassname"><span class="pre">RaggedTensor.</span></span><span class="sig-name descname"><span class="pre">__ne__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">k2.ragged.RaggedTensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">other</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">k2.ragged.RaggedTensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">bool</span></span></span><a class="headerlink" href="#k2.ragged.RaggedTensor.__ne__" title="Permalink to this definition"></a></dt>
<dd><p>Compare two ragged tensors.</p>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>The two tensors MUST have the same dtype. Otherwise,
it throws an exception.</p>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">!=</span> <span class="n">a</span>
<span class="go">False</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span> <span class="o">!=</span> <span class="n">a</span>
<span class="go">True</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>other</strong> – The tensor to be compared.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Return <code class="docutils literal notranslate"><span class="pre">True</span></code> if the two tensors are NOT equal.
Return <code class="docutils literal notranslate"><span class="pre">False</span></code> otherwise.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="id72">
<h3>__repr__<a class="headerlink" href="#id72" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.ragged.RaggedTensor.__repr__">
<span class="sig-prename descclassname"><span class="pre">RaggedTensor.</span></span><span class="sig-name descname"><span class="pre">__repr__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">k2.ragged.RaggedTensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">str</span></span></span><a class="headerlink" href="#k2.ragged.RaggedTensor.__repr__" title="Permalink to this definition"></a></dt>
<dd><p>Return a string representation of this tensor.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>
<span class="go">RaggedTensor([[1],</span>
<span class="go">              [2, 3],</span>
<span class="go">              []], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">str</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="go">&#39;RaggedTensor([[1],\n              [2, 3],\n              []], dtype=torch.int32)&#39;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]],</span> <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cuda:0&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span>
<span class="go">RaggedTensor([[1, 2]], device=&#39;cuda:0&#39;, dtype=torch.int32)</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="id73">
<h3>__setstate__<a class="headerlink" href="#id73" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.ragged.RaggedTensor.__setstate__">
<span class="sig-prename descclassname"><span class="pre">RaggedTensor.</span></span><span class="sig-name descname"><span class="pre">__setstate__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">k2.ragged.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">arg0</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">tuple</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#k2.ragged.RaggedTensor.__setstate__" title="Permalink to this definition"></a></dt>
<dd><p>Set the content of this class from <code class="docutils literal notranslate"><span class="pre">arg0</span></code>.</p>
<p>This method is to support <code class="docutils literal notranslate"><span class="pre">pickle</span></code>, e.g., used by torch.load().
You are not expected to call it by yourself.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>arg0</strong> – It is the return value from the method <code class="docutils literal notranslate"><span class="pre">__getstate__</span></code>.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="id74">
<h3>__str__<a class="headerlink" href="#id74" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.ragged.RaggedTensor.__str__">
<span class="sig-prename descclassname"><span class="pre">RaggedTensor.</span></span><span class="sig-name descname"><span class="pre">__str__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">k2.ragged.RaggedTensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">str</span></span></span><a class="headerlink" href="#k2.ragged.RaggedTensor.__str__" title="Permalink to this definition"></a></dt>
<dd><p>Return a string representation of this tensor.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>
<span class="go">RaggedTensor([[1],</span>
<span class="go">              [2, 3],</span>
<span class="go">              []], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">str</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="go">&#39;RaggedTensor([[1],\n              [2, 3],\n              []], dtype=torch.int32)&#39;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]],</span> <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cuda:0&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span>
<span class="go">RaggedTensor([[1, 2]], device=&#39;cuda:0&#39;, dtype=torch.int32)</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="id75">
<h3>arange<a class="headerlink" href="#id75" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.ragged.RaggedTensor.arange">
<span class="sig-prename descclassname"><span class="pre">RaggedTensor.</span></span><span class="sig-name descname"><span class="pre">arange</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">k2.ragged.RaggedTensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axis</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">begin</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">end</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">k2.ragged.RaggedTensor</span></span></span><a class="headerlink" href="#k2.ragged.RaggedTensor.arange" title="Permalink to this definition"></a></dt>
<dd><p>Return a sub-range of <code class="docutils literal notranslate"><span class="pre">self</span></code> containing indexes <code class="docutils literal notranslate"><span class="pre">begin</span></code>
through <code class="docutils literal notranslate"><span class="pre">end</span> <span class="pre">-</span> <span class="pre">1</span></code> along axis <code class="docutils literal notranslate"><span class="pre">axis</span></code> of <code class="docutils literal notranslate"><span class="pre">self</span></code>.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">axis</span></code> argument may be confusing; its behavior is equivalent to:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">axis</span><span class="p">):</span>
  <span class="bp">self</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">remove_axis</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">begin</span><span class="p">,</span> <span class="n">end</span><span class="p">)</span>
</pre></div>
</div>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>The returned tensor shares the underlying memory with <code class="docutils literal notranslate"><span class="pre">self</span></code>.</p>
</div>
<p><strong>Example 1</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([</span> <span class="p">[[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[],</span> <span class="p">[</span><span class="mi">2</span><span class="p">]],</span> <span class="p">[[],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="p">[]],</span> <span class="p">[[],</span> <span class="p">[</span><span class="mi">1</span><span class="p">]],</span> <span class="p">[[]]</span> <span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>
<span class="go">RaggedTensor([[[1],</span>
<span class="go">               [],</span>
<span class="go">               [2]],</span>
<span class="go">              [[],</span>
<span class="go">               [4, 5],</span>
<span class="go">               []],</span>
<span class="go">              [[],</span>
<span class="go">               [1]],</span>
<span class="go">              [[]]], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">num_axes</span>
<span class="go">3</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">begin</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span>
<span class="go">RaggedTensor([[[],</span>
<span class="go">               [4, 5],</span>
<span class="go">               []],</span>
<span class="go">              [[],</span>
<span class="go">               [1]]], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span><span class="o">.</span><span class="n">num_axes</span>
<span class="go">3</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">begin</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span>
<span class="go">RaggedTensor([[[],</span>
<span class="go">               [4, 5],</span>
<span class="go">               []]], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span><span class="o">.</span><span class="n">num_axes</span>
<span class="go">3</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">d</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">begin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">d</span>
<span class="go">RaggedTensor([[1],</span>
<span class="go">              [],</span>
<span class="go">              [2],</span>
<span class="go">              []], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">d</span><span class="o">.</span><span class="n">num_axes</span>
<span class="go">2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">e</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">begin</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">e</span>
<span class="go">RaggedTensor([[2],</span>
<span class="go">              [],</span>
<span class="go">              [4, 5]], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">e</span><span class="o">.</span><span class="n">num_axes</span>
<span class="go">2</span>
</pre></div>
</div>
<p><strong>Example 2</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([</span> <span class="p">[[[],</span> <span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]],[[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">8</span><span class="p">],</span> <span class="p">[],</span> <span class="p">[</span><span class="mi">9</span><span class="p">]]],</span> <span class="p">[[[</span><span class="mi">10</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="p">[]]],</span> <span class="p">[[[],</span> <span class="p">[],</span> <span class="p">[</span><span class="mi">1</span><span class="p">]]]</span> <span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">num_axes</span>
<span class="go">4</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">begin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span>
<span class="go">RaggedTensor([[[[],</span>
<span class="go">                [1],</span>
<span class="go">                [2, 3]],</span>
<span class="go">               [[5, 8],</span>
<span class="go">                [],</span>
<span class="go">                [9]]],</span>
<span class="go">              [[[10],</span>
<span class="go">                [0],</span>
<span class="go">                []]]], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span><span class="o">.</span><span class="n">num_axes</span>
<span class="go">4</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">begin</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span>
<span class="go">RaggedTensor([[[5, 8],</span>
<span class="go">               [],</span>
<span class="go">               [9]],</span>
<span class="go">              [[10],</span>
<span class="go">               [0],</span>
<span class="go">               []]], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span><span class="o">.</span><span class="n">num_axes</span>
<span class="go">3</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">d</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">begin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">d</span>
<span class="go">RaggedTensor([[],</span>
<span class="go">              [1],</span>
<span class="go">              [2, 3],</span>
<span class="go">              [5, 8],</span>
<span class="go">              []], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">d</span><span class="o">.</span><span class="n">num_axes</span>
<span class="go">2</span>
</pre></div>
</div>
<p><strong>Example 3</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="p">[],</span> <span class="p">[</span><span class="mi">3</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>
<span class="go">RaggedTensor([[0],</span>
<span class="go">              [1],</span>
<span class="go">              [2],</span>
<span class="go">              [],</span>
<span class="go">              [3]], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">num_axes</span>
<span class="go">2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">begin</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span>
<span class="go">RaggedTensor([[1],</span>
<span class="go">              [2],</span>
<span class="go">              []], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>
<span class="go">RaggedTensor([[0],</span>
<span class="go">              [-1],</span>
<span class="go">              [2],</span>
<span class="go">              [],</span>
<span class="go">              [3]], dtype=torch.int32)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>axis</strong> – The axis from which <code class="docutils literal notranslate"><span class="pre">begin</span></code> and <code class="docutils literal notranslate"><span class="pre">end</span></code> correspond to.</p></li>
<li><p><strong>begin</strong> – The beginning of the range (inclusive).</p></li>
<li><p><strong>end</strong> – The end of the range (exclusive).</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>
<section id="id76">
<h3>argmax<a class="headerlink" href="#id76" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.ragged.RaggedTensor.argmax">
<span class="sig-prename descclassname"><span class="pre">RaggedTensor.</span></span><span class="sig-name descname"><span class="pre">argmax</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">k2.ragged.RaggedTensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">initial_value</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">object</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="headerlink" href="#k2.ragged.RaggedTensor.argmax" title="Permalink to this definition"></a></dt>
<dd><p>Return a tensor containing maximum value indexes within each sub-list along the
last axis of <code class="docutils literal notranslate"><span class="pre">self</span></code>, i.e. the max taken over the last axis, The index is -1
if the sub-list was empty or all values in the sub-list are less
than <code class="docutils literal notranslate"><span class="pre">initial_value</span></code>.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[]</span> <span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">argmax</span><span class="p">()</span>
<span class="go">tensor([ 0, -1, -1, -1], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">initial_value</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span>
<span class="go">tensor([ 0, -1, -1, -1], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span><span class="o">.</span><span class="n">argmax</span><span class="p">()</span>
<span class="go">tensor([ 3, -1,  7], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">d</span> <span class="o">=</span> <span class="n">c</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">initial_value</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">d</span>
<span class="go">tensor([ 3, -1,  7], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">c</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="mi">7</span><span class="p">]</span>
<span class="go">(tensor(5, dtype=torch.int32), tensor(8, dtype=torch.int32))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">initial_value</span><span class="o">=</span><span class="mi">6</span><span class="p">)</span>
<span class="go">tensor([-1, -1,  7], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">&#39;cuda:0&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="go">tensor([ 3, -1,  7], device=&#39;cuda:0&#39;, dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="go">tensor([ 3, -1,  7], dtype=torch.int32)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>initial_value</strong> – A base value to compare. If values in a sublist are all less
than this value, then the <code class="docutils literal notranslate"><span class="pre">argmax</span></code> of this sublist is -1.
If a sublist is empty, the <code class="docutils literal notranslate"><span class="pre">argmax</span></code> of it is also -1.
If it is <code class="docutils literal notranslate"><span class="pre">None</span></code>, the lowest value of <code class="docutils literal notranslate"><span class="pre">self.dtype</span></code> is used.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Return a 1-D <code class="docutils literal notranslate"><span class="pre">torch.int32</span></code> tensor. It is on the same device
as <code class="docutils literal notranslate"><span class="pre">self</span></code>.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="id77">
<h3>cat<a class="headerlink" href="#id77" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.ragged.RaggedTensor.cat">
<em class="property"><span class="pre">static</span> </em><span class="sig-prename descclassname"><span class="pre">RaggedTensor.</span></span><span class="sig-name descname"><span class="pre">cat</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">srcs</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">k2.ragged.RaggedTensor</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axis</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">k2.ragged.RaggedTensor</span></span></span><a class="headerlink" href="#k2.ragged.RaggedTensor.cat" title="Permalink to this definition"></a></dt>
<dd><p>Concatenate a list of ragged tensor over a specified axis.</p>
<p><strong>Example 1</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">k2r</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">a</span><span class="p">,</span> <span class="n">a</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="go">RaggedTensor([[1],</span>
<span class="go">              [],</span>
<span class="go">              [2, 3],</span>
<span class="go">              [1],</span>
<span class="go">              [],</span>
<span class="go">              [2, 3]], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">k2r</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">a</span><span class="p">,</span> <span class="n">a</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="go">RaggedTensor([[1, 1],</span>
<span class="go">              [],</span>
<span class="go">              [2, 3, 2, 3]], dtype=torch.int32)</span>
</pre></div>
</div>
<p><strong>Example 2</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[],</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">8</span><span class="p">],</span> <span class="p">[],</span> <span class="p">[</span><span class="mi">9</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">8</span><span class="p">],</span> <span class="p">[],</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">10</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span>
<span class="go">RaggedTensor([[1, 3],</span>
<span class="go">              [],</span>
<span class="go">              [5, 8],</span>
<span class="go">              [],</span>
<span class="go">              [9],</span>
<span class="go">              [0],</span>
<span class="go">              [1, 8],</span>
<span class="go">              [],</span>
<span class="go">              [-1],</span>
<span class="go">              [10]], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span><span class="o">.</span><span class="n">num_axes</span>
<span class="go">2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">d</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">d</span>
<span class="go">RaggedTensor([[1, 3, 0],</span>
<span class="go">              [1, 8],</span>
<span class="go">              [5, 8],</span>
<span class="go">              [-1],</span>
<span class="go">              [9, 10]], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">d</span><span class="o">.</span><span class="n">num_axes</span>
<span class="go">2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="go">RaggedTensor([[1, 3, 0],</span>
<span class="go">              [1, 8],</span>
<span class="go">              [5, 8],</span>
<span class="go">              [-1],</span>
<span class="go">              [9, 10]], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">k2r</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">b</span><span class="p">,</span> <span class="n">a</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="go">RaggedTensor([[0],</span>
<span class="go">              [1, 8],</span>
<span class="go">              [],</span>
<span class="go">              [-1],</span>
<span class="go">              [10],</span>
<span class="go">              [1, 3],</span>
<span class="go">              [],</span>
<span class="go">              [5, 8],</span>
<span class="go">              [],</span>
<span class="go">              [9]], dtype=torch.int32)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>srcs</strong> – A list (or a tuple) of ragged tensors to concatenate. They <strong>MUST</strong> all
have the same dtype and on the same device.</p></li>
<li><p><strong>axis</strong> – Only 0 and 1 are supported right now. If it is 1, then
<code class="docutils literal notranslate"><span class="pre">srcs[i].dim0</span></code> must all have the same value.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Return a concatenated tensor.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="id78">
<h3>clone<a class="headerlink" href="#id78" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.ragged.RaggedTensor.clone">
<span class="sig-prename descclassname"><span class="pre">RaggedTensor.</span></span><span class="sig-name descname"><span class="pre">clone</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">k2.ragged.RaggedTensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">k2.ragged.RaggedTensor</span></span></span><a class="headerlink" href="#k2.ragged.RaggedTensor.clone" title="Permalink to this definition"></a></dt>
<dd><p>Return a copy of this tensor.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">a</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>
<span class="go">RaggedTensor([[1, 2],</span>
<span class="go">              [3]], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">10</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>
<span class="go">RaggedTensor([[10, 2],</span>
<span class="go">              [3]], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span>
<span class="go">RaggedTensor([[1, 2],</span>
<span class="go">              [3]], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span>
<span class="go">RaggedTensor([[-1, 2],</span>
<span class="go">              [3]], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>
<span class="go">RaggedTensor([[10, 2],</span>
<span class="go">              [3]], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span>
<span class="go">RaggedTensor([[10, 2],</span>
<span class="go">              [3]], dtype=torch.int32)</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="id79">
<h3>index<a class="headerlink" href="#id79" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.ragged.RaggedTensor.index">
<span class="sig-prename descclassname"><span class="pre">RaggedTensor.</span></span><span class="sig-name descname"><span class="pre">index</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#k2.ragged.RaggedTensor.index" title="Permalink to this definition"></a></dt>
<dd><p>Overloaded function.</p>
<ol class="arabic simple">
<li><p>index(self: k2.ragged.RaggedTensor, indexes: k2.ragged.RaggedTensor) -&gt; k2.ragged.RaggedTensor</p></li>
</ol>
<p>Index a ragged tensor with a ragged tensor.</p>
<p><strong>Example 1</strong>:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">src</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">11</span><span class="p">],</span> <span class="p">[</span><span class="mi">12</span><span class="p">,</span> <span class="mf">13.5</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">indexes</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">src</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">indexes</span><span class="p">)</span>
<span class="go">RaggedTensor([[[10, 11],</span>
<span class="go">               [12, 13.5]]], dtype=torch.float32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">i</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">src</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
<span class="go">RaggedTensor([[[10, 11]],</span>
<span class="go">              [[12, 13.5]],</span>
<span class="go">              [[10, 11],</span>
<span class="go">               [10, 11]]], dtype=torch.float32)</span>
</pre></div>
</div>
<p><strong>Example 2</strong>:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">src</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([</span> <span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[],</span> <span class="p">[</span><span class="mi">2</span><span class="p">]],</span> <span class="p">[[],</span> <span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]],</span> <span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">i</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">]],</span> <span class="p">[[</span><span class="mi">0</span><span class="p">]]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">src</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
<span class="go">RaggedTensor([[[[[1, 0],</span>
<span class="go">                 [],</span>
<span class="go">                 [2]],</span>
<span class="go">                [[1, 2],</span>
<span class="go">                 [-1]]],</span>
<span class="go">               [[[],</span>
<span class="go">                 [3],</span>
<span class="go">                 [0, 0, 1]]]],</span>
<span class="go">              [[[[1, 0],</span>
<span class="go">                 [],</span>
<span class="go">                 [2]]]]], dtype=torch.int32)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>indexes</strong> – <p>Its values must satisfy <code class="docutils literal notranslate"><span class="pre">0</span> <span class="pre">&lt;=</span> <span class="pre">values[i]</span> <span class="pre">&lt;</span> <span class="pre">self.dim0</span></code>.</p>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>Its dtype has to be <code class="docutils literal notranslate"><span class="pre">torch.int32</span></code>.</p>
</div>
</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Return indexed tensor.</p>
</dd>
</dl>
<ol class="arabic simple" start="2">
<li><p>index(self: k2.ragged.RaggedTensor, indexes: torch.Tensor, axis: int, need_value_indexes: bool = False) -&gt; Tuple[k2.ragged.RaggedTensor, Optional[torch.Tensor]]</p></li>
</ol>
<p>Indexing operation on ragged tensor, returns <code class="docutils literal notranslate"><span class="pre">self[indexes]</span></code>, where
the elements of <code class="docutils literal notranslate"><span class="pre">indexes</span></code> are interpreted as indexes into axis <code class="docutils literal notranslate"><span class="pre">axis</span></code> of
<code class="docutils literal notranslate"><span class="pre">self</span></code>.</p>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p><code class="docutils literal notranslate"><span class="pre">indexes</span></code> is a 1-D tensor and <code class="docutils literal notranslate"><span class="pre">indexes.dtype</span> <span class="pre">==</span> <span class="pre">torch.int32</span></code>.</p>
</div>
<p><strong>Example 1</strong>:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.25</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">i</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span><span class="p">,</span> <span class="n">value_indexes</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">need_value_indexes</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span>
<span class="go">RaggedTensor([[0, 1, 2],</span>
<span class="go">              [0, 2, 3],</span>
<span class="go">              [],</span>
<span class="go">              [3, -1.25]], dtype=torch.float32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">value_indexes</span>
<span class="go">tensor([3, 4, 5, 0, 1, 2, 6, 7], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="n">value_indexes</span><span class="o">.</span><span class="n">long</span><span class="p">()]</span>
<span class="go">tensor([ 0.0000,  1.0000,  2.0000,  0.0000,  2.0000,  3.0000,  3.0000, -1.2500])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">k</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">need_value_indexes</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="go">(RaggedTensor([[0, 1, 2],</span>
<span class="go">              [],</span>
<span class="go">              [0, 2, 3]], dtype=torch.float32), tensor([3, 4, 5, 0, 1, 2], dtype=torch.int32))</span>
</pre></div>
</div>
<p><strong>Example 2</strong>:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([</span> <span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[],</span> <span class="p">[</span><span class="mi">2</span><span class="p">]],</span> <span class="p">[[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">8</span><span class="p">],</span> <span class="p">[],</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">]]</span> <span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">i</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="n">row_ids</span><span class="p">(</span><span class="mi">1</span><span class="p">)[</span><span class="n">i</span><span class="o">.</span><span class="n">long</span><span class="p">()]</span>
<span class="go">tensor([0, 0, 0, 1, 1, 1, 1], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span><span class="p">,</span> <span class="n">value_indexes</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">need_value_indexes</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span>
<span class="go">RaggedTensor([[[1, 3],</span>
<span class="go">               [2],</span>
<span class="go">               []],</span>
<span class="go">              [[2],</span>
<span class="go">               [5, 8],</span>
<span class="go">               [-1],</span>
<span class="go">               []]], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">value_indexes</span>
<span class="go">tensor([0, 1, 2, 6, 3, 4, 5], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="n">value_indexes</span><span class="o">.</span><span class="n">long</span><span class="p">()]</span>
<span class="go">tensor([ 1,  3,  2,  2,  5,  8, -1], dtype=torch.int32)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>indexes</strong> – <p>Array of indexes, which will be interpreted as indexes into axis <code class="docutils literal notranslate"><span class="pre">axis</span></code>
of <code class="docutils literal notranslate"><span class="pre">self</span></code>, i.e. with <code class="docutils literal notranslate"><span class="pre">0</span> <span class="pre">&lt;=</span> <span class="pre">indexes[i]</span> <span class="pre">&lt;</span> <span class="pre">self.tot_size(axis)</span></code>.
Note that if <code class="docutils literal notranslate"><span class="pre">axis</span></code> is 0, then -1 is also a valid entry in <code class="docutils literal notranslate"><span class="pre">index</span></code>,
-1 as an index, which will result in an empty list (as if it were the index
into a position in <code class="docutils literal notranslate"><span class="pre">self</span></code> that had an empty list at that point).</p>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>It is currently not allowed to change the order on axes less than
<code class="docutils literal notranslate"><span class="pre">axis</span></code>, i.e. if <code class="docutils literal notranslate"><span class="pre">axis</span> <span class="pre">&gt;</span> <span class="pre">0</span></code>, we require:
<code class="docutils literal notranslate"><span class="pre">IsMonotonic(self.shape.row_ids(axis)[indexes])</span></code>.</p>
</div>
</p></li>
<li><p><strong>axis</strong> – The axis to be indexed. Must satisfy <code class="docutils literal notranslate"><span class="pre">0</span> <span class="pre">&lt;=</span> <span class="pre">axis</span> <span class="pre">&lt;</span> <span class="pre">self.num_axes</span></code>.</p></li>
<li><p><strong>need_value_indexes</strong> – If <code class="docutils literal notranslate"><span class="pre">True</span></code>, it will return a torch.Tensor containing the indexes into
<code class="docutils literal notranslate"><span class="pre">self.values</span></code> that <code class="docutils literal notranslate"><span class="pre">ans.values</span></code> has, as in
<code class="docutils literal notranslate"><span class="pre">ans.values</span> <span class="pre">=</span> <span class="pre">self.values[value_indexes]</span></code>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p>A ragged tensor, sharing the same dtype and device with <code class="docutils literal notranslate"><span class="pre">self</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">None</span></code> if <code class="docutils literal notranslate"><span class="pre">need_value_indexes</span></code> is False; a 1-D torch.tensor of
dtype <code class="docutils literal notranslate"><span class="pre">torch.int32</span></code> containing the indexes into <code class="docutils literal notranslate"><span class="pre">self.values</span></code> that
<code class="docutils literal notranslate"><span class="pre">ans.values</span></code> has.</p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Return a tuple containing</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="id80">
<h3>max<a class="headerlink" href="#id80" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.ragged.RaggedTensor.max">
<span class="sig-prename descclassname"><span class="pre">RaggedTensor.</span></span><span class="sig-name descname"><span class="pre">max</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">k2.ragged.RaggedTensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">initial_value</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">object</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="headerlink" href="#k2.ragged.RaggedTensor.max" title="Permalink to this definition"></a></dt>
<dd><p>Return a tensor containing the maximum of each sub-list along the last
axis of <code class="docutils literal notranslate"><span class="pre">self</span></code>. The max is taken over the last axis or <code class="docutils literal notranslate"><span class="pre">initial_value</span></code>,
whichever was larger.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([</span> <span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[],</span> <span class="p">[]],</span> <span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">8</span><span class="p">]]</span> <span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>
<span class="go">tensor([          3,           5, -2147483648, -2147483648,           9,</span>
<span class="go">        -2147483648,           8], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">initial_value</span><span class="o">=-</span><span class="mi">10</span><span class="p">)</span>
<span class="go">tensor([  3,   5, -10, -10,   9, -10,   8], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">initial_value</span><span class="o">=</span><span class="mi">7</span><span class="p">)</span>
<span class="go">tensor([7, 7, 7, 7, 9, 7, 8], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">)</span>
<span class="go">tensor([ 3.,  5., -3., -3.,  9., -3.,  8.])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">&#39;cuda:0&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span>
<span class="go">tensor([ 3,  5, -2, -2,  9, -2,  8], device=&#39;cuda:0&#39;, dtype=torch.int32)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>initial_value</strong> – The base value to compare. If values in a sublist are all less
than this value, then the max of this sublist is <code class="docutils literal notranslate"><span class="pre">initial_value</span></code>.
If a sublist is empty, its max is also <code class="docutils literal notranslate"><span class="pre">initial_value</span></code>.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Return 1-D tensor containing the max value of each sublist.
It shares the same dtype and device with <code class="docutils literal notranslate"><span class="pre">self</span></code>.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="id81">
<h3>min<a class="headerlink" href="#id81" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.ragged.RaggedTensor.min">
<span class="sig-prename descclassname"><span class="pre">RaggedTensor.</span></span><span class="sig-name descname"><span class="pre">min</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">k2.ragged.RaggedTensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">initial_value</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">object</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="headerlink" href="#k2.ragged.RaggedTensor.min" title="Permalink to this definition"></a></dt>
<dd><p>Return a tensor containing the minimum of each sub-list along the last
axis of <code class="docutils literal notranslate"><span class="pre">self</span></code>. The min is taken over the last axis or <code class="docutils literal notranslate"><span class="pre">initial_value</span></code>,
whichever was smaller.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([</span> <span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[],</span> <span class="p">[]],</span> <span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">8</span><span class="p">]]</span> <span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">min</span><span class="p">()</span>
<span class="go">tensor([ 0.0000e+00, -1.0000e+00,  3.4028e+38,  3.4028e+38,  1.0000e+00,</span>
<span class="go">         3.4028e+38,  2.0000e+00])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">initial_value</span><span class="o">=</span><span class="nb">float</span><span class="p">(</span><span class="s1">&#39;inf&#39;</span><span class="p">))</span>
<span class="go">tensor([ 0., -1., inf, inf,  1., inf,  2.])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
<span class="go">tensor([  0.,  -1., 100., 100.,   1., 100.,   2.])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>
<span class="go">tensor([ 0, -1, 20, 20,  1, 20,  2], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">&#39;cuda:0&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="mi">15</span><span class="p">)</span>
<span class="go">tensor([ 0., -1., 15., 15.,  1., 15.,  2.], device=&#39;cuda:0&#39;)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>initial_value</strong> – The base value to compare. If values in a sublist are all larger
than this value, then the minimum of this sublist is <code class="docutils literal notranslate"><span class="pre">initial_value</span></code>.
If a sublist is empty, its minimum is also <code class="docutils literal notranslate"><span class="pre">initial_value</span></code>.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Return 1-D tensor containing the minimum of each sublist.
It shares the same dtype and device with <code class="docutils literal notranslate"><span class="pre">self</span></code>.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="id82">
<h3>normalize<a class="headerlink" href="#id82" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.ragged.RaggedTensor.normalize">
<span class="sig-prename descclassname"><span class="pre">RaggedTensor.</span></span><span class="sig-name descname"><span class="pre">normalize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">k2.ragged.RaggedTensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_log</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">k2.ragged.RaggedTensor</span></span></span><a class="headerlink" href="#k2.ragged.RaggedTensor.normalize" title="Permalink to this definition"></a></dt>
<dd><p>Normalize a ragged tensor over the last axis.</p>
<p>If <code class="docutils literal notranslate"><span class="pre">use_log</span></code> is <code class="docutils literal notranslate"><span class="pre">True</span></code>, the normalization per sublist is done as follows:</p>
<blockquote>
<div><ol class="arabic simple">
<li><p>Compute the log sum per sublist</p></li>
</ol>
<p>2. Subtract the log sum computed above from the sublist and return
it</p>
</div></blockquote>
<p>If <code class="docutils literal notranslate"><span class="pre">use_log</span></code> is <code class="docutils literal notranslate"><span class="pre">False</span></code>, the normalization per sublist is done as follows:</p>
<blockquote>
<div><ol class="arabic simple">
<li><p>Compute the sum per sublist</p></li>
<li><p>Divide the sublist by the above sum and return the resulting sublist</p></li>
</ol>
</div></blockquote>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If a sublist contains 3 elements <code class="docutils literal notranslate"><span class="pre">[a,</span> <span class="pre">b,</span> <span class="pre">c]</span></code>, then the log sum
is defined as:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">s</span> <span class="o">=</span> <span class="n">log</span><span class="p">(</span><span class="n">exp</span><span class="p">(</span><span class="n">a</span><span class="p">)</span> <span class="o">+</span> <span class="n">exp</span><span class="p">(</span><span class="n">b</span><span class="p">)</span> <span class="o">+</span> <span class="n">exp</span><span class="p">(</span><span class="n">c</span><span class="p">))</span>
</pre></div>
</div>
<p>The resulting sublist looks like below if <code class="docutils literal notranslate"><span class="pre">use_log</span></code> is <code class="docutils literal notranslate"><span class="pre">True</span></code>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="n">a</span> <span class="o">-</span> <span class="n">s</span><span class="p">,</span> <span class="n">b</span> <span class="o">-</span> <span class="n">s</span><span class="p">,</span> <span class="n">c</span> <span class="o">-</span> <span class="n">s</span><span class="p">]</span>
</pre></div>
</div>
<p>If <code class="docutils literal notranslate"><span class="pre">use_log</span></code> is <code class="docutils literal notranslate"><span class="pre">False</span></code>, the resulting sublist looks like:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="n">a</span><span class="o">/</span><span class="p">(</span><span class="n">a</span><span class="o">+</span><span class="n">b</span><span class="o">+</span><span class="n">c</span><span class="p">),</span> <span class="n">b</span><span class="o">/</span><span class="p">(</span><span class="n">a</span><span class="o">+</span><span class="n">b</span><span class="o">+</span><span class="n">c</span><span class="p">),</span> <span class="n">c</span><span class="o">/</span><span class="p">(</span><span class="n">a</span><span class="o">+</span><span class="n">b</span><span class="o">+</span><span class="n">c</span><span class="p">)]</span>
</pre></div>
</div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">],</span> <span class="p">[],</span> <span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">use_log</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="go">RaggedTensor([[0.25, 0.75],</span>
<span class="go">              [],</span>
<span class="go">              [1],</span>
<span class="go">              [0.2, 0.8]], dtype=torch.float32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">use_log</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="go">RaggedTensor([[-0.798139, -0.598139],</span>
<span class="go">              [],</span>
<span class="go">              [0],</span>
<span class="go">              [-1.03749, -0.437488]], dtype=torch.float32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([</span> <span class="p">[[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">],</span> <span class="p">[]],</span> <span class="p">[[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">]]</span> <span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">use_log</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="go">RaggedTensor([[[0.25, 0.75],</span>
<span class="go">               []],</span>
<span class="go">              [[1],</span>
<span class="go">               [0.2, 0.8]]], dtype=torch.float32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">use_log</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="go">RaggedTensor([[[-0.798139, -0.598139],</span>
<span class="go">               []],</span>
<span class="go">              [[0],</span>
<span class="go">               [-1.03749, -0.437488]]], dtype=torch.float32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">num_axes</span>
<span class="go">2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span><span class="o">.</span><span class="n">num_axes</span>
<span class="go">3</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">])</span><span class="o">.</span><span class="n">exp</span><span class="p">()</span> <span class="o">/</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">])</span><span class="o">.</span><span class="n">exp</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">())</span><span class="o">.</span><span class="n">log</span><span class="p">()</span>
<span class="go">tensor([-0.7981, -0.5981])</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>use_log</strong> – It indicates which kind of normalization to be applied.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Returns a 1-D tensor, sharing the same dtype and device with <code class="docutils literal notranslate"><span class="pre">self</span></code>.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="id83">
<h3>numel<a class="headerlink" href="#id83" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.ragged.RaggedTensor.numel">
<span class="sig-prename descclassname"><span class="pre">RaggedTensor.</span></span><span class="sig-name descname"><span class="pre">numel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">k2.ragged.RaggedTensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">int</span></span></span><a class="headerlink" href="#k2.ragged.RaggedTensor.numel" title="Permalink to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Return number of elements in this tensor. It equals to
<code class="docutils literal notranslate"><span class="pre">self.values.numel()</span></code>.</p>
</dd>
</dl>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span>
<span class="go">5</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">(</span><span class="s1">&#39;[ [[1] [] []]  [[2 3]]]&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span>
<span class="go">3</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">(</span><span class="s1">&#39;[[1] [] [3 4 5 6]]&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span>
<span class="go">5</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="id84">
<h3>pad<a class="headerlink" href="#id84" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.ragged.RaggedTensor.pad">
<span class="sig-prename descclassname"><span class="pre">RaggedTensor.</span></span><span class="sig-name descname"><span class="pre">pad</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">k2.ragged.RaggedTensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding_value</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">object</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="headerlink" href="#k2.ragged.RaggedTensor.pad" title="Permalink to this definition"></a></dt>
<dd><p>Pad a ragged tensor with 2-axes to a 2-D torch tensor.</p>
<p>For example, if <code class="docutils literal notranslate"><span class="pre">self</span></code> has the following values:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span> <span class="p">[</span><span class="mi">1</span> <span class="mi">2</span> <span class="mi">3</span><span class="p">]</span> <span class="p">[</span><span class="mi">4</span><span class="p">]</span> <span class="p">[</span><span class="mi">5</span> <span class="mi">6</span> <span class="mi">7</span> <span class="mi">8</span><span class="p">]</span> <span class="p">]</span>
</pre></div>
</div>
<p>Then it returns a 2-D tensor as follows if <code class="docutils literal notranslate"><span class="pre">padding_value</span></code> is 0 and
mode is <code class="docutils literal notranslate"><span class="pre">constant</span></code>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">]])</span>
</pre></div>
</div>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>It requires that <code class="docutils literal notranslate"><span class="pre">self.num_axes</span> <span class="pre">==</span> <span class="pre">2</span></code>.</p>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">2</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="s1">&#39;constant&#39;</span><span class="p">,</span> <span class="n">padding_value</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="go">tensor([[ 1, -1, -1, -1, -1],</span>
<span class="go">        [-1, -1, -1, -1, -1],</span>
<span class="go">        [ 2,  3, -1, -1, -1],</span>
<span class="go">        [ 5,  8,  9,  8,  2]], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="s1">&#39;replicate&#39;</span><span class="p">,</span> <span class="n">padding_value</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="go">tensor([[ 1,  1,  1,  1,  1],</span>
<span class="go">        [-1, -1, -1, -1, -1],</span>
<span class="go">        [ 2,  3,  3,  3,  3],</span>
<span class="go">        [ 5,  8,  9,  8,  2]], dtype=torch.int32)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>mode</strong> – Valid values are: <code class="docutils literal notranslate"><span class="pre">constant</span></code>, <code class="docutils literal notranslate"><span class="pre">replicate</span></code>. If it is
<code class="docutils literal notranslate"><span class="pre">constant</span></code>, the given <code class="docutils literal notranslate"><span class="pre">padding_value</span></code> is used for filling.
If it is <code class="docutils literal notranslate"><span class="pre">replicate</span></code>, the last entry in a list is used for filling.
If a list is empty, then the given <cite>padding_value</cite> is also used for filling.</p></li>
<li><p><strong>padding_value</strong> – The filling value.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A 2-D torch tensor, sharing the same dtype and device with <code class="docutils literal notranslate"><span class="pre">self</span></code>.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="id85">
<h3>remove_axis<a class="headerlink" href="#id85" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.ragged.RaggedTensor.remove_axis">
<span class="sig-prename descclassname"><span class="pre">RaggedTensor.</span></span><span class="sig-name descname"><span class="pre">remove_axis</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">k2.ragged.RaggedTensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axis</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">k2.ragged.RaggedTensor</span></span></span><a class="headerlink" href="#k2.ragged.RaggedTensor.remove_axis" title="Permalink to this definition"></a></dt>
<dd><p>Remove an axis; if it is not the first or last axis, this is done by appending
lists (effectively the axis is combined with the following axis).  If it is the
last axis it is just removed and the number of elements may be changed.</p>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>The tensor has to have more than two axes.</p>
</div>
<p><strong>Example 1</strong>:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([</span> <span class="p">[[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]],</span> <span class="p">[[],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[]],</span> <span class="p">[[</span><span class="mi">0</span><span class="p">]],</span> <span class="p">[[]]</span> <span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>
<span class="go">RaggedTensor([[[1],</span>
<span class="go">               [],</span>
<span class="go">               [0, -1]],</span>
<span class="go">              [[],</span>
<span class="go">               [2, 3],</span>
<span class="go">               []],</span>
<span class="go">              [[0]],</span>
<span class="go">              [[]]], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">num_axes</span>
<span class="go">3</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">remove_axis</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span>
<span class="go">RaggedTensor([[1],</span>
<span class="go">              [],</span>
<span class="go">              [0, -1],</span>
<span class="go">              [],</span>
<span class="go">              [2, 3],</span>
<span class="go">              [],</span>
<span class="go">              [0],</span>
<span class="go">              []], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">remove_axis</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span>
<span class="go">RaggedTensor([[1, 0, -1],</span>
<span class="go">              [2, 3],</span>
<span class="go">              [0],</span>
<span class="go">              []], dtype=torch.int32)</span>
</pre></div>
</div>
<p><strong>Example 2</strong>:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([</span> <span class="p">[[[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[],</span> <span class="p">[</span><span class="mi">2</span><span class="p">]]],</span> <span class="p">[[[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[],</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span> <span class="p">[]]],</span> <span class="p">[[[],</span> <span class="p">[</span><span class="mi">0</span><span class="p">]]]</span> <span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">num_axes</span>
<span class="go">4</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>
<span class="go">RaggedTensor([[[[1],</span>
<span class="go">                [],</span>
<span class="go">                [2]]],</span>
<span class="go">              [[[3, 4],</span>
<span class="go">                [],</span>
<span class="go">                [5, 6],</span>
<span class="go">                []]],</span>
<span class="go">              [[[],</span>
<span class="go">                [0]]]], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">remove_axis</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span>
<span class="go">RaggedTensor([[[1],</span>
<span class="go">               [],</span>
<span class="go">               [2]],</span>
<span class="go">              [[3, 4],</span>
<span class="go">               [],</span>
<span class="go">               [5, 6],</span>
<span class="go">               []],</span>
<span class="go">              [[],</span>
<span class="go">               [0]]], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">remove_axis</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span>
<span class="go">RaggedTensor([[[1],</span>
<span class="go">               [],</span>
<span class="go">               [2]],</span>
<span class="go">              [[3, 4],</span>
<span class="go">               [],</span>
<span class="go">               [5, 6],</span>
<span class="go">               []],</span>
<span class="go">              [[],</span>
<span class="go">               [0]]], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">d</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">remove_axis</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">d</span>
<span class="go">RaggedTensor([[[1, 2]],</span>
<span class="go">              [[3, 4, 5, 6]],</span>
<span class="go">              [[0]]], dtype=torch.int32)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>axis</strong> – The axis to move.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Return a ragged tensor with one fewer axes.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="id86">
<h3>remove_values_eq<a class="headerlink" href="#id86" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.ragged.RaggedTensor.remove_values_eq">
<span class="sig-prename descclassname"><span class="pre">RaggedTensor.</span></span><span class="sig-name descname"><span class="pre">remove_values_eq</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">k2.ragged.RaggedTensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">object</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">k2.ragged.RaggedTensor</span></span></span><a class="headerlink" href="#k2.ragged.RaggedTensor.remove_values_eq" title="Permalink to this definition"></a></dt>
<dd><p>Returns a ragged tensor after removing all ‘values’ that equal a provided
target.  Leaves all layers of the shape except for the last one unaffected.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>
<span class="go">RaggedTensor([[1, 2, 3, 0, 3, 2],</span>
<span class="go">              [],</span>
<span class="go">              [3, 2, 3],</span>
<span class="go">              [3]], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">remove_values_eq</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span>
<span class="go">RaggedTensor([[1, 2, 0, 2],</span>
<span class="go">              [],</span>
<span class="go">              [2],</span>
<span class="go">              []], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">remove_values_eq</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span>
<span class="go">RaggedTensor([[1, 3, 0, 3],</span>
<span class="go">              [],</span>
<span class="go">              [3, 3],</span>
<span class="go">              [3]], dtype=torch.int32)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>target</strong> – The target value to delete.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Return a ragged tensor whose values don’t contain the <code class="docutils literal notranslate"><span class="pre">target</span></code>.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="id87">
<h3>remove_values_leq<a class="headerlink" href="#id87" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.ragged.RaggedTensor.remove_values_leq">
<span class="sig-prename descclassname"><span class="pre">RaggedTensor.</span></span><span class="sig-name descname"><span class="pre">remove_values_leq</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">k2.ragged.RaggedTensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cutoff</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">object</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">k2.ragged.RaggedTensor</span></span></span><a class="headerlink" href="#k2.ragged.RaggedTensor.remove_values_leq" title="Permalink to this definition"></a></dt>
<dd><p>Returns a ragged tensor after removing all ‘values’ that are
equal to or less than a provided cutoff.
Leaves all layers of the shape except for the last one unaffected.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>
<span class="go">RaggedTensor([[1, 2, 3, 0, 3, 2],</span>
<span class="go">              [],</span>
<span class="go">              [3, 2, 3],</span>
<span class="go">              [3]], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">remove_values_leq</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span>
<span class="go">RaggedTensor([[],</span>
<span class="go">              [],</span>
<span class="go">              [],</span>
<span class="go">              []], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">remove_values_leq</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span>
<span class="go">RaggedTensor([[3, 3],</span>
<span class="go">              [],</span>
<span class="go">              [3, 3],</span>
<span class="go">              [3]], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">d</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">remove_values_leq</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">d</span>
<span class="go">RaggedTensor([[2, 3, 3, 2],</span>
<span class="go">              [],</span>
<span class="go">              [3, 2, 3],</span>
<span class="go">              [3]], dtype=torch.int32)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>cutoff</strong> – Values less than or equal to this <code class="docutils literal notranslate"><span class="pre">cutoff</span></code> are deleted.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Return a ragged tensor whose values are all above <code class="docutils literal notranslate"><span class="pre">cutoff</span></code>.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="id88">
<h3><a href="#id113"><span class="problematic" id="id114">requires_grad_</span></a><a class="headerlink" href="#id88" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.ragged.RaggedTensor.requires_grad_">
<span class="sig-prename descclassname"><span class="pre">RaggedTensor.</span></span><span class="sig-name descname"><span class="pre">requires_grad_</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">k2.ragged.RaggedTensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">requires_grad</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">k2.ragged.RaggedTensor</span></span></span><a class="headerlink" href="#k2.ragged.RaggedTensor.requires_grad_" title="Permalink to this definition"></a></dt>
<dd><p>Change if autograd should record operations on this tensor: Set
this tensor’s <a class="reference internal" href="#k2.ragged.RaggedTensor.requires_grad" title="k2.ragged.RaggedTensor.requires_grad"><code class="xref py py-attr docutils literal notranslate"><span class="pre">requires_grad</span></code></a> attribute <strong>in-place</strong>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If this tensor is not a float tensor, PyTorch will throw a
RuntimeError exception.</p>
</div>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>This method ends with an underscore, meaning it changes this tensor
<strong>in-place</strong>.</p>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">requires_grad</span>
<span class="go">False</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="go">RaggedTensor([[1]], dtype=torch.float64)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">requires_grad</span>
<span class="go">True</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>requires_grad</strong> – If autograd should record operations on this tensor.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Return this tensor.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="id89">
<h3><a href="#id115"><span class="problematic" id="id116">sort_</span></a><a class="headerlink" href="#id89" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.ragged.RaggedTensor.sort_">
<span class="sig-prename descclassname"><span class="pre">RaggedTensor.</span></span><span class="sig-name descname"><span class="pre">sort_</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">k2.ragged.RaggedTensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">descending</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">need_new2old_indexes</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#k2.ragged.RaggedTensor.sort_" title="Permalink to this definition"></a></dt>
<dd><p>Sort a ragged tensor over the last axis <strong>in-place</strong>.</p>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p><code class="docutils literal notranslate"><span class="pre">sort_</span></code> ends with an underscore, meaning this operation
changes <code class="docutils literal notranslate"><span class="pre">self</span></code> <strong>in-place</strong>.</p>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mf">0.</span><span class="p">]</span> <span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a_clone</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">sort_</span><span class="p">(</span><span class="n">descending</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">need_new2old_indexes</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span>
<span class="go">tensor([1, 0, 2, 4, 5, 3, 7, 6, 8], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>
<span class="go">RaggedTensor([[3, 1, 0],</span>
<span class="go">              [5, 3, 2],</span>
<span class="go">              [],</span>
<span class="go">              [3, 1, 0]], dtype=torch.float32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a_clone</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="n">b</span><span class="o">.</span><span class="n">long</span><span class="p">()]</span>
<span class="go">tensor([3., 1., 0., 5., 3., 2., 3., 1., 0.])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a_clone</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">sort_</span><span class="p">(</span><span class="n">descending</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">need_new2old_indexes</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span>
<span class="go">tensor([2, 1, 0, 5, 4, 3, 8, 7, 6], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>
<span class="go">RaggedTensor([[0, 1, 3],</span>
<span class="go">              [2, 3, 5],</span>
<span class="go">              [],</span>
<span class="go">              [0, 1, 3]], dtype=torch.float32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a_clone</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="n">c</span><span class="o">.</span><span class="n">long</span><span class="p">()]</span>
<span class="go">tensor([0., 1., 3., 2., 3., 5., 0., 1., 3.])</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>descending</strong> – <code class="docutils literal notranslate"><span class="pre">True</span></code> to sort in <strong>descending</strong> order.
<code class="docutils literal notranslate"><span class="pre">False</span></code> to sort in <strong>ascending</strong> order.</p></li>
<li><p><strong>need_new2old_indexes</strong> – If <code class="docutils literal notranslate"><span class="pre">True</span></code>, also returns a 1-D tensor, containing the indexes mapping
from the sorted elements to the unsorted elements. We can use
<code class="docutils literal notranslate"><span class="pre">self.clone().values[returned_tensor]</span></code> to get a sorted tensor.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>If <code class="docutils literal notranslate"><span class="pre">need_new2old_indexes</span></code> is False, returns None. Otherwise, returns
a 1-D tensor of dtype <code class="docutils literal notranslate"><span class="pre">torch.int32</span></code>.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="id90">
<h3>sum<a class="headerlink" href="#id90" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.ragged.RaggedTensor.sum">
<span class="sig-prename descclassname"><span class="pre">RaggedTensor.</span></span><span class="sig-name descname"><span class="pre">sum</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">k2.ragged.RaggedTensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">initial_value</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">float</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="headerlink" href="#k2.ragged.RaggedTensor.sum" title="Permalink to this definition"></a></dt>
<dd><p>Compute the sum of sublists over the last axis of this tensor.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If a sublist is empty, the sum for it is the provided
<code class="docutils literal notranslate"><span class="pre">initial_value</span></code>.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This operation supports autograd if this tensor is a float tensor,
i.e., with dtype being torch.float32 or torch.float64.</p>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">(</span><span class="s1">&#39;[ [[1 2] [] [5]]  [[10]] ]&#39;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="go">RaggedTensor([[[1, 2],</span>
<span class="go">               [],</span>
<span class="go">               [5]],</span>
<span class="go">              [[10]]], dtype=torch.float32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span> <span class="o">=</span> <span class="p">(</span><span class="n">b</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">4</span><span class="p">))</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">grad</span>
<span class="go">tensor([0., 0., 2., 3.])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span>
<span class="go">tensor([ 3.,  0.,  5., 10.], grad_fn=&lt;SumFunction&gt;&gt;)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span>
<span class="go">tensor(40., grad_fn=&lt;SumBackward0&gt;)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>initial_value</strong> – This value is added to the sum of each sublist. So when
a sublist is empty, its sum is this value.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Return a 1-D tensor with the same dtype of this tensor
containing the computed sum.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="id91">
<h3>to<a class="headerlink" href="#id91" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.ragged.RaggedTensor.to">
<span class="sig-prename descclassname"><span class="pre">RaggedTensor.</span></span><span class="sig-name descname"><span class="pre">to</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#k2.ragged.RaggedTensor.to" title="Permalink to this definition"></a></dt>
<dd><p>Overloaded function.</p>
<ol class="arabic simple">
<li><p>to(self: k2.ragged.RaggedTensor, device: torch::Device) -&gt; k2.ragged.RaggedTensor</p></li>
</ol>
<p>Transfer this tensor to a given device.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If <code class="docutils literal notranslate"><span class="pre">self</span></code> is already on the specified device, return a
ragged tensor sharing the underlying memory with <code class="docutils literal notranslate"><span class="pre">self</span></code>.
Otherwise, a new tensor is returned.</p>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">device</span>
<span class="go">device(type=&#39;cpu&#39;)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cuda&#39;</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span><span class="o">.</span><span class="n">device</span>
<span class="go">device(type=&#39;cuda&#39;, index=0)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>device</strong> – The target device to move this tensor.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Return a tensor on the given device.</p>
</dd>
</dl>
<ol class="arabic simple" start="2">
<li><p>to(self: k2.ragged.RaggedTensor, device: str) -&gt; k2.ragged.RaggedTensor</p></li>
</ol>
<p>Transfer this tensor to a given device.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If <code class="docutils literal notranslate"><span class="pre">self</span></code> is already on the specified device, return a
ragged tensor sharing the underlying memory with <code class="docutils literal notranslate"><span class="pre">self</span></code>.
Otherwise, a new tensor is returned.</p>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">device</span>
<span class="go">device(type=&#39;cpu&#39;)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">&#39;cuda:0&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span><span class="o">.</span><span class="n">device</span>
<span class="go">device(type=&#39;cuda&#39;, index=0)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span> <span class="o">=</span> <span class="n">b</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span><span class="o">.</span><span class="n">device</span>
<span class="go">device(type=&#39;cpu&#39;)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">d</span> <span class="o">=</span> <span class="n">c</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">&#39;cuda:1&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">d</span><span class="o">.</span><span class="n">device</span>
<span class="go">device(type=&#39;cuda&#39;, index=1)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>device</strong> – The target device to move this tensor.
Note: The device is represented as a string.
Valid strings are: “cpu”, “cuda:0”, “cuda:1”, etc.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Return a tensor on the given device.</p>
</dd>
</dl>
<ol class="arabic simple" start="3">
<li><p>to(self: k2.ragged.RaggedTensor, dtype: torch::dtype) -&gt; k2.ragged.RaggedTensor</p></li>
</ol>
<p>Convert this tensor to a specific dtype.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If <code class="docutils literal notranslate"><span class="pre">self</span></code> is already of the specified <cite>dtype</cite>, return
a ragged tensor sharing the underlying memory with <code class="docutils literal notranslate"><span class="pre">self</span></code>.
Otherwise, a new tensor is returned.</p>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">dtype</span>
<span class="go">torch.int32</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span><span class="o">.</span><span class="n">dtype</span>
<span class="go">torch.float64</span>
</pre></div>
</div>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>Currently, only support dtypes <code class="docutils literal notranslate"><span class="pre">torch.int32</span></code>, <code class="docutils literal notranslate"><span class="pre">torch.float32</span></code>, and
<code class="docutils literal notranslate"><span class="pre">torch.float64</span></code>. We can support other types if needed.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>dtype</strong> – The <cite>dtype</cite> this tensor should be converted to.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Return a tensor of the given <cite>dtype</cite>.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="id92">
<h3>to_str_simple<a class="headerlink" href="#id92" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.ragged.RaggedTensor.to_str_simple">
<span class="sig-prename descclassname"><span class="pre">RaggedTensor.</span></span><span class="sig-name descname"><span class="pre">to_str_simple</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">k2.ragged.RaggedTensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">str</span></span></span><a class="headerlink" href="#k2.ragged.RaggedTensor.to_str_simple" title="Permalink to this definition"></a></dt>
<dd><p>Convert a ragged tensor to a string representation, which
is more compact than <code class="docutils literal notranslate"><span class="pre">self.__str__</span></code>.</p>
<p>An example output is given below:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">RaggedTensor</span><span class="p">([[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[],</span> <span class="p">[</span><span class="mi">0</span><span class="p">]],</span> <span class="p">[[</span><span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mf">10.5</span><span class="p">]]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([</span> <span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[],</span> <span class="p">[</span><span class="mi">0</span><span class="p">]],</span> <span class="p">[[</span><span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mf">10.5</span><span class="p">]]</span> <span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>
<span class="go">RaggedTensor([[[1, 2, 3],</span>
<span class="go">               [],</span>
<span class="go">               [0]],</span>
<span class="go">              [[2],</span>
<span class="go">               [3, 10.5]]], dtype=torch.float32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">str</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="go">&#39;RaggedTensor([[[1, 2, 3],\n               [],\n               [0]],\n              [[2],\n               [3, 10.5]]], dtype=torch.float32)&#39;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">to_str_simple</span><span class="p">()</span>
<span class="go">&#39;RaggedTensor([[[1, 2, 3], [], [0]], [[2], [3, 10.5]]], dtype=torch.float32)&#39;</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="id93">
<h3>tolist<a class="headerlink" href="#id93" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.ragged.RaggedTensor.tolist">
<span class="sig-prename descclassname"><span class="pre">RaggedTensor.</span></span><span class="sig-name descname"><span class="pre">tolist</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">k2.ragged.RaggedTensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">list</span></span></span><a class="headerlink" href="#k2.ragged.RaggedTensor.tolist" title="Permalink to this definition"></a></dt>
<dd><p>Turn a ragged tensor into a list of lists [of lists..].</p>
<div class="admonition hint">
<p class="admonition-title">Hint</p>
<p>You can pass the returned list to the constructor of <code class="xref py py-class docutils literal notranslate"><span class="pre">RaggedTensor</span></code>.</p>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([</span> <span class="p">[[],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="p">[]],</span> <span class="p">[[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">]],</span> <span class="p">[[],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[],</span> <span class="p">[]]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
<span class="go">[[[], [1, 2], [3], []], [[5, 6, 7]], [[], [0, 2, 3], [], []]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">tolist</span><span class="p">())</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">==</span> <span class="n">b</span>
<span class="go">True</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([[</span><span class="mf">1.</span><span class="p">],</span> <span class="p">[</span><span class="mf">2.</span><span class="p">],</span> <span class="p">[],</span> <span class="p">[</span><span class="mf">3.25</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
<span class="go">[[1.0], [2.0], [], [3.25, 2.5]]</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A list of list of lists [of lists …] containing the same elements
and structure as <code class="docutils literal notranslate"><span class="pre">self</span></code>.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="id94">
<h3>tot_size<a class="headerlink" href="#id94" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.ragged.RaggedTensor.tot_size">
<span class="sig-prename descclassname"><span class="pre">RaggedTensor.</span></span><span class="sig-name descname"><span class="pre">tot_size</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">k2.ragged.RaggedTensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axis</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">int</span></span></span><a class="headerlink" href="#k2.ragged.RaggedTensor.tot_size" title="Permalink to this definition"></a></dt>
<dd><p>Return the number of elements of an given axis. If axis is 0, it’s
equivalent to the property <code class="docutils literal notranslate"><span class="pre">dim0</span></code>.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">(</span><span class="s1">&#39;[ [1 2 3] [] [5 8 ] ]&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">tot_size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="go">3</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">tot_size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="go">5</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">(</span><span class="s1">&#39;[ [[1 2 3] [] [5 8]] [[] [1 5 9 10 -1] [] [] []] ]&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span><span class="o">.</span><span class="n">tot_size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="go">2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span><span class="o">.</span><span class="n">tot_size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="go">8</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span><span class="o">.</span><span class="n">tot_size</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="go">10</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="id95">
<h3>unique<a class="headerlink" href="#id95" title="Permalink to this headline"></a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="k2.ragged.RaggedTensor.unique">
<span class="sig-prename descclassname"><span class="pre">RaggedTensor.</span></span><span class="sig-name descname"><span class="pre">unique</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">k2.ragged.RaggedTensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">need_num_repeats</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">need_new2old_indexes</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">k2.ragged.RaggedTensor</span><span class="p"><span class="pre">,</span> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">k2.ragged.RaggedTensor</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#k2.ragged.RaggedTensor.unique" title="Permalink to this definition"></a></dt>
<dd><p>If <code class="docutils literal notranslate"><span class="pre">self</span></code> has two axes, this will return the unique sub-lists
(in a possibly different order, but without repeats).
If <code class="docutils literal notranslate"><span class="pre">self</span></code> has 3 axes, it will do the above but separately for each
index on axis 0; if more than 3 axes, the earliest axes will be ignored.</p>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>It does not completely guarantee that all unique sequences will be
present in the output, as it relies on hashing and ignores collisions.
If several sequences have the same hash, only one of them is kept, even
if the actual content in the sequence is different.</p>
</div>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>Even if there are no repeated sequences, the output may be different
from <code class="docutils literal notranslate"><span class="pre">self</span></code>. That is, <cite>new2old_indexes</cite> may NOT be an identity map even
if nothing was removed.</p>
</div>
<p><strong>Example 1</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">unique</span><span class="p">()</span>
<span class="go">(RaggedTensor([[1],</span>
<span class="go">              [2],</span>
<span class="go">              [3],</span>
<span class="go">              [3, 1]], dtype=torch.int32), None, None)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">need_num_repeats</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">need_new2old_indexes</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="go">(RaggedTensor([[1],</span>
<span class="go">              [2],</span>
<span class="go">              [3],</span>
<span class="go">              [3, 1]], dtype=torch.int32), RaggedTensor([[2, 1, 1, 2]], dtype=torch.int32), tensor([2, 5, 1, 0], dtype=torch.int32))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">need_num_repeats</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="go">(RaggedTensor([[1],</span>
<span class="go">              [2],</span>
<span class="go">              [3],</span>
<span class="go">              [3, 1]], dtype=torch.int32), RaggedTensor([[2, 1, 1, 2]], dtype=torch.int32), None)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">need_new2old_indexes</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="go">(RaggedTensor([[1],</span>
<span class="go">              [2],</span>
<span class="go">              [3],</span>
<span class="go">              [3, 1]], dtype=torch.int32), None, tensor([2, 5, 1, 0], dtype=torch.int32))</span>
</pre></div>
</div>
<p><strong>Example 2</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]],</span> <span class="p">[[</span><span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">]],</span> <span class="p">[[],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[],</span> <span class="p">[</span><span class="mi">3</span><span class="p">]]</span> <span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">unique</span><span class="p">()</span>
<span class="go">(RaggedTensor([[[1, 2],</span>
<span class="go">               [2, 1]],</span>
<span class="go">              [[2],</span>
<span class="go">               [3],</span>
<span class="go">               [0, 1]],</span>
<span class="go">              [[],</span>
<span class="go">               [3],</span>
<span class="go">               [2, 3]]], dtype=torch.int32), None, None)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">need_num_repeats</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">need_new2old_indexes</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="go">(RaggedTensor([[[1, 2],</span>
<span class="go">               [2, 1]],</span>
<span class="go">              [[2],</span>
<span class="go">               [3],</span>
<span class="go">               [0, 1]],</span>
<span class="go">              [[],</span>
<span class="go">               [3],</span>
<span class="go">               [2, 3]]], dtype=torch.int32), RaggedTensor([[3, 1],</span>
<span class="go">              [2, 1, 1],</span>
<span class="go">              [2, 1, 1]], dtype=torch.int32), tensor([ 0,  1,  5,  4,  6,  8, 11,  9], dtype=torch.int32))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">need_num_repeats</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="go">(RaggedTensor([[[1, 2],</span>
<span class="go">               [2, 1]],</span>
<span class="go">              [[2],</span>
<span class="go">               [3],</span>
<span class="go">               [0, 1]],</span>
<span class="go">              [[],</span>
<span class="go">               [3],</span>
<span class="go">               [2, 3]]], dtype=torch.int32), RaggedTensor([[3, 1],</span>
<span class="go">              [2, 1, 1],</span>
<span class="go">              [2, 1, 1]], dtype=torch.int32), None)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">need_new2old_indexes</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="go">(RaggedTensor([[[1, 2],</span>
<span class="go">               [2, 1]],</span>
<span class="go">              [[2],</span>
<span class="go">               [3],</span>
<span class="go">               [0, 1]],</span>
<span class="go">              [[],</span>
<span class="go">               [3],</span>
<span class="go">               [2, 3]]], dtype=torch.int32), None, tensor([ 0,  1,  5,  4,  6,  8, 11,  9], dtype=torch.int32))</span>
</pre></div>
</div>
<p><strong>Example 3</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
<span class="go">(RaggedTensor([[1],</span>
<span class="go">              [2],</span>
<span class="go">              [3]], dtype=torch.int32), RaggedTensor([[1, 1, 1]], dtype=torch.int32), tensor([0, 2, 1], dtype=torch.int32))</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>need_num_repeats</strong> – If True, it also returns the number of repeats of each sequence.</p></li>
<li><p><strong>need_new2old_indexes</strong> – <p>If true, it returns an extra 1-D tensor <cite>new2old_indexes</cite>.
If <cite>src</cite> has 2 axes, this tensor contains <cite>src_idx0</cite>;
if <cite>src</cite> has 3 axes, this tensor contains <cite>src_idx01</cite>.</p>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>For repeated sublists, only one of them is kept.
The choice of which one to keep is <strong>deterministic</strong> and
is an implementation detail.</p>
</div>
</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p>ans: A ragged tensor with the same number of axes as <code class="docutils literal notranslate"><span class="pre">self</span></code> and possibly
fewer elements due to removing repeated sequences on the last axis
(and with the last-but-one indexes possibly in a different order).</p></li>
<li><p>num_repeats: A tensor containing number of repeats of each returned
sequence if <code class="docutils literal notranslate"><span class="pre">need_num_repeats</span></code> is True; it is <code class="docutils literal notranslate"><span class="pre">None</span></code> otherwise.
If it is not <code class="docutils literal notranslate"><span class="pre">None</span></code>, <code class="docutils literal notranslate"><span class="pre">num_repeats.num_axes</span></code> is always 2.
If <code class="docutils literal notranslate"><span class="pre">ans.num_axes</span></code> is 2, then <code class="docutils literal notranslate"><span class="pre">num_repeats.dim0</span> <span class="pre">==</span> <span class="pre">1</span></code> and
<code class="docutils literal notranslate"><span class="pre">num_repeats.numel()</span> <span class="pre">==</span> <span class="pre">ans.dim0</span></code>.
If <code class="docutils literal notranslate"><span class="pre">ans.num_axes</span></code> is 3, then <code class="docutils literal notranslate"><span class="pre">num_repeats.dim0</span> <span class="pre">==</span> <span class="pre">ans.dim0</span></code> and
<code class="docutils literal notranslate"><span class="pre">num_repeats.numel()</span> <span class="pre">==</span> <span class="pre">ans.tot_size(1)</span></code>.</p></li>
<li><p>new2old_indexes: A 1-D tensor whose i-th element specifies the
input sublist that the i-th output sublist corresponds to.</p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Returns a tuple containing</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="id96">
<h3>device<a class="headerlink" href="#id96" title="Permalink to this headline"></a></h3>
<dl class="py attribute">
<dt class="sig sig-object py" id="k2.ragged.RaggedTensor.device">
<span class="sig-prename descclassname"><span class="pre">RaggedTensor.</span></span><span class="sig-name descname"><span class="pre">device</span></span><a class="headerlink" href="#k2.ragged.RaggedTensor.device" title="Permalink to this definition"></a></dt>
<dd><p>Return the device of this tensor.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">device</span>
<span class="go">device(type=&#39;cpu&#39;)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cuda&#39;</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span><span class="o">.</span><span class="n">device</span>
<span class="go">device(type=&#39;cuda&#39;, index=0)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span><span class="o">.</span><span class="n">device</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cuda:0&#39;</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="id97">
<h3>dim0<a class="headerlink" href="#id97" title="Permalink to this headline"></a></h3>
<dl class="py attribute">
<dt class="sig sig-object py" id="k2.ragged.RaggedTensor.dim0">
<span class="sig-prename descclassname"><span class="pre">RaggedTensor.</span></span><span class="sig-name descname"><span class="pre">dim0</span></span><a class="headerlink" href="#k2.ragged.RaggedTensor.dim0" title="Permalink to this definition"></a></dt>
<dd><p>Return number of sublists at axis 0.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[]</span> <span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">dim0</span>
<span class="go">5</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">(</span><span class="s1">&#39;[ [[]] [[] []]]&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span><span class="o">.</span><span class="n">dim0</span>
<span class="go">2</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="id98">
<h3>dtype<a class="headerlink" href="#id98" title="Permalink to this headline"></a></h3>
<dl class="py attribute">
<dt class="sig sig-object py" id="k2.ragged.RaggedTensor.dtype">
<span class="sig-prename descclassname"><span class="pre">RaggedTensor.</span></span><span class="sig-name descname"><span class="pre">dtype</span></span><a class="headerlink" href="#k2.ragged.RaggedTensor.dtype" title="Permalink to this definition"></a></dt>
<dd><p>Return the dtype of this tensor.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">dtype</span>
<span class="go">torch.int32</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">dtype</span>
<span class="go">torch.float32</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([[</span><span class="mi">3</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span><span class="o">.</span><span class="n">dtype</span>
<span class="go">torch.float64</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="id99">
<h3>grad<a class="headerlink" href="#id99" title="Permalink to this headline"></a></h3>
<dl class="py attribute">
<dt class="sig sig-object py" id="k2.ragged.RaggedTensor.grad">
<span class="sig-prename descclassname"><span class="pre">RaggedTensor.</span></span><span class="sig-name descname"><span class="pre">grad</span></span><a class="headerlink" href="#k2.ragged.RaggedTensor.grad" title="Permalink to this definition"></a></dt>
<dd><p>This attribute is <code class="docutils literal notranslate"><span class="pre">None</span></code> by default. PyTorch will set it
during <code class="docutils literal notranslate"><span class="pre">backward()</span></code>.</p>
<p>The attribute will contain the gradients computed and future
calls to <code class="docutils literal notranslate"><span class="pre">backward()</span></code> will accumulate (add) gradients into it.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span> <span class="p">[]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="go">RaggedTensor([[1, 2],</span>
<span class="go">              [3],</span>
<span class="go">              [5, 6],</span>
<span class="go">              []], dtype=torch.float32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span>
<span class="go">tensor([ 3.,  3., 11.,  0.], grad_fn=&lt;SumFunction&gt;&gt;)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span> <span class="o">=</span> <span class="n">b</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">grad</span>
<span class="go">tensor([0., 0., 1., 2., 2.])</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="id100">
<h3>is_cuda<a class="headerlink" href="#id100" title="Permalink to this headline"></a></h3>
<dl class="py attribute">
<dt class="sig sig-object py" id="k2.ragged.RaggedTensor.is_cuda">
<span class="sig-prename descclassname"><span class="pre">RaggedTensor.</span></span><span class="sig-name descname"><span class="pre">is_cuda</span></span><a class="headerlink" href="#k2.ragged.RaggedTensor.is_cuda" title="Permalink to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Return <code class="docutils literal notranslate"><span class="pre">True</span></code> if the tensor is stored on the GPU, <code class="docutils literal notranslate"><span class="pre">False</span></code>
otherwise.</p>
</dd>
</dl>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">is_cuda</span>
<span class="go">False</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cuda&#39;</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span><span class="o">.</span><span class="n">is_cuda</span>
<span class="go">True</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="id101">
<h3>num_axes<a class="headerlink" href="#id101" title="Permalink to this headline"></a></h3>
<dl class="py attribute">
<dt class="sig sig-object py" id="k2.ragged.RaggedTensor.num_axes">
<span class="sig-prename descclassname"><span class="pre">RaggedTensor.</span></span><span class="sig-name descname"><span class="pre">num_axes</span></span><a class="headerlink" href="#k2.ragged.RaggedTensor.num_axes" title="Permalink to this definition"></a></dt>
<dd><p>Return the number of axes of this tensor.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">(</span><span class="s1">&#39;[ [] [] [] [] ]&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">num_axes</span>
<span class="go">2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">(</span><span class="s1">&#39;[ [[] []] [[]] ]&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span><span class="o">.</span><span class="n">num_axes</span>
<span class="go">3</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span> <span class="o">=</span> <span class="n">k24</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="s1">&#39;[ [ [[] [1]] [[3 4] []] ]  [ [[1]] [[2] [3 4]] ] ]&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span><span class="o">.</span><span class="n">num_axes</span>
<span class="go">4</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Return number of axes of this tensor, which is at least 2.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="id102">
<h3>requires_grad<a class="headerlink" href="#id102" title="Permalink to this headline"></a></h3>
<dl class="py attribute">
<dt class="sig sig-object py" id="k2.ragged.RaggedTensor.requires_grad">
<span class="sig-prename descclassname"><span class="pre">RaggedTensor.</span></span><span class="sig-name descname"><span class="pre">requires_grad</span></span><a class="headerlink" href="#k2.ragged.RaggedTensor.requires_grad" title="Permalink to this definition"></a></dt>
<dd><p>Return <code class="docutils literal notranslate"><span class="pre">True</span></code> if gradients need to be computed for this tensor.
Return <code class="docutils literal notranslate"><span class="pre">False</span></code> otherwise.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">requires_grad</span>
<span class="go">False</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">True</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">requires_grad</span>
<span class="go">True</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="id103">
<h3>shape<a class="headerlink" href="#id103" title="Permalink to this headline"></a></h3>
<dl class="py attribute">
<dt class="sig sig-object py" id="k2.ragged.RaggedTensor.shape">
<span class="sig-prename descclassname"><span class="pre">RaggedTensor.</span></span><span class="sig-name descname"><span class="pre">shape</span></span><a class="headerlink" href="#k2.ragged.RaggedTensor.shape" title="Permalink to this definition"></a></dt>
<dd><p>Return the shape of this tensor.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[],</span> <span class="p">[</span><span class="mi">3</span><span class="p">]</span> <span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">shape</span>
<span class="go">[ [ x x ] [ ] [ x ] ]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">type</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="go">&lt;class &#39;k2.ragged.RaggedShape&#39;&gt;</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="id104">
<h3>values<a class="headerlink" href="#id104" title="Permalink to this headline"></a></h3>
<dl class="py attribute">
<dt class="sig sig-object py" id="k2.ragged.RaggedTensor.values">
<span class="sig-prename descclassname"><span class="pre">RaggedTensor.</span></span><span class="sig-name descname"><span class="pre">values</span></span><a class="headerlink" href="#k2.ragged.RaggedTensor.values" title="Permalink to this definition"></a></dt>
<dd><p>Return the underlying memory as a 1-D tensor.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">k2.ragged</span> <span class="k">as</span> <span class="nn">k2r</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">k2r</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[],</span> <span class="p">[</span><span class="mi">5</span><span class="p">],</span> <span class="p">[],</span> <span class="p">[</span><span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">10</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">values</span>
<span class="go">tensor([ 1,  2,  5,  8,  9, 10], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">isinstance</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span>
<span class="go">True</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>
<span class="go">RaggedTensor([[1, 2],</span>
<span class="go">              [],</span>
<span class="go">              [5],</span>
<span class="go">              [],</span>
<span class="go">              [8, -1, 10]], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">3</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>
<span class="go">RaggedTensor([[1, 2],</span>
<span class="go">              [],</span>
<span class="go">              [5],</span>
<span class="go">              [],</span>
<span class="go">              [-3, -1, 10]], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>
<span class="go">RaggedTensor([[1, 2],</span>
<span class="go">              [],</span>
<span class="go">              [-2],</span>
<span class="go">              [],</span>
<span class="go">              [-3, -1, 10]], dtype=torch.int32)</span>
</pre></div>
</div>
</dd></dl>

</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="version.html" class="btn btn-neutral float-left" title="version" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2020-2021, k2 development team.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
 <script type="text/javascript">
    $(document).ready(function() {
        $(".toggle > *").hide();
        $(".toggle .header").show();
        $(".toggle .header").click(function() {
            $(this).parent().children().not(".header").toggle(400);
            $(this).parent().children(".header").toggleClass("open");
        })
    });
</script>


</body>
</html>